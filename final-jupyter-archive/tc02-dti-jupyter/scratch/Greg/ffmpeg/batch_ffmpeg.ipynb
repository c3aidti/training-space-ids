{"cells": [{"cell_type": "code", "execution_count": 2, "id": "1499cc31", "metadata": {"ExecuteTime": {"end_time": "2022-02-11T16:47:23.838660Z", "start_time": "2022-02-11T16:47:23.699804Z"}}, "outputs": [], "source": ["from __future__ import print_function\n", "import datetime\n", "import io\n", "import os\n", "import sys\n", "import time\n", "import config\n", "\n", "sys.path.append('/home/c3/.local/lib/python3.7/site-packages/')\n", "import config\n", "\n", "try:\n", "    input = raw_input\n", "except NameError:\n", "    pass\n", "\n", "\n", "from azure.core.exceptions import ResourceExistsError\n", "\n", "from azure.storage.blob import (\n", "    BlobServiceClient,\n", "    BlobSasPermissions,\n", "    generate_blob_sas\n", ")\n", "\n", "from azure.batch import BatchServiceClient\n", "from azure.batch.batch_auth import SharedKeyCredentials\n", "import azure.batch.models as batchmodels\n", "\n", "sys.path.append('.')\n", "sys.path.append('..')\n", "\n", "# Update the Batch and Storage account credential strings in config.py with values\n", "# unique to your accounts. These are used when constructing connection strings\n", "# for the Batch and Storage client objects."]}, {"cell_type": "code", "execution_count": null, "id": "3b92edbb", "metadata": {"ExecuteTime": {"end_time": "2021-12-21T18:50:12.762910Z", "start_time": "2021-12-21T18:50:12.753736Z"}}, "outputs": [], "source": []}, {"cell_type": "code", "execution_count": 3, "id": "ef0edb99", "metadata": {"ExecuteTime": {"end_time": "2022-02-11T16:47:23.846417Z", "start_time": "2022-02-11T16:47:23.840202Z"}}, "outputs": [], "source": ["def upload_file_to_container(blob_service_client, container_name, file_path):\n", "    \"\"\"\n", "    Uploads a local file to an Azure Blob storage container.\n", "\n", "    :param blob_service_client: A blob service client.\n", "    :type blob_service_client: `azure.storage.blob.BlobServiceClient`\n", "    :param str container_name: The name of the Azure Blob storage container.\n", "    :param str file_path: The local path to the file.\n", "    :rtype: `azure.batch.models.ResourceFile`\n", "    :return: A ResourceFile initialized with a SAS URL appropriate for Batch\n", "    tasks.\n", "    \"\"\"\n", "    blob_name = os.path.basename(file_path)\n", "    print(blob_name)\n", "    blob_client = blob_service_client.get_blob_client(container_name, blob_name)\n", "\n", "    print('Uploading file {} to container [{}]...'.format(file_path,\n", "                                                          container_name))\n", "\n", "    with open(file_path, \"rb\") as data:\n", "        blob_client.upload_blob(data, overwrite=True)\n", "\n", "    sas_token = generate_blob_sas(\n", "        config._STORAGE_ACCOUNT_NAME,\n", "        container_name,\n", "        blob_name,\n", "        account_key=config._STORAGE_ACCOUNT_KEY,\n", "        permission=BlobSasPermissions(read=True),\n", "        expiry=datetime.datetime.utcnow() + datetime.timedelta(hours=24)\n", "    )\n", "\n", "    sas_url = generate_sas_url(\n", "        config._STORAGE_ACCOUNT_NAME,\n", "        config._STORAGE_ACCOUNT_DOMAIN,\n", "        container_name,\n", "        blob_name,\n", "        sas_token\n", "    )\n", "\n", "    return batchmodels.ResourceFile(\n", "        http_url=sas_url,\n", "        file_path=blob_name\n", "    )\n", "\n", "def generate_sas_url(\n", "    account_name, account_domain, container_name, blob_name, sas_token\n", "):\n", "    \n", "    print(\"SAS URL is: https://{}.{}/{}/{}?{}\".format(\n", "        account_name,\n", "        account_domain,\n", "        container_name,\n", "        blob_name,\n", "        sas_token\n", "    ))\n", "    \n", "    return \"https://{}.{}/{}/{}?{}\".format(\n", "        account_name,\n", "        account_domain,\n", "        container_name,\n", "        blob_name,\n", "        sas_token\n", "    )\n"]}, {"cell_type": "code", "execution_count": 4, "id": "a256b41a", "metadata": {"ExecuteTime": {"end_time": "2022-02-11T16:47:24.100803Z", "start_time": "2022-02-11T16:47:23.847968Z"}}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["temp1.png\n", "Uploading file /home/c3/jupyter_root_dir/scratch/Greg/ffmpeg/temp1.png to container [input]...\n", "SAS URL is: https://gregbatchstorage.blob.core.windows.net/input/temp1.png?se=2022-02-12T16%3A47%3A23Z&sp=rt&sv=2020-10-02&sr=b&sig=UMihWaw7w7dDw%2B4VeBlS6LSqxsvrvY/6XyWAhAbzdEs%3D\n", "temp2.png\n", "Uploading file /home/c3/jupyter_root_dir/scratch/Greg/ffmpeg/temp2.png to container [input]...\n", "SAS URL is: https://gregbatchstorage.blob.core.windows.net/input/temp2.png?se=2022-02-12T16%3A47%3A24Z&sp=rt&sv=2020-10-02&sr=b&sig=f7bti94NbfwopSoqGDyDiwNhXC2lC7t%2Bvy0T3JmnNy0%3D\n", "temp3.png\n", "Uploading file /home/c3/jupyter_root_dir/scratch/Greg/ffmpeg/temp3.png to container [input]...\n", "SAS URL is: https://gregbatchstorage.blob.core.windows.net/input/temp3.png?se=2022-02-12T16%3A47%3A24Z&sp=rt&sv=2020-10-02&sr=b&sig=Av1mSkDkLfKRLUPVQO6QhqCrwx5dNNYpdyXkBAryigU%3D\n", "temp4.png\n", "Uploading file /home/c3/jupyter_root_dir/scratch/Greg/ffmpeg/temp4.png to container [input]...\n", "SAS URL is: https://gregbatchstorage.blob.core.windows.net/input/temp4.png?se=2022-02-12T16%3A47%3A24Z&sp=rt&sv=2020-10-02&sr=b&sig=ZRMN4tOUWQiV%2BiEBsY8qyPYmg3NQcGjn1ul1AxX96dw%3D\n", "temp5.png\n", "Uploading file /home/c3/jupyter_root_dir/scratch/Greg/ffmpeg/temp5.png to container [input]...\n", "SAS URL is: https://gregbatchstorage.blob.core.windows.net/input/temp5.png?se=2022-02-12T16%3A47%3A24Z&sp=rt&sv=2020-10-02&sr=b&sig=rg%2Bsi70fNo7Hi/6/ok1%2B%2BTwS0LGnkgXWj1RiVsdMC0Y%3D\n", "temp6.png\n", "Uploading file /home/c3/jupyter_root_dir/scratch/Greg/ffmpeg/temp6.png to container [input]...\n", "SAS URL is: https://gregbatchstorage.blob.core.windows.net/input/temp6.png?se=2022-02-12T16%3A47%3A24Z&sp=rt&sv=2020-10-02&sr=b&sig=3oqfdXYnw/lohAvTdsVO7pd48mmE/I9/DbVEH9QMJBE%3D\n", "temp7.png\n", "Uploading file /home/c3/jupyter_root_dir/scratch/Greg/ffmpeg/temp7.png to container [input]...\n", "SAS URL is: https://gregbatchstorage.blob.core.windows.net/input/temp7.png?se=2022-02-12T16%3A47%3A24Z&sp=rt&sv=2020-10-02&sr=b&sig=Dp8RKHQK9xJzDSzuTuLjg%2BJv6cqtrx1ZZ2JhzstyK6M%3D\n", "temp8.png\n", "Uploading file /home/c3/jupyter_root_dir/scratch/Greg/ffmpeg/temp8.png to container [input]...\n", "SAS URL is: https://gregbatchstorage.blob.core.windows.net/input/temp8.png?se=2022-02-12T16%3A47%3A24Z&sp=rt&sv=2020-10-02&sr=b&sig=Uo5sd%2BHhMHVwVY030yiumte5Vxfjx%2BG1UD7oxeOMAko%3D\n", "temp9.png\n", "Uploading file /home/c3/jupyter_root_dir/scratch/Greg/ffmpeg/temp9.png to container [input]...\n", "SAS URL is: https://gregbatchstorage.blob.core.windows.net/input/temp9.png?se=2022-02-12T16%3A47%3A24Z&sp=rt&sv=2020-10-02&sr=b&sig=l%2B%2BS9r326Q/EVQH/GiaWmfbQ6Diyal6hJq%2BS8QRj2vo%3D\n", "SAS URL is: https://gregbatchstorage.blob.core.windows.net/output/?se=2022-02-12T16%3A47%3A24Z&sp=rt&sv=2020-10-02&sr=b&sig=hdq1AARmFv/23qlP33DzW27ilV63TbUBqGrLKckML7s%3D\n"]}], "source": ["if __name__ == '__main__':\n", "\n", "\n", "    # Create the blob client, for use in obtaining references to\n", "    # blob storage containers and uploading files to containers.\n", "\n", "    blob_service_client = BlobServiceClient(\n", "    account_url=\"https://{}.{}/\".format(\n", "        config._STORAGE_ACCOUNT_NAME,\n", "        config._STORAGE_ACCOUNT_DOMAIN\n", "    ),\n", "    credential=config._STORAGE_ACCOUNT_KEY\n", "    )\n", "# Use the blob client to create the containers in Azure Storage if they\n", "# don't yet exist.\n", "    input_container_name = 'input'\n", "    output_container_name = 'output'\n", "    \n", "    try:\n", "        blob_service_client.create_container(input_container_name)\n", "    except ResourceExistsError:\n", "        pass\n", "\n", "    try:\n", "        blob_service_client.create_container(output_container_name)\n", "    except ResourceExistsError:\n", "        pass\n", "    \n", "    # The collection of data files that are to be processed by the tasks.\n", "    input_directory_path = \"/home/c3/jupyter_root_dir/scratch/Greg/ffmpeg/\"\n", "    input_file_paths = [os.path.join(input_directory_path, 'temp1.png'),\n", "                       os.path.join(input_directory_path, 'temp2.png'),\n", "                       os.path.join(input_directory_path, 'temp3.png'),\n", "                       os.path.join(input_directory_path, 'temp4.png'),\n", "                       os.path.join(input_directory_path, 'temp5.png'),\n", "                       os.path.join(input_directory_path, 'temp6.png'),\n", "                       os.path.join(input_directory_path, 'temp7.png'),\n", "                       os.path.join(input_directory_path, 'temp8.png'),\n", "                       os.path.join(input_directory_path, 'temp9.png')\n", "                       ]\n", "\n", "    # Upload the data files.\n", "    input_files = [\n", "        upload_file_to_container(blob_service_client, input_container_name, file_path)\n", "        for file_path in input_file_paths]\n", "\n", "\n", "# Generate sas token for output\n", "    sas_token = generate_blob_sas(\n", "        config._STORAGE_ACCOUNT_NAME,\n", "        output_container_name,\n", "        \"\",\n", "        account_key=config._STORAGE_ACCOUNT_KEY,\n", "#        permission=BlobSasPermissions(read=True, add=True, create=True, write=True, delete=True, delete_previous_version=True, tag=True),\n", "        permission=BlobSasPermissions(read=True),\n", "        expiry=datetime.datetime.utcnow() + datetime.timedelta(hours=24)\n", "    )\n", "\n", "# Generate output container sas url to pass to task output parameters\n", "    output_container_sas_url = generate_sas_url(\n", "        config._STORAGE_ACCOUNT_NAME,\n", "        config._STORAGE_ACCOUNT_DOMAIN,\n", "        output_container_name,\n", "        \"\",\n", "        sas_token\n", "    )\n", "\n", "    # Create a Batch service client. We'll now be interacting with the Batch\n", "    # service in addition to Storage\n", "    credentials = SharedKeyCredentials(config._BATCH_ACCOUNT_NAME,\n", "        config._BATCH_ACCOUNT_KEY)\n", "\n", "    batch_client = BatchServiceClient(\n", "        credentials,\n", "        batch_url=config._BATCH_ACCOUNT_URL)\n"]}, {"cell_type": "code", "execution_count": 5, "id": "67cacbea", "metadata": {"ExecuteTime": {"end_time": "2022-02-11T16:47:24.107035Z", "start_time": "2022-02-11T16:47:24.102293Z"}}, "outputs": [], "source": ["def create_job(batch_service_client, job_id, pool_id):\n", "    \"\"\"\n", "    Creates a job with the specified ID, associated with the specified pool.\n", "\n", "    :param batch_service_client: A Batch service client.\n", "    :type batch_service_client: `azure.batch.BatchServiceClient`\n", "    :param str job_id: The ID for the job.\n", "    :param str pool_id: The ID for the pool.\n", "    \"\"\"\n", "    print('Creating job [{}]...'.format(job_id))\n", "\n", "    job = batchmodels.JobAddParameter(\n", "        id=job_id,\n", "        pool_info=batchmodels.PoolInformation(pool_id=pool_id))\n", "\n", "    batch_service_client.job.add(job)\n", "\n", "\n", "def print_batch_exception(batch_exception):\n", "    \"\"\"\n", "    Prints the contents of the specified Batch exception.\n", "\n", "    :param batch_exception:\n", "    \"\"\"\n", "    print('-------------------------------------------')\n", "    print('Exception encountered:')\n", "    if batch_exception.error and \\\n", "            batch_exception.error.message and \\\n", "            batch_exception.error.message.value:\n", "        print(batch_exception.error.message.value)\n", "        if batch_exception.error.values:\n", "            print()\n", "            for mesg in batch_exception.error.values:\n", "                print('{}:\\t{}'.format(mesg.key, mesg.value))\n", "    print('-------------------------------------------')"]}, {"cell_type": "code", "execution_count": 6, "id": "f6616cdb", "metadata": {"ExecuteTime": {"end_time": "2022-02-11T16:47:24.293915Z", "start_time": "2022-02-11T16:47:24.108109Z"}}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Creating job [LinuxFfmpegJob]...\n"]}], "source": ["    try:\n", "        # Create the job that will run the tasks.\n", "        create_job(batch_client, config._JOB_ID, config._POOL_ID)\n", "\n", "    except batchmodels.BatchErrorException as err:\n", "        print_batch_exception(err)\n", "        raise"]}, {"cell_type": "code", "execution_count": 7, "id": "ac33bacc", "metadata": {"ExecuteTime": {"end_time": "2022-02-11T16:47:24.301399Z", "start_time": "2022-02-11T16:47:24.295590Z"}}, "outputs": [], "source": ["def add_tasks(batch_service_client, job_id, input_files, output_file_path, output_container_sas_url):\n", "    \"\"\"\n", "    Adds a task for each input file in the collection to the specified job.\n", "\n", "    :param batch_service_client: A Batch service client.\n", "    :type batch_service_client: `azure.batch.BatchServiceClient`\n", "    :param str job_id: The ID of the job to which to add the tasks.\n", "    :param list input_files: A collection of input files. One task will be\n", "     created for each input file.\n", "    :param output_container_sas_token: A SAS token granting write access to\n", "    the specified Azure Blob storage container.\n", "    \"\"\"\n", "\n", "    print('Adding {} files to job [{}]...'.format(len(input_files), job_id))\n", "\n", "    tasks = list()\n", "    \n", "    input_file_list = []\n", "    for idx, input_file in enumerate(input_files):\n", "        input_file_list.append(input_file)\n", "\n", "    #command = \"/bin/bash -c \\\"pwd; ffmpeg -framerate 2 -i temp%01d.png output.mp4 2>&1; ls -Fal\\\"\"\n", "    command = \"/bin/bash -c \\\"ffmpeg -framerate 2 -i temp%01d.png output.mp4 2>&1; ls -Fal\\\"\"\n", "    tasks.append(batchmodels.TaskAddParameter(\n", "        id='Task0',\n", "        command_line=command,\n", "        resource_files=input_file_list,\n", "            output_files=[batchmodels.OutputFile(\n", "#                file_pattern=output_file_path,\n", "                file_pattern=\"*\",\n", "                destination=batchmodels.OutputFileDestination(\n", "                          container=batchmodels.OutputFileBlobContainerDestination(\n", "                              container_url=output_container_sas_url)),\n", "                upload_options=batchmodels.OutputFileUploadOptions(\n", "                    upload_condition=batchmodels.OutputFileUploadCondition.task_success))]\n", "    )\n", "    )\n", "    batch_service_client.task.add_collection(job_id, tasks)"]}, {"cell_type": "code", "execution_count": 8, "id": "748c1cdc", "metadata": {"ExecuteTime": {"end_time": "2022-02-11T16:47:24.349241Z", "start_time": "2022-02-11T16:47:24.302601Z"}}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Adding 9 files to job [LinuxFfmpegJob]...\n"]}], "source": ["\n", "        # Add the tasks to the job. Pass the input files and a SAS URL\n", "        # to the storage container for output files.\n", "        add_tasks(batch_client, config._JOB_ID, input_files, \"*\", output_container_sas_url)"]}, {"cell_type": "code", "execution_count": null, "id": "1dd7b6a8", "metadata": {}, "outputs": [], "source": []}, {"cell_type": "code", "execution_count": null, "id": "132d6bcd", "metadata": {}, "outputs": [], "source": []}, {"cell_type": "code", "execution_count": null, "id": "7724c565", "metadata": {}, "outputs": [], "source": []}, {"cell_type": "markdown", "id": "ef0be099", "metadata": {"ExecuteTime": {"end_time": "2021-12-21T18:50:30.206425Z", "start_time": "2021-12-21T18:50:30.202341Z"}}, "source": ["\n", "\n", "\n", "        # Pause execution until tasks reach Completed state.\n", "        wait_for_tasks_to_complete(batch_client,\n", "                                   config._JOB_ID,\n", "                                   datetime.timedelta(minutes=30))\n", "\n", "        print(\"  Success! All tasks reached the 'Completed' state within the \"\n", "              \"specified timeout period.\")\n", "\n", "\n", "\n", "    # Delete input container in storage\n", "    print('Deleting container [{}]...'.format(input_container_name))\n", "    blob_client.delete_container(input_container_name)\n", "\n", "    # Clean up Batch resources (if the user so chooses).\n", "    if query_yes_no('Delete job?') == 'yes':\n", "        batch_client.job.delete(config._JOB_ID)\n", "\n", "    if query_yes_no('Delete pool?') == 'yes':\n", "        batch_client.pool.delete(config._POOL_ID)\n", "\n", "    print()\n", "    input('Press ENTER to exit...')"]}, {"cell_type": "code", "execution_count": null, "id": "dd8d9c34", "metadata": {}, "outputs": [], "source": []}], "metadata": {"has_local_update": false, "is_local": true, "is_remote": true, "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.8.10"}, "last_sync_time": "2022-02-23T17:42:28.249013"}, "nbformat": 4, "nbformat_minor": 5}