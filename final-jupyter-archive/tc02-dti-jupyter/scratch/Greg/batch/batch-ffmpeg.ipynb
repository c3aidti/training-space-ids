{"cells": [{"cell_type": "code", "execution_count": 73, "id": "5046b791", "metadata": {"ExecuteTime": {"end_time": "2021-11-30T23:00:42.042872Z", "start_time": "2021-11-30T23:00:42.039774Z"}}, "outputs": [], "source": ["from __future__ import print_function\n", "import datetime\n", "import io\n", "import os\n", "import sys\n", "import time\n"]}, {"cell_type": "code", "execution_count": 74, "id": "71598cbf", "metadata": {"ExecuteTime": {"end_time": "2021-11-30T23:00:43.625402Z", "start_time": "2021-11-30T23:00:42.045007Z"}}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Defaulting to user installation because normal site-packages is not writeable\n", "Requirement already satisfied: config in /home/c3/.local/lib/python3.8/site-packages (0.5.1)\n"]}], "source": ["!pip install config\n"]}, {"cell_type": "code", "execution_count": 75, "id": "0d6756cb", "metadata": {"ExecuteTime": {"end_time": "2021-11-30T23:00:43.630164Z", "start_time": "2021-11-30T23:00:43.627765Z"}}, "outputs": [], "source": ["sys.path.append('/home/c3/.local/lib/python3.7/site-packages/')\n", "import config"]}, {"cell_type": "code", "execution_count": 76, "id": "5a06c3b3", "metadata": {"ExecuteTime": {"end_time": "2021-11-30T23:00:43.963524Z", "start_time": "2021-11-30T23:00:43.631601Z"}}, "outputs": [{"data": {"text/plain": ["'koz8n5TKez2RR0hPOWsBR4w/PImkt4yztB7PyVJi99EmxAybu+/U9j+vubTYi280AnqE+DrPLsklG/zY/3bgnQ=='"]}, "execution_count": 76, "metadata": {}, "output_type": "execute_result"}], "source": ["bar = config._BATCH_ACCOUNT_KEY\n", "type(bar)\n", "bar"]}, {"cell_type": "raw", "id": "2c672302", "metadata": {}, "source": ["try:\n", "    input = raw_input\n", "except NameError:\n", "    pass"]}, {"cell_type": "code", "execution_count": 77, "id": "b49a41ab", "metadata": {"ExecuteTime": {"end_time": "2021-11-30T23:00:44.403800Z", "start_time": "2021-11-30T23:00:43.964822Z"}}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["/home/c3/jupyter_root_dir/scratch/Greg/batch\r\n"]}], "source": ["!pwd"]}, {"cell_type": "code", "execution_count": 78, "id": "ad56dcf9", "metadata": {"ExecuteTime": {"end_time": "2021-11-30T23:00:44.407636Z", "start_time": "2021-11-30T23:00:44.405566Z"}}, "outputs": [], "source": ["#!pip install azure-batch==11.0.0\n", "#!pip install azure-storage-blob==12.8.1\n", "\n"]}, {"cell_type": "code", "execution_count": 79, "id": "0febf5b0", "metadata": {"ExecuteTime": {"end_time": "2021-11-30T23:00:44.439624Z", "start_time": "2021-11-30T23:00:44.408809Z"}}, "outputs": [], "source": ["from azure.core.exceptions import ResourceExistsError\n", "\n", "from azure.storage.blob import (\n", "    BlobServiceClient,\n", "    BlobSasPermissions,\n", "    generate_blob_sas\n", ")\n", "\n", "from azure.batch import BatchServiceClient\n", "from azure.batch.batch_auth import SharedKeyCredentials\n", "import azure.batch.models as batchmodels"]}, {"cell_type": "code", "execution_count": null, "id": "36ed3d40", "metadata": {}, "outputs": [], "source": []}, {"cell_type": "code", "execution_count": 80, "id": "c108aec7", "metadata": {"ExecuteTime": {"end_time": "2021-11-30T23:00:44.463752Z", "start_time": "2021-11-30T23:00:44.441430Z"}, "code_folding": [7]}, "outputs": [], "source": ["\n", "\n", "\n", "# Update the Batch and Storage account credential strings in config.py with values\n", "# unique to your accounts. These are used when constructing connection strings\n", "# for the Batch and Storage client objects.\n", "\n", "def query_yes_no(question, default=\"yes\"):\n", "    \"\"\"\n", "    Prompts the user for yes/no input, displaying the specified question text.\n", "\n", "    :param str question: The text of the prompt for input.\n", "    :param str default: The default if the user hits <ENTER>. Acceptable values\n", "    are 'yes', 'no', and None.\n", "    :rtype: str\n", "    :return: 'yes' or 'no'\n", "    \"\"\"\n", "    valid = {'y': 'yes', 'n': 'no'}\n", "    if default is None:\n", "        prompt = ' [y/n] '\n", "    elif default == 'yes':\n", "        prompt = ' [Y/n] '\n", "    elif default == 'no':\n", "        prompt = ' [y/N] '\n", "    else:\n", "        raise ValueError(\"Invalid default answer: '{}'\".format(default))\n", "\n", "    while 1:\n", "        choice = input(question + prompt).lower()\n", "        if default and not choice:\n", "            return default\n", "        try:\n", "            return valid[choice[0]]\n", "        except (KeyError, IndexError):\n", "            print(\"Please respond with 'yes' or 'no' (or 'y' or 'n').\\n\")\n", "\n", "\n", "def print_batch_exception(batch_exception):\n", "    \"\"\"\n", "    Prints the contents of the specified Batch exception.\n", "\n", "    :param batch_exception:\n", "    \"\"\"\n", "    print('-------------------------------------------')\n", "    print('Exception encountered:')\n", "    if batch_exception.error and \\\n", "            batch_exception.error.message and \\\n", "            batch_exception.error.message.value:\n", "        print(batch_exception.error.message.value)\n", "        if batch_exception.error.values:\n", "            print()\n", "            for mesg in batch_exception.error.values:\n", "                print('{}:\\t{}'.format(mesg.key, mesg.value))\n", "    print('-------------------------------------------')\n", "\n", "\n", "def upload_file_to_container(blob_service_client, container_name, file_path):\n", "    \"\"\"\n", "    Uploads a local file to an Azure Blob storage container.\n", "\n", "    :param blob_service_client: A blob service client.\n", "    :type blob_service_client: `azure.storage.blob.BlobServiceClient`\n", "    :param str container_name: The name of the Azure Blob storage container.\n", "    :param str file_path: The local path to the file.\n", "    :rtype: `azure.batch.models.ResourceFile`\n", "    :return: A ResourceFile initialized with a SAS URL appropriate for Batch\n", "    tasks.\n", "    \"\"\"\n", "    blob_name = os.path.basename(file_path)\n", "    blob_client = blob_service_client.get_blob_client(container_name, blob_name)\n", "\n", "    print('Uploading file {} to container [{}]...'.format(file_path,\n", "                                                          container_name))\n", "\n", "    with open(file_path, \"rb\") as data:\n", "        blob_client.upload_blob(data, overwrite=True)\n", "\n", "    sas_token = generate_blob_sas(\n", "        config._STORAGE_ACCOUNT_NAME,\n", "        container_name,\n", "        blob_name,\n", "        account_key=config._STORAGE_ACCOUNT_KEY,\n", "        permission=BlobSasPermissions(read=True),\n", "        expiry=datetime.datetime.utcnow() + datetime.timedelta(hours=2)\n", "    )\n", "\n", "    sas_url = generate_sas_url(\n", "        config._STORAGE_ACCOUNT_NAME,\n", "        config._STORAGE_ACCOUNT_DOMAIN,\n", "        container_name,\n", "        blob_name,\n", "        sas_token\n", "    )\n", "\n", "    return batchmodels.ResourceFile(\n", "        http_url=sas_url,\n", "        file_path=blob_name\n", "    )\n", "\n", "\n", "def generate_sas_url(\n", "    account_name, account_domain, container_name, blob_name, sas_token\n", "):\n", "    return \"https://{}.{}/{}/{}?{}\".format(\n", "        account_name,\n", "        account_domain,\n", "        container_name,\n", "        blob_name,\n", "        sas_token\n", "    )\n", "\n", "\n", "\n", "def create_job(batch_service_client, job_id, pool_id):\n", "    \"\"\"\n", "    Creates a job with the specified ID, associated with the specified pool.\n", "\n", "    :param batch_service_client: A Batch service client.\n", "    :type batch_service_client: `azure.batch.BatchServiceClient`\n", "    :param str job_id: The ID for the job.\n", "    :param str pool_id: The ID for the pool.\n", "    \"\"\"\n", "    print('Creating job [{}]...'.format(job_id))\n", "\n", "    job = batchmodels.JobAddParameter(\n", "        id=job_id,\n", "        pool_info=batchmodels.PoolInformation(pool_id=pool_id))\n", "\n", "    batch_service_client.job.add(job)\n", "\n", "\n", "def add_tasks(batch_service_client, job_id, input_files):\n", "    \"\"\"\n", "    Adds a task for each input file in the collection to the specified job.\n", "\n", "    :param batch_service_client: A Batch service client.\n", "    :type batch_service_client: `azure.batch.BatchServiceClient`\n", "    :param str job_id: The ID of the job to which to add the tasks.\n", "    :param list input_files: A collection of input files. One task will be\n", "     created for each input file.\n", "    :param output_container_sas_token: A SAS token granting write access to\n", "    the specified Azure Blob storage container.\n", "    \"\"\"\n", "\n", "    print('Adding {} tasks to job [{}]...'.format(len(input_files), job_id))\n", "\n", "    tasks = list()\n", "\n", "    for idx, input_file in enumerate(input_files):\n", "\n", "        #command = \"/bin/bash -c \\\"/usr/bin/python3 /opt/ibm/ILOG/CPLEX_Studio201/cplex/examples/src/python/cutstock.py {}\\\"\".format(input_file.file_path)\n", "        command = \"/bin/bash -c \\\"which apt; sudo apt --yes install ffmpeg; ffmpeg -version; pwd\\\"\"\n", "        tasks.append(batchmodels.TaskAddParameter(\n", "            id='Task{}'.format(idx),\n", "            command_line=command,\n", "            resource_files=[input_file]\n", "        )\n", "        )\n", "\n", "    batch_service_client.task.add_collection(job_id, tasks)\n", "\n", "\n", "def wait_for_tasks_to_complete(batch_service_client, job_id, timeout):\n", "    \"\"\"\n", "    Returns when all tasks in the specified job reach the Completed state.\n", "\n", "    :param batch_service_client: A Batch service client.\n", "    :type batch_service_client: `azure.batch.BatchServiceClient`\n", "    :param str job_id: The id of the job whose tasks should be to monitored.\n", "    :param timedelta timeout: The duration to wait for task completion. If all\n", "    tasks in the specified job do not reach Completed state within this time\n", "    period, an exception will be raised.\n", "    \"\"\"\n", "    timeout_expiration = datetime.datetime.now() + timeout\n", "\n", "    print(\"Monitoring all tasks for 'Completed' state, timeout in {}...\"\n", "          .format(timeout), end='')\n", "\n", "    while datetime.datetime.now() < timeout_expiration:\n", "        print('.', end='')\n", "        sys.stdout.flush()\n", "        tasks = batch_service_client.task.list(job_id)\n", "\n", "        incomplete_tasks = [task for task in tasks if\n", "                            task.state != batchmodels.TaskState.completed]\n", "        if not incomplete_tasks:\n", "            print()\n", "            return True\n", "        else:\n", "            time.sleep(1)\n", "\n", "    print()\n", "    raise RuntimeError(\"ERROR: Tasks did not reach 'Completed' state within \"\n", "                       \"timeout period of \" + str(timeout))\n", "\n", "\n", "def print_task_output(batch_service_client, job_id, encoding=None):\n", "    \"\"\"\n", "    Prints the stdout.txt file for each task in the job.\n", "\n", "    :param batch_client: The batch client to use.\n", "    :type batch_client: `batchserviceclient.BatchServiceClient`\n", "    :param str job_id: The id of the job with task output files to print.\n", "    \"\"\"\n", "\n", "    print('Printing task output...')\n", "\n", "    tasks = batch_service_client.task.list(job_id)\n", "\n", "    for task in tasks:\n", "\n", "        node_id = batch_service_client.task.get(\n", "            job_id, task.id).node_info.node_id\n", "        print(\"Task: {}\".format(task.id))\n", "        print(\"Node: {}\".format(node_id))\n", "\n", "        stream = batch_service_client.file.get_from_task(\n", "            job_id, task.id, config._STANDARD_OUT_FILE_NAME)\n", "\n", "        file_text = _read_stream_as_string(\n", "            stream,\n", "            encoding)\n", "        print(\"Standard output:\")\n", "        print(file_text)\n", "\n", "\n", "def _read_stream_as_string(stream, encoding):\n", "    \"\"\"\n", "    Read stream as string\n", "\n", "    :param stream: input stream generator\n", "    :param str encoding: The encoding of the file. The default is utf-8.\n", "    :return: The file content.\n", "    :rtype: str\n", "    \"\"\"\n", "    output = io.BytesIO()\n", "    try:\n", "        for data in stream:\n", "            output.write(data)\n", "        if encoding is None:\n", "            encoding = 'utf-8'\n", "        return output.getvalue().decode(encoding)\n", "    finally:\n", "        output.close()"]}, {"cell_type": "code", "execution_count": null, "id": "d8a07310", "metadata": {"ExecuteTime": {"start_time": "2021-11-30T23:00:41.889Z"}}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Sample start: 2021-11-30 23:00:44\n", "\n", "Uploading file /home/c3/jupyter_root_dir/scratch/Greg/batch/cutstock0.dat to container [input3]...\n", "Uploading file /home/c3/jupyter_root_dir/scratch/Greg/batch/cutstock1.dat to container [input3]...\n", "Uploading file /home/c3/jupyter_root_dir/scratch/Greg/batch/cutstock2.dat to container [input3]...\n", "Uploading file /home/c3/jupyter_root_dir/scratch/Greg/batch/cutstock3.dat to container [input3]...\n", "Uploading file /home/c3/jupyter_root_dir/scratch/Greg/batch/cutstock4.dat to container [input3]...\n", "Uploading file /home/c3/jupyter_root_dir/scratch/Greg/batch/cutstock5.dat to container [input3]...\n", "Uploading file /home/c3/jupyter_root_dir/scratch/Greg/batch/cutstock6.dat to container [input3]...\n", "Uploading file /home/c3/jupyter_root_dir/scratch/Greg/batch/cutstock7.dat to container [input3]...\n", "Uploading file /home/c3/jupyter_root_dir/scratch/Greg/batch/cutstock8.dat to container [input3]...\n", "Uploading file /home/c3/jupyter_root_dir/scratch/Greg/batch/cutstock9.dat to container [input3]...\n", "Creating job [PythonQuickstartJob4]...\n", "Adding 10 tasks to job [PythonQuickstartJob4]...\n", "Monitoring all tasks for 'Completed' state, timeout in 0:30:00................................\n", "  Success! All tasks reached the 'Completed' state within the specified timeout period.\n", "Printing task output...\n", "Task: Task0\n", "Node: tvmps_0bcb20f9988c7ae08f90f9d0c276ab5674b099ede4d090dbcf000c98d0fe383a_d\n", "Standard output:\n", "/usr/bin/apt\n", "/mnt/batch/tasks/workitems/PythonQuickstartJob4/job-1/Task0/wd\n", "\n", "Task: Task1\n", "Node: tvmps_0bcb20f9988c7ae08f90f9d0c276ab5674b099ede4d090dbcf000c98d0fe383a_d\n", "Standard output:\n", "/usr/bin/apt\n", "/mnt/batch/tasks/workitems/PythonQuickstartJob4/job-1/Task1/wd\n", "\n", "Task: Task2\n", "Node: tvmps_0bcb20f9988c7ae08f90f9d0c276ab5674b099ede4d090dbcf000c98d0fe383a_d\n", "Standard output:\n", "/usr/bin/apt\n", "/mnt/batch/tasks/workitems/PythonQuickstartJob4/job-1/Task2/wd\n", "\n", "Task: Task3\n", "Node: tvmps_0bcb20f9988c7ae08f90f9d0c276ab5674b099ede4d090dbcf000c98d0fe383a_d\n", "Standard output:\n", "/usr/bin/apt\n", "/mnt/batch/tasks/workitems/PythonQuickstartJob4/job-1/Task3/wd\n", "\n", "Task: Task4\n", "Node: tvmps_0bcb20f9988c7ae08f90f9d0c276ab5674b099ede4d090dbcf000c98d0fe383a_d\n", "Standard output:\n", "/usr/bin/apt\n", "/mnt/batch/tasks/workitems/PythonQuickstartJob4/job-1/Task4/wd\n", "\n", "Task: Task5\n", "Node: tvmps_0bcb20f9988c7ae08f90f9d0c276ab5674b099ede4d090dbcf000c98d0fe383a_d\n", "Standard output:\n", "/usr/bin/apt\n", "/mnt/batch/tasks/workitems/PythonQuickstartJob4/job-1/Task5/wd\n", "\n", "Task: Task6\n", "Node: tvmps_0bcb20f9988c7ae08f90f9d0c276ab5674b099ede4d090dbcf000c98d0fe383a_d\n", "Standard output:\n", "/usr/bin/apt\n", "/mnt/batch/tasks/workitems/PythonQuickstartJob4/job-1/Task6/wd\n", "\n", "Task: Task7\n", "Node: tvmps_0bcb20f9988c7ae08f90f9d0c276ab5674b099ede4d090dbcf000c98d0fe383a_d\n", "Standard output:\n", "/usr/bin/apt\n", "/mnt/batch/tasks/workitems/PythonQuickstartJob4/job-1/Task7/wd\n", "\n", "Task: Task8\n", "Node: tvmps_0bcb20f9988c7ae08f90f9d0c276ab5674b099ede4d090dbcf000c98d0fe383a_d\n", "Standard output:\n", "/usr/bin/apt\n", "/mnt/batch/tasks/workitems/PythonQuickstartJob4/job-1/Task8/wd\n", "\n", "Task: Task9\n", "Node: tvmps_0bcb20f9988c7ae08f90f9d0c276ab5674b099ede4d090dbcf000c98d0fe383a_d\n", "Standard output:\n", "/usr/bin/apt\n", "/mnt/batch/tasks/workitems/PythonQuickstartJob4/job-1/Task9/wd\n", "\n", "Deleting container [input3]...\n", "\n", "Sample end: 2021-11-30 23:01:14\n", "Elapsed time: 0:00:30\n", "\n"]}], "source": ["if __name__ == '__main__':\n", "\n", "    start_time = datetime.datetime.now().replace(microsecond=0)\n", "    print('Sample start: {}'.format(start_time))\n", "    print()\n", "\n", "    # Create the blob client, for use in obtaining references to\n", "    # blob storage containers and uploading files to containers.\n", "    blob_service_client = BlobServiceClient(\n", "        account_url=\"https://{}.{}/\".format(\n", "            config._STORAGE_ACCOUNT_NAME,\n", "            config._STORAGE_ACCOUNT_DOMAIN\n", "        ),\n", "        credential=config._STORAGE_ACCOUNT_KEY\n", "    )\n", "\n", "    # Use the blob client to create the containers in Azure Storage if they\n", "    # don't yet exist.\n", "    input_container_name = 'input3'\n", "    try:\n", "        blob_service_client.create_container(input_container_name)\n", "    except ResourceExistsError:\n", "        pass\n", "\n", "    # The collection of data files that are to be processed by the tasks.\n", "    input_file_paths = [os.path.join('/home/c3/jupyter_root_dir/scratch/Greg/batch/', 'cutstock0.dat'),\n", "                        os.path.join('/home/c3/jupyter_root_dir/scratch/Greg/batch/', 'cutstock1.dat'),\n", "                        os.path.join('/home/c3/jupyter_root_dir/scratch/Greg/batch/', 'cutstock2.dat'),\n", "                        os.path.join('/home/c3/jupyter_root_dir/scratch/Greg/batch/', 'cutstock3.dat'),\n", "                        os.path.join('/home/c3/jupyter_root_dir/scratch/Greg/batch/', 'cutstock4.dat'),\n", "                        os.path.join('/home/c3/jupyter_root_dir/scratch/Greg/batch/', 'cutstock5.dat'),\n", "                        os.path.join('/home/c3/jupyter_root_dir/scratch/Greg/batch/', 'cutstock6.dat'),\n", "                        os.path.join('/home/c3/jupyter_root_dir/scratch/Greg/batch/', 'cutstock7.dat'),\n", "                        os.path.join('/home/c3/jupyter_root_dir/scratch/Greg/batch/', 'cutstock8.dat'),\n", "                        os.path.join('/home/c3/jupyter_root_dir/scratch/Greg/batch/', 'cutstock9.dat')]\n", "\n", "    # Upload the data files.\n", "    input_files = [\n", "        upload_file_to_container(blob_service_client, input_container_name, file_path)\n", "        for file_path in input_file_paths]\n", "\n", "    # Create a Batch service client. We'll now be interacting with the Batch\n", "    # service in addition to Storage\n", "    credentials = SharedKeyCredentials(config._BATCH_ACCOUNT_NAME,\n", "        config._BATCH_ACCOUNT_KEY)\n", "\n", "    batch_client = BatchServiceClient(\n", "        credentials,\n", "        batch_url=config._BATCH_ACCOUNT_URL)\n", "\n", "    try:\n", "        ## Create the pool that will contain the compute nodes that will execute the\n", "        ## tasks.\n", "        #create_pool(batch_client, config._POOL_ID)\n", "\n", "        # Create the job that will run the tasks.\n", "        create_job(batch_client, config._JOB_ID, config._POOL_ID)\n", "\n", "        # Add the tasks to the job.\n", "        add_tasks(batch_client, config._JOB_ID, input_files)\n", "\n", "        # Pause execution until tasks reach Completed state.\n", "        wait_for_tasks_to_complete(batch_client,\n", "                                   config._JOB_ID,\n", "                                   datetime.timedelta(minutes=30))\n", "\n", "        print(\"  Success! All tasks reached the 'Completed' state within the \"\n", "              \"specified timeout period.\")\n", "\n", "        # Print the stdout.txt and stderr.txt files for each task to the console\n", "        print_task_output(batch_client, config._JOB_ID)\n", "\n", "    except batchmodels.BatchErrorException as err:\n", "        print_batch_exception(err)\n", "        raise\n", "\n", "    # Clean up storage resources\n", "    print('Deleting container [{}]...'.format(input_container_name))\n", "    blob_service_client.delete_container(input_container_name)\n", "\n", "    # Print out some timing info\n", "    end_time = datetime.datetime.now().replace(microsecond=0)\n", "    print()\n", "    print('Sample end: {}'.format(end_time))\n", "    print('Elapsed time: {}'.format(end_time - start_time))\n", "    print()\n", "\n", "    # Clean up Batch resources (if the user so chooses).\n", "    if query_yes_no('Delete job?') == 'yes':\n", "        batch_client.job.delete(config._JOB_ID)\n", "\n", "    #if query_yes_no('Delete pool?') == 'yes':\n", "    #    batch_client.pool.delete(config._POOL_ID)\n", "\n", "    print()\n", "    input('Press ENTER to exit...')"]}, {"cell_type": "code", "execution_count": null, "id": "993f2862", "metadata": {}, "outputs": [], "source": []}], "metadata": {"has_local_update": false, "is_local": true, "is_remote": true, "kernelspec": {"display_name": "py-py-greg-azure-ids", "language": "Python", "name": "py-py-greg-azure-ids"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.13"}, "last_sync_time": "2021-11-30T20:35:14.100891"}, "nbformat": 4, "nbformat_minor": 5}