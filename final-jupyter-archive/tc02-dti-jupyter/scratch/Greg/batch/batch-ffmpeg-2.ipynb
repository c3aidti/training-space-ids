{"cells": [{"cell_type": "code", "execution_count": 33, "id": "7126b2a1", "metadata": {"ExecuteTime": {"end_time": "2021-12-03T00:56:44.958482Z", "start_time": "2021-12-03T00:56:44.955381Z"}}, "outputs": [], "source": ["from __future__ import print_function\n", "import datetime\n", "import io\n", "import os\n", "import sys\n", "import time\n"]}, {"cell_type": "code", "execution_count": 34, "id": "dbbe475e", "metadata": {"ExecuteTime": {"end_time": "2021-12-03T00:56:46.219623Z", "start_time": "2021-12-03T00:56:44.960076Z"}}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Defaulting to user installation because normal site-packages is not writeable\r\n", "Requirement already satisfied: config in /home/c3/.local/lib/python3.8/site-packages (0.5.1)\r\n"]}], "source": ["!pip install config\n"]}, {"cell_type": "code", "execution_count": 35, "id": "fca674a3", "metadata": {"ExecuteTime": {"end_time": "2021-12-03T00:56:46.226453Z", "start_time": "2021-12-03T00:56:46.222926Z"}}, "outputs": [], "source": ["sys.path.append('/home/c3/.local/lib/python3.7/site-packages/')\n", "import config"]}, {"cell_type": "code", "execution_count": 36, "id": "98b8120b", "metadata": {"ExecuteTime": {"end_time": "2021-12-03T00:56:46.250107Z", "start_time": "2021-12-03T00:56:46.228865Z"}}, "outputs": [{"data": {"text/plain": ["'koz8n5TKez2RR0hPOWsBR4w/PImkt4yztB7PyVJi99EmxAybu+/U9j+vubTYi280AnqE+DrPLsklG/zY/3bgnQ=='"]}, "execution_count": 36, "metadata": {}, "output_type": "execute_result"}], "source": ["bar = config._BATCH_ACCOUNT_KEY\n", "type(bar)\n", "bar"]}, {"cell_type": "raw", "id": "19b3f50e", "metadata": {}, "source": ["try:\n", "    input = raw_input\n", "except NameError:\n", "    pass"]}, {"cell_type": "code", "execution_count": 37, "id": "a17a07d5", "metadata": {"ExecuteTime": {"end_time": "2021-12-03T00:56:46.681471Z", "start_time": "2021-12-03T00:56:46.251287Z"}}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["/home/c3/jupyter_root_dir/scratch/Greg/batch\r\n"]}], "source": ["!pwd"]}, {"cell_type": "code", "execution_count": 38, "id": "01523ae7", "metadata": {"ExecuteTime": {"end_time": "2021-12-03T00:56:46.687659Z", "start_time": "2021-12-03T00:56:46.683830Z"}}, "outputs": [], "source": ["#!pip install azure-batch==11.0.0\n", "#!pip install azure-storage-blob==12.8.1\n", "from azure.core.exceptions import ResourceExistsError\n", "\n", "from azure.storage.blob import (\n", "    BlobServiceClient,\n", "    BlobSasPermissions,\n", "    generate_blob_sas\n", ")\n", "\n", "from azure.batch import BatchServiceClient\n", "from azure.batch.batch_auth import SharedKeyCredentials\n", "import azure.batch.models as batchmodels"]}, {"cell_type": "code", "execution_count": null, "id": "278ae60e", "metadata": {}, "outputs": [], "source": []}, {"cell_type": "code", "execution_count": 39, "id": "1b003e8d", "metadata": {"ExecuteTime": {"end_time": "2021-12-03T00:56:46.711100Z", "start_time": "2021-12-03T00:56:46.688958Z"}, "code_folding": [7, 37, 100, 102, 103, 129]}, "outputs": [], "source": ["\n", "\n", "\n", "# Update the Batch and Storage account credential strings in config.py with values\n", "# unique to your accounts. These are used when constructing connection strings\n", "# for the Batch and Storage client objects.\n", "\n", "def query_yes_no(question, default=\"yes\"):\n", "    \"\"\"\n", "    Prompts the user for yes/no input, displaying the specified question text.\n", "\n", "    :param str question: The text of the prompt for input.\n", "    :param str default: The default if the user hits <ENTER>. Acceptable values\n", "    are 'yes', 'no', and None.\n", "    :rtype: str\n", "    :return: 'yes' or 'no'\n", "    \"\"\"\n", "    valid = {'y': 'yes', 'n': 'no'}\n", "    if default is None:\n", "        prompt = ' [y/n] '\n", "    elif default == 'yes':\n", "        prompt = ' [Y/n] '\n", "    elif default == 'no':\n", "        prompt = ' [y/N] '\n", "    else:\n", "        raise ValueError(\"Invalid default answer: '{}'\".format(default))\n", "\n", "    while 1:\n", "        choice = input(question + prompt).lower()\n", "        if default and not choice:\n", "            return default\n", "        try:\n", "            return valid[choice[0]]\n", "        except (KeyError, IndexError):\n", "            print(\"Please respond with 'yes' or 'no' (or 'y' or 'n').\\n\")\n", "\n", "\n", "def print_batch_exception(batch_exception):\n", "    \"\"\"\n", "    Prints the contents of the specified Batch exception.\n", "\n", "    :param batch_exception:\n", "    \"\"\"\n", "    print('-------------------------------------------')\n", "    print('Exception encountered:')\n", "    if batch_exception.error and \\\n", "            batch_exception.error.message and \\\n", "            batch_exception.error.message.value:\n", "        print(batch_exception.error.message.value)\n", "        if batch_exception.error.values:\n", "            print()\n", "            for mesg in batch_exception.error.values:\n", "                print('{}:\\t{}'.format(mesg.key, mesg.value))\n", "    print('-------------------------------------------')\n", "\n", "\n", "def upload_file_to_container(blob_service_client, container_name, file_path):\n", "    \"\"\"\n", "    Uploads a local file to an Azure Blob storage container.\n", "\n", "    :param blob_service_client: A blob service client.\n", "    :type blob_service_client: `azure.storage.blob.BlobServiceClient`\n", "    :param str container_name: The name of the Azure Blob storage container.\n", "    :param str file_path: The local path to the file.\n", "    :rtype: `azure.batch.models.ResourceFile`\n", "    :return: A ResourceFile initialized with a SAS URL appropriate for Batch\n", "    tasks.\n", "    \"\"\"\n", "    blob_name = os.path.basename(file_path)\n", "    blob_client = blob_service_client.get_blob_client(container_name, blob_name)\n", "\n", "    print('Uploading file {} to container [{}]...'.format(file_path,\n", "                                                          container_name))\n", "\n", "    with open(file_path, \"rb\") as data:\n", "        blob_client.upload_blob(data, overwrite=True)\n", "\n", "    sas_token = generate_blob_sas(\n", "        config._STORAGE_ACCOUNT_NAME,\n", "        container_name,\n", "        blob_name,\n", "        account_key=config._STORAGE_ACCOUNT_KEY,\n", "        permission=BlobSasPermissions(read=True),\n", "        expiry=datetime.datetime.utcnow() + datetime.timedelta(hours=2)\n", "    )\n", "\n", "    sas_url = generate_sas_url(\n", "        config._STORAGE_ACCOUNT_NAME,\n", "        config._STORAGE_ACCOUNT_DOMAIN,\n", "        container_name,\n", "        blob_name,\n", "        sas_token\n", "    )\n", "\n", "    return batchmodels.ResourceFile(\n", "        http_url=sas_url,\n", "        file_path=blob_name\n", "    )\n", "\n", "\n", "def generate_sas_url(\n", "    account_name, account_domain, container_name, blob_name, sas_token\n", "):\n", "    return \"https://{}.{}/{}/{}?{}\".format(\n", "        account_name,\n", "        account_domain,\n", "        container_name,\n", "        blob_name,\n", "        sas_token\n", "    )\n", "\n", "\n", "def create_pool(batch_service_client, pool_id):\n", "    \"\"\"\n", "    Creates a pool of compute nodes with the specified OS settings.\n", "\n", "    :param batch_service_client: A Batch service client.\n", "    :type batch_service_client: `azure.batch.BatchServiceClient`\n", "    :param str pool_id: An ID for the new pool.\n", "    :param str publisher: Marketplace image publisher\n", "    :param str offer: Marketplace image offer\n", "    :param str sku: Marketplace image sku\n", "    \"\"\"\n", "    print('Creating pool [{}]...'.format(pool_id))\n", "\n", "    # Create a new pool of Linux compute nodes using an Azure Virtual Machines\n", "    # Marketplace image. For more information about creating pools of Linux\n", "    # nodes, see:\n", "    # https://azure.microsoft.com/documentation/articles/batch-linux-nodes/\n", "    new_pool = batchmodels.PoolAddParameter(\n", "        id=pool_id,\n", "        virtual_machine_configuration=batchmodels.VirtualMachineConfiguration(\n", "            image_reference=batchmodels.ImageReference(\n", "#                publisher=\"canonical\",\n", "#                offer=\"0001-com-ubuntu-server-focal\",\n", "#                sku=\"20_04-lts\",\n", "#                version=\"latest\"\n", "                publisher = \"microsoft-dsvm\",\n", "                offer = \"ubuntu-1804\",\n", "                sku = \"1804\",\n", "                version = \"latest\"\n", "            ),\n", "            node_agent_sku_id=\"batch.node.ubuntu 20.04\"),\n", "        vm_size=config._POOL_VM_SIZE,\n", "        target_dedicated_nodes=config._POOL_NODE_COUNT,\n", "        start_task=batchmodels.StartTask(\n", "            command_line=\"/bin/bash -c \\\"apt-get update && apt-get install -y ffmpeg\\\"\",\n", "            wait_for_success=True,\n", "            user_identity=batchmodels.UserIdentity(\n", "                auto_user=batchmodels.AutoUserSpecification(\n", "                    scope=batchmodels.AutoUserScope.pool,\n", "                    elevation_level=batchmodels.ElevationLevel.admin)),\n", "        )\n", "    )\n", "    batch_service_client.pool.add(new_pool)\n", "\n", "\n", "def create_job(batch_service_client, job_id, pool_id):\n", "    \"\"\"\n", "    Creates a job with the specified ID, associated with the specified pool.\n", "\n", "    :param batch_service_client: A Batch service client.\n", "    :type batch_service_client: `azure.batch.BatchServiceClient`\n", "    :param str job_id: The ID for the job.\n", "    :param str pool_id: The ID for the pool.\n", "    \"\"\"\n", "    print('Creating job [{}]...'.format(job_id))\n", "\n", "    job = batchmodels.JobAddParameter(\n", "        id=job_id,\n", "        pool_info=batchmodels.PoolInformation(pool_id=pool_id))\n", "\n", "    batch_service_client.job.add(job)\n", "\n", "\n", "def add_tasks(batch_service_client, job_id, input_files):\n", "    \"\"\"\n", "    Adds a task for each input file in the collection to the specified job.\n", "\n", "    :param batch_service_client: A Batch service client.\n", "    :type batch_service_client: `azure.batch.BatchServiceClient`\n", "    :param str job_id: The ID of the job to which to add the tasks.\n", "    :param list input_files: A collection of input files. One task will be\n", "     created for each input file.\n", "    :param output_container_sas_token: A SAS token granting write access to\n", "    the specified Azure Blob storage container.\n", "    \"\"\"\n", "\n", "    print('Adding {} files to job [{}]...'.format(len(input_files), job_id))\n", "\n", "    tasks = list()\n", "    \n", "    input_file_list = []\n", "    for idx, input_file in enumerate(input_files):\n", "        input_file_list.append(input_file)\n", "\n", "    #command = \"/bin/bash -c \\\"pwd; ffmpeg -framerate 2 -i temp%01d.png output.mp4 2>&1; ls -Fal\\\"\"\n", "    command = \"/bin/bash -c \\\"ffmpeg -framerate 2 -i temp%01d.png output.mp4 2>&1; ls -Fal\\\"\"\n", "    tasks.append(batchmodels.TaskAddParameter(\n", "        id='Task0',\n", "        command_line=command,\n", "        resource_files=input_file_list\n", "    )\n", "    )\n", "    batch_service_client.task.add_collection(job_id, tasks)\n", "\n", "\n", "def wait_for_tasks_to_complete(batch_service_client, job_id, timeout):\n", "    \"\"\"\n", "    Returns when all tasks in the specified job reach the Completed state.\n", "\n", "    :param batch_service_client: A Batch service client.\n", "    :type batch_service_client: `azure.batch.BatchServiceClient`\n", "    :param str job_id: The id of the job whose tasks should be to monitored.\n", "    :param timedelta timeout: The duration to wait for task completion. If all\n", "    tasks in the specified job do not reach Completed state within this time\n", "    period, an exception will be raised.\n", "    \"\"\"\n", "    timeout_expiration = datetime.datetime.now() + timeout\n", "\n", "    print(\"Monitoring all tasks for 'Completed' state, timeout in {}...\"\n", "          .format(timeout), end='')\n", "\n", "    while datetime.datetime.now() < timeout_expiration:\n", "        print('.', end='')\n", "        sys.stdout.flush()\n", "        tasks = batch_service_client.task.list(job_id)\n", "\n", "        incomplete_tasks = [task for task in tasks if\n", "                            task.state != batchmodels.TaskState.completed]\n", "        if not incomplete_tasks:\n", "            print()\n", "            return True\n", "        else:\n", "            time.sleep(1)\n", "\n", "    print()\n", "    raise RuntimeError(\"ERROR: Tasks did not reach 'Completed' state within \"\n", "                       \"timeout period of \" + str(timeout))\n", "\n", "\n", "def print_task_output(batch_service_client, job_id, encoding=None):\n", "    \"\"\"\n", "    Prints the stdout.txt file for each task in the job.\n", "\n", "    :param batch_client: The batch client to use.\n", "    :type batch_client: `batchserviceclient.BatchServiceClient`\n", "    :param str job_id: The id of the job with task output files to print.\n", "    \"\"\"\n", "\n", "    print('Printing task output...')\n", "\n", "    tasks = batch_service_client.task.list(job_id)\n", "\n", "    for task in tasks:\n", "\n", "        node_id = batch_service_client.task.get(\n", "            job_id, task.id).node_info.node_id\n", "        print(\"Task: {}\".format(task.id))\n", "        print(\"Node: {}\".format(node_id))\n", "\n", "        stream = batch_service_client.file.get_from_task(\n", "            job_id, task.id, config._STANDARD_OUT_FILE_NAME)\n", "\n", "        file_text = _read_stream_as_string(\n", "            stream,\n", "            encoding)\n", "        print(\"Standard output:\")\n", "        print(file_text)\n", "\n", "\n", "def _read_stream_as_string(stream, encoding):\n", "    \"\"\"\n", "    Read stream as string\n", "\n", "    :param stream: input stream generator\n", "    :param str encoding: The encoding of the file. The default is utf-8.\n", "    :return: The file content.\n", "    :rtype: str\n", "    \"\"\"\n", "    output = io.BytesIO()\n", "    try:\n", "        for data in stream:\n", "            output.write(data)\n", "        if encoding is None:\n", "            encoding = 'utf-8'\n", "        return output.getvalue().decode(encoding)\n", "    finally:\n", "        output.close()"]}, {"cell_type": "code", "execution_count": null, "id": "7b53f0ac", "metadata": {"ExecuteTime": {"start_time": "2021-12-03T00:56:44.881Z"}}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Sample start: 2021-12-03 00:56:46\n", "\n", "Uploading file /home/c3/jupyter_root_dir/scratch/Greg/batch/temp1.png to container [input]...\n", "Uploading file /home/c3/jupyter_root_dir/scratch/Greg/batch/temp2.png to container [input]...\n", "Uploading file /home/c3/jupyter_root_dir/scratch/Greg/batch/temp3.png to container [input]...\n", "Uploading file /home/c3/jupyter_root_dir/scratch/Greg/batch/temp4.png to container [input]...\n", "Uploading file /home/c3/jupyter_root_dir/scratch/Greg/batch/temp5.png to container [input]...\n", "Uploading file /home/c3/jupyter_root_dir/scratch/Greg/batch/temp6.png to container [input]...\n", "Uploading file /home/c3/jupyter_root_dir/scratch/Greg/batch/temp7.png to container [input]...\n", "Uploading file /home/c3/jupyter_root_dir/scratch/Greg/batch/temp8.png to container [input]...\n", "Uploading file /home/c3/jupyter_root_dir/scratch/Greg/batch/temp9.png to container [input]...\n", "Creating job [PythonQuickstartJobFfmpeg]...\n", "Adding 9 files to job [PythonQuickstartJobFfmpeg]...\n", "Monitoring all tasks for 'Completed' state, timeout in 0:30:00................................................................................................................................................................."]}], "source": ["\n", "\n", "\n", "if __name__ == '__main__':\n", "\n", "    start_time = datetime.datetime.now().replace(microsecond=0)\n", "    print('Sample start: {}'.format(start_time))\n", "    print()\n", "\n", "    # Create the blob client, for use in obtaining references to\n", "    # blob storage containers and uploading files to containers.\n", "    blob_service_client = BlobServiceClient(\n", "        account_url=\"https://{}.{}/\".format(\n", "            config._STORAGE_ACCOUNT_NAME,\n", "            config._STORAGE_ACCOUNT_DOMAIN\n", "        ),\n", "        credential=config._STORAGE_ACCOUNT_KEY\n", "    )\n", "\n", "    # Use the blob client to create the containers in Azure Storage if they\n", "    # don't yet exist.\n", "    input_container_name = 'input'\n", "    try:\n", "        blob_service_client.create_container(input_container_name)\n", "    except ResourceExistsError:\n", "        pass\n", "\n", "    # The collection of data files that are to be processed by the tasks.\n", "    input_file_paths = [os.path.join('/home/c3/jupyter_root_dir/scratch/Greg/batch/', 'temp1.png'),\n", "                       os.path.join('/home/c3/jupyter_root_dir/scratch/Greg/batch/', 'temp2.png'),\n", "                       os.path.join('/home/c3/jupyter_root_dir/scratch/Greg/batch/', 'temp3.png'),\n", "                       os.path.join('/home/c3/jupyter_root_dir/scratch/Greg/batch/', 'temp4.png'),\n", "                       os.path.join('/home/c3/jupyter_root_dir/scratch/Greg/batch/', 'temp5.png'),\n", "                       os.path.join('/home/c3/jupyter_root_dir/scratch/Greg/batch/', 'temp6.png'),\n", "                       os.path.join('/home/c3/jupyter_root_dir/scratch/Greg/batch/', 'temp7.png'),\n", "                       os.path.join('/home/c3/jupyter_root_dir/scratch/Greg/batch/', 'temp8.png'),\n", "                       os.path.join('/home/c3/jupyter_root_dir/scratch/Greg/batch/', 'temp9.png')\n", "                       ]\n", "\n", "    # Upload the data files.\n", "    input_files = [\n", "        upload_file_to_container(blob_service_client, input_container_name, file_path)\n", "        for file_path in input_file_paths]\n", "\n", "    # Create a Batch service client. We'll now be interacting with the Batch\n", "    # service in addition to Storage\n", "    credentials = SharedKeyCredentials(config._BATCH_ACCOUNT_NAME,\n", "        config._BATCH_ACCOUNT_KEY)\n", "\n", "    batch_client = BatchServiceClient(\n", "        credentials,\n", "        batch_url=config._BATCH_ACCOUNT_URL)\n", "\n", "    try:\n", "        # Create the pool that will contain the compute nodes that will execute the\n", "        # tasks.\n", "        #create_pool(batch_client, config._POOL_ID)\n", "\n", "        # Create the job that will run the tasks.\n", "        create_job(batch_client, config._JOB_ID, config._POOL_ID)\n", "\n", "        # Add the tasks to the job.\n", "        add_tasks(batch_client, config._JOB_ID, input_files)\n", "\n", "        # Pause execution until tasks reach Completed state.\n", "        wait_for_tasks_to_complete(batch_client,\n", "                                   config._JOB_ID,\n", "                                   datetime.timedelta(minutes=30))\n", "\n", "        print(\"  Success! All tasks reached the 'Completed' state within the \"\n", "              \"specified timeout period.\")\n", "\n", "        # Print the stdout.txt and stderr.txt files for each task to the console\n", "        print_task_output(batch_client, config._JOB_ID)\n", "\n", "    except batchmodels.BatchErrorException as err:\n", "        print_batch_exception(err)\n", "        raise\n", "\n", "    # Clean up storage resources\n", "    print('Deleting container [{}]...'.format(input_container_name))\n", "    blob_service_client.delete_container(input_container_name)\n", "\n", "    # Print out some timing info\n", "    end_time = datetime.datetime.now().replace(microsecond=0)\n", "    print()\n", "    print('Sample end: {}'.format(end_time))\n", "    print('Elapsed time: {}'.format(end_time - start_time))\n", "    print()\n", "\n", "    # Clean up Batch resources (if the user so chooses).\n", "    if query_yes_no('Delete job?') == 'yes':\n", "        batch_client.job.delete(config._JOB_ID)\n", "\n", "    if query_yes_no('Delete pool?') == 'yes':\n", "        batch_client.pool.delete(config._POOL_ID)\n", "\n", "    print()\n", "    input('Press ENTER to exit...')"]}, {"cell_type": "code", "execution_count": null, "id": "5112f450", "metadata": {}, "outputs": [], "source": []}], "metadata": {"has_local_update": true, "is_local": true, "is_remote": true, "kernelspec": {"display_name": "py-py-greg-azure-ids", "language": "Python", "name": "py-py-greg-azure-ids"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.13"}, "last_sync_time": "2021-12-03T00:46:49.436743"}, "nbformat": 4, "nbformat_minor": 5}