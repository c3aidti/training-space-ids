{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Setting Up A Machine Learning Deployment Workflow on the C3 AI Suite\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### For the Data Science Course: As stated in the course materials, you do not need to edit anything in this notebook! You should simply execute this notebook with \"Run All\" from the Cell menu.\n", "\n", "This notebook is intended to set up an MLProject. In the next notebook, you will attach your already-trained model to that existing project to show you how to use artifacts you have created and update existing projects.\n", "\n", "If you would like to watch a walkthrough video of this notebook, you can do so [here](https://developer.c3.ai/data-science?qd=1) (scroll down to ML Model Deployment Workflow video).\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["**Note**: This workflow will work for any timeseries ML use-case that you may have, however for this example we will consider a simple binary classification problem for our SmartBulb Predictive Maintenance use-case."]}, {"cell_type": "markdown", "metadata": {}, "source": [" * [Machine Learning Productionizing Workflow](#1)\n", "    * [Pre-deployment]\n", "        * [1. Define Use Case](#1.1)\n", "        * [2. Create a segment of your population](#1.2)\n", "        * [3. Define how to retrieve and format data as features, data mask, and labels](#1.3)\n", "        * [Using an untrained ML Pipeline]\n", "            * [4. Define the steps in your machine learning pipeline flow](#1.4)\n", "            * [5. Configure the pipeline with the data specifications and tie it to the project](#1.5)\n", "            * [6. Train the model on the combined data from the subjects in the defined segment](#1.6)\n", "            * [7. Use the trained model to predict on a small subset of data](#1.7)\n", "    * [Deployment]\n", "        * [8. Configure how model predictions will be persisted](#1.8)\n", "        * [9. Deploy the trained model to a group of subjects](#1.9)\n", "    * [Post-deployment]\n", "        * [10. Evaluate Model and persist predictions and feature contributions on the subjects with the deployed model](#1.10)\n"]}, {"cell_type": "code", "execution_count": 1, "metadata": {"ExecuteTime": {"end_time": "2022-06-21T01:10:01.697056Z", "start_time": "2022-06-21T01:10:01.393061Z"}}, "outputs": [], "source": ["import pandas as pd\n", "import time\n", "import matplotlib.pyplot as plt\n", "import time\n", "from datetime import timedelta\n", "\n", "\n", "def monitor_job_status(job, sleepFor=10):\n", "    \n", "    while (job.status().status not in [\"completed\", \"failed\", \"completed_with_errors\"]):\n", "        print(job.status().status)\n", "        time.sleep(sleepFor)\n", "        \n", "    return job.status()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Only use the cell below if the notebook has failed unexpectedly and you cannot troubleshoot the errors."]}, {"cell_type": "markdown", "metadata": {}, "source": ["**Note**: Use the following code block to clean up the objects created in this MLProject so that you can re-start the process. Only use this if the notebook has failed unexpectedly and you are unable to troubleshoot the error easily. \n", "\n", "**Warning** - This will remove all model deployment related artifacts you created under a project. Do not execute this unless you want to start over!"]}, {"cell_type": "code", "execution_count": 2, "metadata": {"ExecuteTime": {"end_time": "2022-06-21T01:10:01.700352Z", "start_time": "2022-06-21T01:10:01.698505Z"}}, "outputs": [], "source": ["# project.cleanUp(c3.MLCleanSpec(\n", "#     mlModels=True,\n", "#     mlPipelines=True,\n", "#     mlPopulationSegments=True,\n", "#     mlPredictionConfigurations=True,\n", "#     mlPredictionModelConfigurations=True,\n", "#     mlProjectSubjects=True,\n", "#     predictionDataSourceSpecs=True,\n", "#     trainingDataSourceSpecs=True,\n", "#     predictions=True,\n", "#     contributions=True,\n", "#     scores=True\n", "# ))\n", "# project.remove()\n"]}, {"cell_type": "markdown", "metadata": {"heading_collapsed": true}, "source": ["### Step 1: Define Use Case <a class=\"anchor\" id=\"1.1\">\n", "\n", "\n", "\n", "| Types  | Function  |\n", "|:---:|:---:|\n", "| `MLProject`  |  Represents the ML use case you are trying to solve with your model. Eg: Predictive Maintenance, Churn Prediction, Demand Forecasting |\n", "| `MLSubject`  |  Represents the object that you want to make predictions on. This subject should have data implicitly *attached* to it that you will use to make ML features. In your data model, there should be some C3 type representing this object. |\n", "| `MLProjectSubject` | Represents the object (`MLSubject`) but only in the context of your particular ML use case  |\n", "|   |   |\n", "\n", "\n", "If you were setting this up yourself, you would configure two c3typ files, one for the `MLSubject` and one for the `MLProjectSubject`. See [Create a Type to model the ML Subject](https://developer.c3.ai/docs/7.24.0/guide/guide-ml-ds/modelDeployment#section:1.1) for information on how to configure these two files.\n", "\n", "For this course, the course package has been configured for you.\n", "\n"]}, {"cell_type": "code", "execution_count": 3, "metadata": {"ExecuteTime": {"end_time": "2022-06-21T01:10:01.710755Z", "start_time": "2022-06-21T01:10:01.701753Z"}, "hidden": true}, "outputs": [], "source": ["project_name = \"SmartBulbPredictiveMaintenance\"\n", "subject_type_name = \"SmartBulb\"\n", "project_subject_type_name = \"SmartBulbProjectSubject\""]}, {"cell_type": "code", "execution_count": 4, "metadata": {"ExecuteTime": {"end_time": "2022-06-21T01:10:02.533063Z", "start_time": "2022-06-21T01:10:01.711952Z"}, "hidden": true}, "outputs": [], "source": ["project = c3.MLProject(\n", "    id=project_name,\n", "    name=project_name,\n", "    sourceType=subject_type_name,\n", "    projectSubjectType=project_subject_type_name\n", ").upsert()\n", "# Trigger a job populating the TadProjectSubject type that will execute asynchronously\n", "subject_creation_job = project.createProjectSubjects()\n"]}, {"cell_type": "markdown", "metadata": {"hidden": true}, "source": ["Wait for creation of `MLProjectSubject` entities to complete."]}, {"cell_type": "code", "execution_count": 5, "metadata": {"ExecuteTime": {"end_time": "2022-06-21T01:10:12.843319Z", "start_time": "2022-06-21T01:10:02.534510Z"}, "hidden": true, "scrolled": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["running\n"]}, {"data": {"text/plain": ["c3.MapReduceStatus(\n", " started=datetime.datetime(2022, 6, 21, 1, 10, 2, tzinfo=datetime.timezone.utc),\n", " startedby='lecheng4@illinois.edu',\n", " completed=datetime.datetime(2022, 6, 21, 1, 10, 5, tzinfo=datetime.timezone.utc),\n", " status='completed')"]}, "execution_count": 5, "metadata": {}, "output_type": "execute_result"}], "source": ["# subject_creation_job.status()\n", "\n", "monitor_job_status(subject_creation_job)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Step 2: Create a segment of your population: <a class=\"anchor\" id=\"1.2\">\n", "Key C3 Types:\n", "- `MLPopulationSegment` represents a logical grouping of the subjects (`MLSubject`) defined by a C3 fetch filter (`MLPopulationSegment#subjectFilter`). See [here](https://developer.c3.ai/docs/7.24.0/guide/guide-ml-ds/modelDeployment#section:1.2) for more information.\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["We create train, validation and test population segments:"]}, {"cell_type": "code", "execution_count": 6, "metadata": {"ExecuteTime": {"end_time": "2022-06-21T01:10:12.895393Z", "start_time": "2022-06-21T01:10:12.844741Z"}}, "outputs": [], "source": ["training_segment = c3.MLPopulationSegment(\n", "    subjectFilter=\"!(contains(id, 'SMBLB1') || contains(id, 'SMBLB2'))\", # Which subjects to include in the group\n", "    mlProject=project,\n", "    name=\"TrainingBulbs\",\n", ").upsert()\n"]}, {"cell_type": "code", "execution_count": 7, "metadata": {"ExecuteTime": {"end_time": "2022-06-21T01:10:12.966405Z", "start_time": "2022-06-21T01:10:12.896920Z"}}, "outputs": [], "source": ["validation_segment = c3.MLPopulationSegment(\n", "    subjectFilter=\"contains(id, 'SMBLB1')\", # Which subjects to include in the group\n", "    mlProject=project,\n", "    name=\"ValidationBulbs\",\n", ").upsert()\n"]}, {"cell_type": "code", "execution_count": 8, "metadata": {"ExecuteTime": {"end_time": "2022-06-21T01:10:13.096597Z", "start_time": "2022-06-21T01:10:12.967672Z"}}, "outputs": [], "source": ["test_segment = c3.MLPopulationSegment(\n", "    subjectFilter=\"contains(id, 'SMBLB2')\", # Which subjects to include in the group\n", "    mlProject=project,\n", "    name=\"TestingBulbs\",\n", ").upsert()\n"]}, {"cell_type": "code", "execution_count": 9, "metadata": {"ExecuteTime": {"end_time": "2022-06-21T01:10:13.103513Z", "start_time": "2022-06-21T01:10:13.099073Z"}}, "outputs": [{"data": {"text/plain": ["c3.MLPopulationSegment(\n", " subjectFilter='1 == 1',\n", " id='c9c5033c-9054-4945-a8fd-3832a25dbb2c',\n", " name='TestingBulbs',\n", " meta=c3.Meta(\n", "        created=datetime.datetime(2022, 6, 21, 1, 10, 12, tzinfo=datetime.timezone.utc),\n", "        updated=datetime.datetime(2022, 6, 21, 1, 10, 12, tzinfo=datetime.timezone.utc),\n", "        timestamp=datetime.datetime(2022, 6, 21, 1, 10, 12, tzinfo=datetime.timezone.utc),\n", "        refreshCalcFields=True),\n", " version=1)"]}, "execution_count": 9, "metadata": {}, "output_type": "execute_result"}], "source": ["test_segment"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Assign `MLProjectSubjects` in the `MLProject` to the `MLPopulationSegments` you just created."]}, {"cell_type": "code", "execution_count": 10, "metadata": {"ExecuteTime": {"end_time": "2022-06-21T01:10:13.583354Z", "start_time": "2022-06-21T01:10:13.105285Z"}}, "outputs": [], "source": ["assignment_action = project.assignSegments()\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Step 3: Define how to retrieve and format data as features, data mask, and labels. <a class=\"anchor\" id=\"1.3\">\n", "Key C3 Types:\n", "- `MLDataSourceSpec` defines where the data lies and how to extract the features for each subject to create the dataset for model training or prediction. For time series data, `EvalMetricsDatasetMLDataSourceSpec` comes out-of-the-box, but if you're using a different kind of data, you can create your own `MLDataSourceSpec` by following this [tutorial](https://developer.c3.ai/docs/7.24.0/topic/custom-mldatasourcespec)."]}, {"cell_type": "code", "execution_count": 11, "metadata": {"ExecuteTime": {"end_time": "2022-06-21T01:10:13.656548Z", "start_time": "2022-06-21T01:10:13.584685Z"}}, "outputs": [], "source": ["# List of C3 metric (SimpleMetric or Compound) names\n", "features = [\n", "                \"AverageTemperature\",\n", "                \"AveragePower\",\n", "]\n", "\n", "# We will use this to discard data AFTER a bulb has failed\n", "mask = 'HasEverFailed'\n", "label = 'WillFailNextMonth'\n", "train_start_date = \"2016-01-01\" # datetime string for start of training period\n", "train_end_date = \"2021-01-01\" # datetime string for end of training period\n", "time_series_interval = \"DAY\" # string specifying interval of data (See Interval type for more info)\n", "\n", "source_spec = c3.EvalMetricsDatasetMLDataSourceSpec(\n", "    name=\"training_smartbulb\",\n", "    srcType=subject_type_name,\n", "    features=features,\n", "    maskMetric=mask,\n", "    target=label,\n", "    start=train_start_date,\n", "    end=train_end_date,\n", "    interval=time_series_interval\n", ").upsert()\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Note regarding Steps 4 to 7"]}, {"cell_type": "markdown", "metadata": {}, "source": ["**Steps 4 to 7 are required if you wish to train a new machine learning pipeline and then deploy it. If you are continuing work from a tuned ML pipeline from the MLExperimentation workflow, then continue onto Step 8**"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Step 4: Define the machine learning pipeline. <a class=\"anchor\" id=\"1.4\">\n", "Key Types:\n", "- `MLPipeline` defines steps of machine learning algorithms/models in the workflow. See [Working with ML Pipeline](https://developer.c3.ai/docs/7.24.0/guide/guide-ml-ds/machine-learning-pipeline) for more details about `MLPipeline` and [Custom Machine Learning Pipelines](https://developer.c3.ai/docs/7.24.0/guide/guide-ml-ds/custom-machine-learning-pipelines) for how to configure a pipeline that is not available out-of-the-box.\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["We can make deeply nested machine learning pipelines as shown above, but in this example we will use a simple RandomForestClassifier from sklearn"]}, {"cell_type": "code", "execution_count": 12, "metadata": {"ExecuteTime": {"end_time": "2022-06-21T01:11:22.082448Z", "start_time": "2022-06-21T01:10:13.657992Z"}}, "outputs": [], "source": ["interpret_technique = c3.TreeInterpreterInterpretTechnique() # Specify MLInterpretTechnique here or None\n", "scoring_metrics = [c3.MLAccuracyMetric(), c3.MLPrecisionMetric(), c3.MLRecallMetric(), c3.MLF1ScoreMetric()]\n", "\n", "untrained_pipeline = c3.MLSerialPipeline(\n", "    steps=[\n", "        c3.MLStep(pipe=c3.SklearnPipe( # Specify MLLeafPipe here\n", "            technique=c3.SklearnTechnique( # Add associated MLTechnique with hyperparameters here\n", "                        name=\"ensemble.RandomForestClassifier\",\n", "                        processingFunctionName=\"predict\"),\n", "            \n", "            interpretTechnique=interpret_technique),\n", "            \n", "        name=\"rfPipeline\"\n", "        )\n", "    ],\n", "    scoringMetrics=c3.MLScoringMetric.toScoringMetricMap(scoring_metrics)\n", ").upsert()\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Step 5: Configure the pipeline with the data specifications and tie it to the project. <a class=\"anchor\" id=\"1.5\">\n", "Key Types:\n", "- `MLModel` combines the machine learning pipeline with the training data specifications and the inference data specifications into one entity. See [here](https://developer.c3.ai/docs/7.24.0/guide/guide-ml-ds/modelDeployment#section:1.3) for more information."]}, {"cell_type": "code", "execution_count": 13, "metadata": {"ExecuteTime": {"end_time": "2022-06-21T01:11:22.685315Z", "start_time": "2022-06-21T01:11:22.084004Z"}}, "outputs": [], "source": ["ml_model = c3.MLModel.createFromPipeline(\n", "    pipeline=untrained_pipeline.get(), \n", "    trainingDataSourceSpec=source_spec.get(),\n", "    spec=c3.MLModelCreateSpec(\n", "        predictionDataSourceSpec=source_spec.get(),\n", "        mlProject=project\n", "    )\n", ").upsert(spec=c3.UpsertSpec(returnInclude=\"this\"))\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Step 6: Train the model on the combined data from the subjects in the defined segment. <a class=\"anchor\" id=\"1.6\">\n", "- `MLPopulationSegmentTrainingJob` is a model training job that is kicked off when `MLModel#train` is called. It parallelizes the creation of the dataset and then trains the model. See [here](https://developer.c3.ai/docs/7.24.0/type/MLPopulationSegmentTrainingJob) for more information."]}, {"cell_type": "code", "execution_count": 14, "metadata": {"ExecuteTime": {"end_time": "2022-06-21T01:11:23.559783Z", "start_time": "2022-06-21T01:11:22.686602Z"}}, "outputs": [], "source": ["training_job = ml_model.train(training_segment.get(),\n", "                              spec=c3.MLTrainingJobOptions(persistData=True))\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Wait for model training to finish."]}, {"cell_type": "code", "execution_count": 15, "metadata": {"ExecuteTime": {"end_time": "2022-06-21T01:12:44.337786Z", "start_time": "2022-06-21T01:11:23.561115Z"}}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["running\n", "running\n", "running\n", "running\n", "running\n", "running\n", "running\n", "running\n"]}, {"data": {"text/plain": ["c3.MapReduceStatus(\n", " started=datetime.datetime(2022, 6, 21, 1, 11, 23, tzinfo=datetime.timezone.utc),\n", " startedby='lecheng4@illinois.edu',\n", " completed=datetime.datetime(2022, 6, 21, 1, 12, 38, tzinfo=datetime.timezone.utc),\n", " status='failed',\n", " errors=c3.Arry<JobRunErrorDetail>([c3.JobRunErrorDetail(\n", "           failedActionId='8649.-2125004381',\n", "           errorMsg='Error executing command: '\n", "                     '/usr/local/share/c3/condaEnvs/dev/tc03d/py-sklearn_3_0_0/bin/python '\n", "                     '/tmp/pythonActionSourceCache3224350693024947338/SklearnPipe_train.py\\n'\n", "                     'Process exited with 3 exit code.\\n'\n", "                     'a_id=8649.-2124558012 a_implementation=python '\n", "                     't_tenant=dev t_tag=tc03d t_type=SklearnPipe '\n", "                     't_action=train p_logger=action '\n", "                     'url=http://dev-dti-app-w-007:8080 connector=null '\n", "                     'mode=\"thick\" Action failed!\\n'\n", "                     'Traceback (most recent call last):\\n'\n", "                     '  File \"PythonMLHelper.py\", line 334, in dec\\n'\n", "                     '    return func(*args, **kwargs)\\n'\n", "                     '  File \"SklearnPipe.py\", line 151, in train\\n'\n", "                     '    technique_obj.fit(input_arr, target_output_arr)\\n'\n", "                     '  File '\n", "                     '\"/usr/local/share/c3/condaEnvs/dev/tc03d/py-sklearn_3_0_0/lib/python3.6/site-packages/sklearn/ensemble/_forest.py\", '\n", "                     'line 304, in fit\\n'\n", "                     '    accept_sparse=\"csc\", dtype=DTYPE)\\n'\n", "                     '  File '\n", "                     '\"/usr/local/share/c3/condaEnvs/dev/tc03d/py-sklearn_3_0_0/lib/python3.6/site-packages/sklearn/base.py\", '\n", "                     'line 432, in _validate_data\\n'\n", "                     '    X, y = check_X_y(X, y, **check_params)\\n'\n", "                     '  File '\n", "                     '\"/usr/local/share/c3/condaEnvs/dev/tc03d/py-sklearn_3_0_0/lib/python3.6/site-packages/sklearn/utils/validation.py\", '\n", "                     'line 73, in inner_f\\n'\n", "                     '    return f(**kwargs)\\n'\n", "                     '  File '\n", "                     '\"/usr/local/share/c3/condaEnvs/dev/tc03d/py-sklearn_3_0_0/lib/python3.6/site-packages/sklearn/utils/validation.py\", '\n", "                     'line 803, in check_X_y\\n'\n", "                     '    estimator=estimator)\\n'\n", "                     '  File '\n", "                     '\"/usr/local/share/c3/condaEnvs/dev/tc03d/py-sklearn_3_0_0/lib/python3.6/site-packages/sklearn/utils/validation.py\", '\n", "                     'line 73, in inner_f\\n'\n", "                     '    return f(**kwargs)\\n'\n", "                     '  File '\n", "                     '\"/usr/local/share/c3/condaEnvs/dev/tc03d/py-sklearn_3_0_0/lib/python3.6/site-packages/sklearn/utils/validation.py\", '\n", "                     'line 654, in check_array\\n'\n", "                     '    context))\\n'\n", "                     'ValueError: Found array with 0 sample(s) (shape=(0, 2)) '\n", "                     'while a minimum of 1 is required.\\n'\n", "                     '\\n'\n", "                     'During handling of the above exception, another '\n", "                     'exception occurred:\\n'\n", "                     '\\n'\n", "                     'Traceback (most recent call last):\\n'\n", "                     '  File '\n", "                     '\"/tmp/pythonActionSourceCache3224350693024947338/SklearnPipe_train.py\", '\n", "                     'line 406, in _c3_remote_bootstrap__run_c3_action\\n'\n", "                     '    _c3_result = _action()\\n'\n", "                     '  File '\n", "                     '\"/tmp/pythonActionSourceCache3224350693024947338/SklearnPipe_train.py\", '\n", "                     'line 537, in <lambda>\\n'\n", "                     '    action=lambda: train(this = '\n", "                     \"_c3_inputs.get('this'),input = \"\n", "                     \"_c3_inputs.get('input'),targetOutput = \"\n", "                     \"_c3_inputs.get('targetOutput'),spec = \"\n", "                     \"_c3_inputs.get('spec')),\\n\"\n", "                     '  File \"PythonMLHelper.py\", line 342, in dec\\n'\n", "                     '    raise Exception(errMsg + \" \" + e.__class__.__name__ '\n", "                     '+ \" raised: \" + str(e))\\n'\n", "                     'Exception: For given Input: shape: c3.Arry<int>([0, 2]) '\n", "                     'and targetOutput: shape: c3.Arry<int>([0, 1]) ValueError '\n", "                     'raised: Found array with 0 sample(s) (shape=(0, 2)) '\n", "                     'while a minimum of 1 is required.\\n'\n", "                     '\\n'\n", "                     '  from action SklearnPipe.train\\n'\n", "                     '  from env_server.js, line 132\\n'\n", "                     '    130    if (C3._context.locale)\\n'\n", "                     '    131      options.language = C3._context.locale;\\n'\n", "                     '  > 132    return c3CallAction(target, args, options);\\n'\n", "                     '    133  }\\n'\n", "                     '    134  \\n'\n", "                     '  from typesys.js, line 1692\\n'\n", "                     '    1690  \\n'\n", "                     '    1691          // call the server to execute this '\n", "                     'function as an action\\n'\n", "                     '  > 1692          response = c3Call(this, name, args);\\n'\n", "                     '    1693        }\\n'\n", "                     '    1694  \\n'\n", "                     '  from MLSerialPipeline_doTrain.js, line 332\\n'\n", "                     '    330          this.steps[numSteps - 1].pipe = '\n", "                     'lastStep.pipe.doTrai...\\n'\n", "                     '    331        } else {\\n'\n", "                     '  > 332          this.steps[numSteps - 1].pipe = '\n", "                     'lastStep.pipe.train(...\\n'\n", "                     '    333        }\\n'\n", "                     '    334      } else {\\n'\n", "                     '  from MLSerialPipeline_doTrain.js, line 624\\n'\n", "                     '    622  \\n'\n", "                     '    623  if (typeof $MLSerialPipeline$functions.doTrain '\n", "                     \"== 'function') {\\n\"\n", "                     '  > 624    function doTrain() { return '\n", "                     '$MLSerialPipeline$functions.do...\\n'\n", "                     '    625  }\\n'\n", "                     '    626  \\n'\n", "                     '  from MLSerialPipeline_doTrain.js, line 942\\n'\n", "                     \"    940  if (typeof doTrain != 'function') throw new \"\n", "                     \"Error('Function ...\\n\"\n", "                     '    941  global$.call$MLSerialPipeline$doTrain = '\n", "                     'function(this_, inpu...\\n'\n", "                     '  > 942    return doTrain.call(this_, input, '\n", "                     'targetOutput, spec);\\n'\n", "                     '    943  };\\n'\n", "                     '    944  })(this);\\n'\n", "                     '  base action MLSerialPipeline.doTrain',\n", "           errorCodes='NotClassified',\n", "           errorLog='c3.love.exceptions.C3RuntimeException: Error executing '\n", "                     'command: '\n", "                     '/usr/local/share/c3/condaEnvs/dev/tc03d/py-sklearn_3_0_0/bin/python '\n", "                     '/tmp/pythonActionSourceCache3224350693024947338/SklearnPipe_train.py\\n'\n", "                     'Process exited with 3 exit code.\\n'\n", "                     'a_id=8649.-2124558012 a_implementation=python '\n", "                     't_tenant=dev t_tag=tc03d t_type=SklearnPipe '\n", "                     't_action=train p_logger=action '\n", "                     'url=http://dev-dti-app-w-007:8080 connector=null '\n", "                     'mode=\"thick\" Action failed!\\n'\n", "                     'Traceback (most recent call last):\\n'\n", "                     '  File \"PythonMLHelper.py\", line 334, in dec\\n'\n", "                     '    return func(*args, **kwargs)\\n'\n", "                     '  File \"SklearnPipe.py\", line 151, in train\\n'\n", "                     '    technique_obj.fit(input_arr, target_output_arr)\\n'\n", "                     '  File '\n", "                     '\"/usr/local/share/c3/condaEnvs/dev/tc03d/py-sklearn_3_0_0/lib/python3.6/site-packages/sklearn/ensemble/_forest.py\", '\n", "                     'line 304, in fit\\n'\n", "                     '    accept_sparse=\"csc\", dtype=DTYPE)\\n'\n", "                     '  File '\n", "                     '\"/usr/local/share/c3/condaEnvs/dev/tc03d/py-sklearn_3_0_0/lib/python3.6/site-packages/sklearn/base.py\", '\n", "                     'line 432, in _validate_data\\n'\n", "                     '    X, y = check_X_y(X, y, **check_params)\\n'\n", "                     '  File '\n", "                     '\"/usr/local/share/c3/condaEnvs/dev/tc03d/py-sklearn_3_0_0/lib/python3.6/site-packages/sklearn/utils/validation.py\", '\n", "                     'line 73, in inner_f\\n'\n", "                     '    return f(**kwargs)\\n'\n", "                     '  File '\n", "                     '\"/usr/local/share/c3/condaEnvs/dev/tc03d/py-sklearn_3_0_0/lib/python3.6/site-packages/sklearn/utils/validation.py\", '\n", "                     'line 803, in check_X_y\\n'\n", "                     '    estimator=estimator)\\n'\n", "                     '  File '\n", "                     '\"/usr/local/share/c3/condaEnvs/dev/tc03d/py-sklearn_3_0_0/lib/python3.6/site-packages/sklearn/utils/validation.py\", '\n", "                     'line 73, in inner_f\\n'\n", "                     '    return f(**kwargs)\\n'\n", "                     '  File '\n", "                     '\"/usr/local/share/c3/condaEnvs/dev/tc03d/py-sklearn_3_0_0/lib/python3.6/site-packages/sklearn/utils/validation.py\", '\n", "                     'line 654, in check_array\\n'\n", "                     '    context))\\n'\n", "                     'ValueError: Found array with 0 sample(s) (shape=(0, 2)) '\n", "                     'while a minimum of 1 is required.\\n'\n", "                     '\\n'\n", "                     'During handling of the above exception, another '\n", "                     'exception occurred:\\n'\n", "                     '\\n'\n", "                     'Traceback (most recent call last):\\n'\n", "                     '  File '\n", "                     '\"/tmp/pythonActionSourceCache3224350693024947338/SklearnPipe_train.py\", '\n", "                     'line 406, in _c3_remote_bootstrap__run_c3_action\\n'\n", "                     '    _c3_result = _actio..."]}, "execution_count": 15, "metadata": {}, "output_type": "execute_result"}], "source": ["# training_job.status()\n", "\n", "monitor_job_status(training_job)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Retrieve the resulting trained model from the training job."]}, {"cell_type": "code", "execution_count": 17, "metadata": {"ExecuteTime": {"end_time": "2022-06-21T01:23:34.510006Z", "start_time": "2022-06-21T01:23:34.298126Z"}}, "outputs": [{"ename": "TypeError", "evalue": "'NoneType' object is not subscriptable", "output_type": "error", "traceback": ["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m", "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)", "\u001b[0;32m<ipython-input-17-7d0380076c57>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m trained_ml_model = c3.MLModel.fetch(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mspec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mc3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFetchSpec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf\"configuration.id == '{training_job.trainedModelConfiguration.id}'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m ).objs[0]\n", "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"]}], "source": ["trained_ml_model = c3.MLModel.fetch(\n", "    spec=c3.FetchSpec(filter=f\"configuration.id == '{training_job.trainedModelConfiguration.id}'\")\n", ").objs[0]"]}, {"cell_type": "code", "execution_count": null, "metadata": {"ExecuteTime": {"end_time": "2022-06-21T01:12:44.416846Z", "start_time": "2022-06-21T01:10:01.596Z"}}, "outputs": [], "source": ["trained_ml_model"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Step 7: Use the trained model to predict on a small subset of data.  <a class=\"anchor\" id=\"1.7\">\n", "Key Types:\n", "- `MLPartialDataSourceSpec` exists to allow users to override certain fields of the `MLDataSourceSpec` during inference. In the case of time series data, you might want to override the `start` and `end` dates whenever you make a new prediction because you received new data. See [here](https://developer.c3.ai/docs/7.24.0/topic/custom-mldatasourcespec#section:1.2) for more information."]}, {"cell_type": "code", "execution_count": null, "metadata": {"ExecuteTime": {"end_time": "2022-06-21T01:12:44.417448Z", "start_time": "2022-06-21T01:10:01.597Z"}}, "outputs": [], "source": ["prediction_subjects = getattr(c3, subject_type_name).fetch({ # Get a sample subject to predict on\n", "    \"filter\": test_segment.get().subjectFilter,\n", "    \"limit\": 1\n", "}).objs\n", "\n", "partial_data_source_spec = c3.EvalMetricsMLPartialDataSourceSpec(start=\"2018-05-01\",\n", "                                                                 end=\"2021-01-01\") # MLPartialDataSourceSpec subtype for your dataset\n", "\n", "sample_predictions = trained_ml_model.predictForSubjects(\n", "    partialDataSpec=partial_data_source_spec, \n", "    subjects=prediction_subjects\n", ")\n", "\n", "pred_df = c3.Dataset.toPandas(sample_predictions)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Retrieve ground truth labels:"]}, {"cell_type": "code", "execution_count": null, "metadata": {"ExecuteTime": {"end_time": "2022-06-21T01:12:44.417942Z", "start_time": "2022-06-21T01:10:01.598Z"}}, "outputs": [], "source": ["y_true_dataset = source_spec.get().withPartialSpec(partial_data_source_spec)\\\n", "                                        .getTargetDataForSources([prediction_subjects[0].id])\n", "\n", "y_true = c3.Dataset.toPandas(y_true_dataset)                                  "]}, {"cell_type": "markdown", "metadata": {}, "source": ["Additional formatting on the prediction and ground truth dataframes:"]}, {"cell_type": "code", "execution_count": null, "metadata": {"ExecuteTime": {"end_time": "2022-06-21T01:12:44.418463Z", "start_time": "2022-06-21T01:10:01.599Z"}}, "outputs": [], "source": ["def format_df(df):\n", "    df['source'] = df.index.str.split('_').str[0]\n", "    df['timestamp'] = pd.to_datetime(df.index.str.split('_').str[1],format=\"%Y-%m-%dT%H:%M:%S.%f\")\n", "    return df\n", "\n", "pred_df = format_df(pred_df)\n", "y_true = format_df(y_true)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["View prediction series for the sample subject."]}, {"cell_type": "code", "execution_count": null, "metadata": {"ExecuteTime": {"end_time": "2022-06-21T01:12:44.418984Z", "start_time": "2022-06-21T01:10:01.600Z"}}, "outputs": [], "source": ["fig, ax = plt.subplots(figsize=(16, 6))\n", "\n", "ax.plot(pred_df['timestamp'], pred_df['prediction'], color='tab:orange', label='predictions')\n", "ax.plot(y_true['timestamp'], y_true[label], color='tab:blue', label='ground truth')\n", "ax.set_xlabel('Time')\n", "ax.set_ylabel('Status')\n", "ax.set_title(f'Comparing Predictions to Ground Truth for {prediction_subjects[0].id}')\n", "ax.legend(loc='upper left');"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Step 8: Configure how model predictions will be persisted <a class=\"anchor\" id=\"1.8\">\n", "Key C3 Types:\n", "- `MLPredictionPersister`\n", "- `MLModelTimedPredictionSeries`"]}, {"cell_type": "markdown", "metadata": {}, "source": ["We will use the default timeseries prediction persister here"]}, {"cell_type": "code", "execution_count": null, "metadata": {"ExecuteTime": {"end_time": "2022-06-21T01:12:44.419501Z", "start_time": "2022-06-21T01:10:01.601Z"}}, "outputs": [], "source": ["trained_ml_model= trained_ml_model.get() # or c3.MLModel.get('model_id') if using a model trained earlier\n", "trained_ml_model.predictionPersisters = None # Specify MLPredictionPersisters or None to use default\n", "trained_ml_model.merge(spec=c3.MergeSpec(mergeInclude=\"predictionPersisters\"))\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Step 9: Deploy the trained model to a group of subjects. <a class=\"anchor\" id=\"1.9\">\n", "Deploying the model to a group of subjects means that the model is used to make and persist predictions on each subject. This group of subjects (`MLPopulationSegment`) that the model is deployed on is often the same group that the model was trained on, but can be applied to other subjects as well (e.g. subjects that do not have enough data to train on)."]}, {"cell_type": "code", "execution_count": null, "metadata": {"ExecuteTime": {"end_time": "2022-06-21T01:12:44.420183Z", "start_time": "2022-06-21T01:10:01.602Z"}}, "outputs": [], "source": ["test_segment.deployModels(\n", "    [training_job.trainedModelConfiguration.get()], \n", "    statusLabel=\"LIVE\" # \"LIVE\", \"CHALLENGER\", OR \"CANDIDATE\"\n", ")\n", "\n", "\n", "# test_segment.deployModels(\n", "#     [trained_ml_model.configuration], \n", "#     statusLabel=\"CHALLENGER\" # \"LIVE\", \"CHALLENGER\", OR \"CANDIDATE\"\n", "# )\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"ExecuteTime": {"end_time": "2022-06-21T01:12:44.420715Z", "start_time": "2022-06-21T01:10:01.603Z"}}, "outputs": [], "source": ["update_job = test_segment.updateModels()\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Wait for model to be deployed."]}, {"cell_type": "code", "execution_count": null, "metadata": {"ExecuteTime": {"end_time": "2022-06-21T01:12:44.421226Z", "start_time": "2022-06-21T01:10:01.604Z"}}, "outputs": [], "source": ["# update_job.status()\n", "\n", "monitor_job_status(update_job)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Step 10:  Evaluate Model and persist predictions and feature contributions on the subjects with the deployed model. <a class=\"anchor\" id=\"1.10\">"]}, {"cell_type": "markdown", "metadata": {}, "source": ["We will now submit jobs to score, predict and interpret results from our machine learning model. The results are persisted automatically and can be efficiently queried from other applications."]}, {"cell_type": "code", "execution_count": null, "metadata": {"ExecuteTime": {"end_time": "2022-06-21T01:12:44.421753Z", "start_time": "2022-06-21T01:10:01.605Z"}}, "outputs": [], "source": ["partial_data_source_spec = c3.EvalMetricsMLPartialDataSourceSpec(start=\"2016-01-01\",\n", "                                                                 end=\"2021-01-01\") # MLPartialDataSourceSpec subtype for your dataset\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"ExecuteTime": {"end_time": "2022-06-21T01:12:44.422316Z", "start_time": "2022-06-21T01:10:01.606Z"}}, "outputs": [], "source": ["score_job = test_segment.score(\n", "    partialDataSpec=partial_data_source_spec\n", ")\n", "\n", "prediction_job = test_segment.predict(\n", "    partialDataSpec=partial_data_source_spec\n", ")\n", "\n", "interpret_job = test_segment.interpret(\n", "    partialDataSpec=partial_data_source_spec\n", ")\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"ExecuteTime": {"end_time": "2022-06-21T01:12:44.422878Z", "start_time": "2022-06-21T01:10:01.607Z"}}, "outputs": [], "source": ["# score_job.status()\n", "\n", "monitor_job_status(score_job)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Wait for prediction and feature contribution jobs to complete."]}, {"cell_type": "code", "execution_count": null, "metadata": {"ExecuteTime": {"end_time": "2022-06-21T01:12:44.423402Z", "start_time": "2022-06-21T01:10:01.607Z"}}, "outputs": [], "source": ["# prediction_job.status()\n", "\n", "monitor_job_status(prediction_job)"]}, {"cell_type": "code", "execution_count": null, "metadata": {"ExecuteTime": {"end_time": "2022-06-21T01:12:44.424686Z", "start_time": "2022-06-21T01:10:01.608Z"}, "scrolled": false}, "outputs": [], "source": ["# interpret_job.status()\n", "\n", "monitor_job_status(interpret_job)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["View the results of the prediction job for a single subject."]}, {"cell_type": "code", "execution_count": null, "metadata": {"ExecuteTime": {"end_time": "2022-06-21T01:12:44.425265Z", "start_time": "2022-06-21T01:10:01.609Z"}}, "outputs": [], "source": ["predictions_emr = c3.MLModel.evalMetrics(spec=c3.EvalMetricsSpec(\n", "    ids=[trained_ml_model.id], expressions=[\"MLProjectPrediction\"], \n", "    start=\"2016-01-01\", end=\"2021-01-01\",\n", "    bindings=[{\"subjectId\": \"SMBLB2\"}],\n", "    interval=\"HOUR\",\n", "    resultKey=c3.Lambda.fromPython(\"lambda expression, bindings: expression + ('_' + bindings.get('featName', '') if expression == 'MLProjectContribution' else '')\")\n", "))"]}, {"cell_type": "code", "execution_count": null, "metadata": {"ExecuteTime": {"end_time": "2022-06-21T01:12:44.425981Z", "start_time": "2022-06-21T01:10:01.610Z"}}, "outputs": [], "source": ["c3.EvalMetricsResult.toPandas(predictions_emr, multiIndexed=True).droplevel(0).plot(figsize=(16, 4))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["View the results of the interpret job for a single subject:"]}, {"cell_type": "code", "execution_count": null, "metadata": {"ExecuteTime": {"end_time": "2022-06-21T01:12:44.426640Z", "start_time": "2022-06-21T01:10:01.611Z"}, "scrolled": true}, "outputs": [], "source": ["feature_contributions_emr = c3.MLModel.evalMetrics(spec=c3.EvalMetricsSpec(\n", "    ids=[trained_ml_model.id], expressions=[\"MLProjectContribution\"], \n", "    start=\"2016-01-01\", end=\"2021-01-01\",\n", "    bindings=[{\"featName\": feat, \"subjectId\": \"SMBLB2\"} for feat in features],\n", "    interval=\"DAY\",\n", "    resultKey=c3.Lambda.fromPython(\"lambda expression, bindings: expression + ('_' + bindings.get('featName', '') if expression == 'MLProjectContribution' else '')\")\n", "))"]}, {"cell_type": "code", "execution_count": null, "metadata": {"ExecuteTime": {"end_time": "2022-06-21T01:12:44.427187Z", "start_time": "2022-06-21T01:10:01.612Z"}}, "outputs": [], "source": ["c3.EvalMetricsResult.toPandas(feature_contributions_emr, multiIndexed=True).droplevel(0).plot(figsize=(16, 4))\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["View Scores resulting from our scoring job:"]}, {"cell_type": "code", "execution_count": null, "metadata": {"ExecuteTime": {"end_time": "2022-06-21T01:12:44.427827Z", "start_time": "2022-06-21T01:10:01.612Z"}}, "outputs": [], "source": ["start = trained_ml_model.get(\"scores.data.this\").scores[0].data[0].start\n", "scores_emr = c3.MLModel.evalMetrics(spec=c3.EvalMetricsSpec(\n", "                ids=[trained_ml_model.id], expressions=[\"Score\"], \n", "                start=start - timedelta(hours=3), end=start + timedelta(hours=12),\n", "                bindings=[{'scoringMetricName': 'MLAccuracyMetric'},\n", "                          {'scoringMetricName': 'MLF1ScoreMetric'},\n", "                          {'scoringMetricName': 'MLPrecisionMetric'},\n", "                          {'scoringMetricName': 'MLRecallMetric'}],\n", "                interval=\"DAY\",\n", "                resultKey=c3.Lambda.fromPython(\"lambda expression, bindings: expression + '_' + bindings['scoringMetricName']\")\n", "))\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"ExecuteTime": {"end_time": "2022-06-21T01:12:44.428474Z", "start_time": "2022-06-21T01:10:01.613Z"}, "scrolled": true}, "outputs": [], "source": ["c3.EvalMetricsResult.toPandas(scores_emr, multiIndexed=True).droplevel(0).plot(figsize=(12, 4), marker='x', grid=True, subplots=True)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["**Congratulations! You have just deployed a ```LIVE``` machine learning model in production using best practices that allow you to scale seamlessly. Now your applications can begin querying your model to generate predictions, feature contributions and scores that are automatically persisted.** "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["### View the ids of the created MLProject and of the trained MLModel from the project (the \"LIVE\" model) in the cells below."]}, {"cell_type": "code", "execution_count": null, "metadata": {"ExecuteTime": {"end_time": "2022-06-21T01:12:44.428987Z", "start_time": "2022-06-21T01:10:01.615Z"}}, "outputs": [], "source": ["# project"]}, {"cell_type": "code", "execution_count": null, "metadata": {"ExecuteTime": {"end_time": "2022-06-21T01:12:44.429534Z", "start_time": "2022-06-21T01:10:01.616Z"}}, "outputs": [], "source": ["project.id"]}, {"cell_type": "code", "execution_count": null, "metadata": {"ExecuteTime": {"end_time": "2022-06-21T01:12:44.430089Z", "start_time": "2022-06-21T01:10:01.616Z"}}, "outputs": [], "source": ["trained_ml_model.id"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}], "metadata": {"has_local_update": false, "is_local": true, "is_remote": true, "kernelspec": {"display_name": "py-pythonEnv", "language": "Python", "name": "py-pythonenv"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.7.13"}, "last_sync_time": "2022-06-21T03:17:52.560375"}, "nbformat": 4, "nbformat_minor": 4}