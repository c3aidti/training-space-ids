{"cells": [{"cell_type": "markdown", "id": "22aa67cd", "metadata": {}, "source": ["Use this notebook as a template to complete the Capstone. This notebook assumes that you have successfully run the previous notebook 05.1_C3_Capstone_Setup_MDF and have at least one MLModel deployed as `LIVE` on the test population segment. It also assumes that you have a trained and tuned pipeline wihch has acheived an F1 score of at least 0.8 that you have used to create an MLModel at the end of the notebook 04_C3_Model_Development_Experimentation. Once you have this MLModel created, you can use this notebook to deploy that model as a `CHALLENGER` model. \n", "\n", "Your goal is to have a `CHALLENGER` model that achieves an F1-Score of at least 0.80 on the Test Segment. Please don't train on the test segment. :)"]}, {"cell_type": "markdown", "id": "8a727c24", "metadata": {}, "source": ["# Deploy Challenger Models"]}, {"cell_type": "markdown", "id": "61db0cb2", "metadata": {}, "source": ["Necessary imports:"]}, {"cell_type": "code", "execution_count": 17, "id": "4555ad7f", "metadata": {"ExecuteTime": {"end_time": "2022-06-21T01:22:16.280110Z", "start_time": "2022-06-21T01:22:16.276578Z"}}, "outputs": [], "source": ["import pandas as pd\n", "import time\n", "from datetime import timedelta\n", "\n", "\n", "def monitor_job_status(job, sleepFor=10):\n", "    \n", "    while (job.status().status not in [\"completed\", \"failed\", \"completed_with_errors\"]):\n", "        print(job.status().status)\n", "        time.sleep(sleepFor)\n", "        \n", "    return job.status()"]}, {"cell_type": "markdown", "id": "e9709d1c", "metadata": {}, "source": ["### Retrieve the MLPopulation Segments we currently have"]}, {"cell_type": "code", "execution_count": 18, "id": "5a45195b", "metadata": {"ExecuteTime": {"end_time": "2022-06-21T01:22:18.747912Z", "start_time": "2022-06-21T01:22:18.712496Z"}, "scrolled": true}, "outputs": [{"data": {"text/html": ["<div>\n", "<style scoped>\n", "    .dataframe tbody tr th:only-of-type {\n", "        vertical-align: middle;\n", "    }\n", "\n", "    .dataframe tbody tr th {\n", "        vertical-align: top;\n", "    }\n", "\n", "    .dataframe thead th {\n", "        text-align: right;\n", "    }\n", "</style>\n", "<table border=\"1\" class=\"dataframe\">\n", "  <thead>\n", "    <tr style=\"text-align: right;\">\n", "      <th></th>\n", "      <th>type</th>\n", "      <th>priority</th>\n", "      <th>subjectFilter</th>\n", "      <th>id</th>\n", "      <th>name</th>\n", "      <th>meta</th>\n", "      <th>version</th>\n", "      <th>mlProject</th>\n", "      <th>deployedSegmentStatistic</th>\n", "    </tr>\n", "  </thead>\n", "  <tbody>\n", "    <tr>\n", "      <th>0</th>\n", "      <td>MLPopulationSegment</td>\n", "      <td>0.0</td>\n", "      <td>contains(id, 'SMBLB1')</td>\n", "      <td>08c5f0ec-64df-4ce2-bc9c-32c06e3f022e</td>\n", "      <td>ValidationBulbs</td>\n", "      <td>{'type': 'Meta', 'tenantTagId': 152, 'tenant':...</td>\n", "      <td>1</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "    </tr>\n", "    <tr>\n", "      <th>1</th>\n", "      <td>MLPopulationSegment</td>\n", "      <td>0.0</td>\n", "      <td>!(contains(id, 'SMBLB1') || contains(id, 'SMBL...</td>\n", "      <td>48c75a84-cf39-4e48-b45b-a1885624c960</td>\n", "      <td>TrainingBulbs</td>\n", "      <td>{'type': 'Meta', 'tenantTagId': 152, 'tenant':...</td>\n", "      <td>1</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "    </tr>\n", "    <tr>\n", "      <th>2</th>\n", "      <td>MLPopulationSegment</td>\n", "      <td>0.0</td>\n", "      <td>contains(id, 'SMBLB2')</td>\n", "      <td>5d90cd1e-8ffe-4e16-babc-56fa2df3b921</td>\n", "      <td>TestingBulbs</td>\n", "      <td>{'type': 'Meta', 'tenantTagId': 152, 'tenant':...</td>\n", "      <td>1</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "    </tr>\n", "    <tr>\n", "      <th>3</th>\n", "      <td>MLPopulationSegment</td>\n", "      <td>0.0</td>\n", "      <td>!(contains(id, 'SMBLB1') || contains(id, 'SMBL...</td>\n", "      <td>69099c7f-ad7c-4e33-95c1-d0c3c4bbc329</td>\n", "      <td>TrainingBulbs</td>\n", "      <td>{'type': 'Meta', 'tenantTagId': 152, 'tenant':...</td>\n", "      <td>1</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "    </tr>\n", "    <tr>\n", "      <th>4</th>\n", "      <td>MLPopulationSegment</td>\n", "      <td>0.0</td>\n", "      <td>contains(id, 'SMBLB1')</td>\n", "      <td>6e802041-5f55-48ba-b56b-1b27468374a1</td>\n", "      <td>ValidationBulbs</td>\n", "      <td>{'type': 'Meta', 'tenantTagId': 152, 'tenant':...</td>\n", "      <td>2</td>\n", "      <td>{'type': 'MLProject', 'id': 'SmartBulbPredicti...</td>\n", "      <td>{'type': 'MLPopulationSegmentStatistic', 'coun...</td>\n", "    </tr>\n", "    <tr>\n", "      <th>5</th>\n", "      <td>MLPopulationSegment</td>\n", "      <td>1.0</td>\n", "      <td>!(contains(id, 'SMBLB1') || contains(id, 'SMBL...</td>\n", "      <td>8b8459ad-2597-456e-b244-cd1663a84d48</td>\n", "      <td>TrainingBulbs</td>\n", "      <td>{'type': 'Meta', 'tenantTagId': 152, 'tenant':...</td>\n", "      <td>2</td>\n", "      <td>{'type': 'MLProject', 'id': 'SmartBulbPredicti...</td>\n", "      <td>{'type': 'MLPopulationSegmentStatistic', 'coun...</td>\n", "    </tr>\n", "    <tr>\n", "      <th>6</th>\n", "      <td>MLPopulationSegment</td>\n", "      <td>0.0</td>\n", "      <td>contains(id, 'SMBLB2')</td>\n", "      <td>b0239211-2f49-444a-80c4-f38175f96a05</td>\n", "      <td>TestingBulbs</td>\n", "      <td>{'type': 'Meta', 'tenantTagId': 152, 'tenant':...</td>\n", "      <td>1</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "    </tr>\n", "    <tr>\n", "      <th>7</th>\n", "      <td>MLPopulationSegment</td>\n", "      <td>-1.0</td>\n", "      <td>contains(id, 'SMBLB2')</td>\n", "      <td>c9c5033c-9054-4945-a8fd-3832a25dbb2c</td>\n", "      <td>TestingBulbs</td>\n", "      <td>{'type': 'Meta', 'tenantTagId': 152, 'tenant':...</td>\n", "      <td>2</td>\n", "      <td>{'type': 'MLProject', 'id': 'SmartBulbPredicti...</td>\n", "      <td>{'type': 'MLPopulationSegmentStatistic', 'coun...</td>\n", "    </tr>\n", "    <tr>\n", "      <th>8</th>\n", "      <td>MLPopulationSegment</td>\n", "      <td>0.0</td>\n", "      <td>contains(id, 'SMBLB1')</td>\n", "      <td>e3499eb9-3737-4f7c-931a-acba0813a1fc</td>\n", "      <td>ValidationBulbs</td>\n", "      <td>{'type': 'Meta', 'tenantTagId': 152, 'tenant':...</td>\n", "      <td>1</td>\n", "      <td>NaN</td>\n", "      <td>NaN</td>\n", "    </tr>\n", "  </tbody>\n", "</table>\n", "</div>"], "text/plain": ["                  type  priority  \\\n", "0  MLPopulationSegment       0.0   \n", "1  MLPopulationSegment       0.0   \n", "2  MLPopulationSegment       0.0   \n", "3  MLPopulationSegment       0.0   \n", "4  MLPopulationSegment       0.0   \n", "5  MLPopulationSegment       1.0   \n", "6  MLPopulationSegment       0.0   \n", "7  MLPopulationSegment      -1.0   \n", "8  MLPopulationSegment       0.0   \n", "\n", "                                       subjectFilter  \\\n", "0                             contains(id, 'SMBLB1')   \n", "1  !(contains(id, 'SMBLB1') || contains(id, 'SMBL...   \n", "2                             contains(id, 'SMBLB2')   \n", "3  !(contains(id, 'SMBLB1') || contains(id, 'SMBL...   \n", "4                             contains(id, 'SMBLB1')   \n", "5  !(contains(id, 'SMBLB1') || contains(id, 'SMBL...   \n", "6                             contains(id, 'SMBLB2')   \n", "7                             contains(id, 'SMBLB2')   \n", "8                             contains(id, 'SMBLB1')   \n", "\n", "                                     id             name  \\\n", "0  08c5f0ec-64df-4ce2-bc9c-32c06e3f022e  ValidationBulbs   \n", "1  48c75a84-cf39-4e48-b45b-a1885624c960    TrainingBulbs   \n", "2  5d90cd1e-8ffe-4e16-babc-56fa2df3b921     TestingBulbs   \n", "3  69099c7f-ad7c-4e33-95c1-d0c3c4bbc329    TrainingBulbs   \n", "4  6e802041-5f55-48ba-b56b-1b27468374a1  ValidationBulbs   \n", "5  8b8459ad-2597-456e-b244-cd1663a84d48    TrainingBulbs   \n", "6  b0239211-2f49-444a-80c4-f38175f96a05     TestingBulbs   \n", "7  c9c5033c-9054-4945-a8fd-3832a25dbb2c     TestingBulbs   \n", "8  e3499eb9-3737-4f7c-931a-acba0813a1fc  ValidationBulbs   \n", "\n", "                                                meta  version  \\\n", "0  {'type': 'Meta', 'tenantTagId': 152, 'tenant':...        1   \n", "1  {'type': 'Meta', 'tenantTagId': 152, 'tenant':...        1   \n", "2  {'type': 'Meta', 'tenantTagId': 152, 'tenant':...        1   \n", "3  {'type': 'Meta', 'tenantTagId': 152, 'tenant':...        1   \n", "4  {'type': 'Meta', 'tenantTagId': 152, 'tenant':...        2   \n", "5  {'type': 'Meta', 'tenantTagId': 152, 'tenant':...        2   \n", "6  {'type': 'Meta', 'tenantTagId': 152, 'tenant':...        1   \n", "7  {'type': 'Meta', 'tenantTagId': 152, 'tenant':...        2   \n", "8  {'type': 'Meta', 'tenantTagId': 152, 'tenant':...        1   \n", "\n", "                                           mlProject  \\\n", "0                                                NaN   \n", "1                                                NaN   \n", "2                                                NaN   \n", "3                                                NaN   \n", "4  {'type': 'MLProject', 'id': 'SmartBulbPredicti...   \n", "5  {'type': 'MLProject', 'id': 'SmartBulbPredicti...   \n", "6                                                NaN   \n", "7  {'type': 'MLProject', 'id': 'SmartBulbPredicti...   \n", "8                                                NaN   \n", "\n", "                            deployedSegmentStatistic  \n", "0                                                NaN  \n", "1                                                NaN  \n", "2                                                NaN  \n", "3                                                NaN  \n", "4  {'type': 'MLPopulationSegmentStatistic', 'coun...  \n", "5  {'type': 'MLPopulationSegmentStatistic', 'coun...  \n", "6                                                NaN  \n", "7  {'type': 'MLPopulationSegmentStatistic', 'coun...  \n", "8                                                NaN  "]}, "execution_count": 18, "metadata": {}, "output_type": "execute_result"}], "source": ["pd.DataFrame(c3.MLPopulationSegment.fetch().objs.toJson())"]}, {"cell_type": "markdown", "id": "bd97e03c", "metadata": {}, "source": ["### Get Test Segment id:"]}, {"cell_type": "code", "execution_count": 21, "id": "331e23fc", "metadata": {"ExecuteTime": {"end_time": "2022-06-21T01:22:55.448547Z", "start_time": "2022-06-21T01:22:55.430894Z"}}, "outputs": [], "source": ["# Look in the table above to find the id of the MLPopulation segment for TestingBulbs.\n", "# Make sure to use the id that is attached to an MLProject (does not have NaN in the MLProject column).\n", "\n", "test_segment = c3.MLPopulationSegment.get('MLPopulationSegmentIdForTestingBulbs')"]}, {"cell_type": "code", "execution_count": 22, "id": "a98b8b0d", "metadata": {"ExecuteTime": {"end_time": "2022-06-21T01:22:56.648787Z", "start_time": "2022-06-21T01:22:56.642067Z"}, "scrolled": false}, "outputs": [{"ename": "AttributeError", "evalue": "'NoneType' object has no attribute 'id'", "output_type": "error", "traceback": ["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m", "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)", "\u001b[0;32m<ipython-input-22-0ca954f2f920>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m c3.MLPopulationSegment.refreshCalcFields(c3.RefreshCalcFieldsSpec(calcFieldsToRefresh=['primaryConfiguration'],\n\u001b[0;32m----> 2\u001b[0;31m                                                                   ids=[test_segment.id]))\n\u001b[0m", "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'id'"]}], "source": ["c3.MLPopulationSegment.refreshCalcFields(c3.RefreshCalcFieldsSpec(calcFieldsToRefresh=['primaryConfiguration'],\n", "                                                                  ids=[test_segment.id]))\n"]}, {"cell_type": "markdown", "id": "9719577c", "metadata": {}, "source": ["### What is the current primary deployed model on the Test Segment?"]}, {"cell_type": "code", "execution_count": 6, "id": "ce0f8c47", "metadata": {"ExecuteTime": {"end_time": "2022-06-21T01:20:52.627466Z", "start_time": "2022-06-21T01:20:52.619463Z"}}, "outputs": [{"ename": "AttributeError", "evalue": "'NoneType' object has no attribute 'evaluate'", "output_type": "error", "traceback": ["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m", "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)", "\u001b[0;32m<ipython-input-6-878e022df02e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m primary_model_name = test_segment.evaluate(\n\u001b[0m\u001b[1;32m      2\u001b[0m     c3.EvaluateSpec(filter=f'id==\"{test_segment.id}\"',\n\u001b[1;32m      3\u001b[0m                     \u001b[0mprojection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'primaryConfiguration.predictionModels[0].model.pipeline.steps[0].name'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m )).tuples[0].cells[0].value()\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"The primary configuration has a model with name: {primary_model_name}.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'evaluate'"]}], "source": ["primary_model_name = test_segment.evaluate(\n", "    c3.EvaluateSpec(filter=f'id==\"{test_segment.id}\"',\n", "                    projection='primaryConfiguration.predictionModels[0].model.pipeline.steps[0].name'\n", ")).tuples[0].cells[0].value()\n", "print(f\"The primary configuration has a model with name: {primary_model_name}.\")"]}, {"cell_type": "code", "execution_count": null, "id": "646374e1", "metadata": {"ExecuteTime": {"end_time": "2022-06-21T01:20:12.831220Z", "start_time": "2022-06-21T01:20:12.701Z"}}, "outputs": [], "source": ["# # see all models deployed in this MLProject and their deployment status\n", "\n", "# pd.DataFrame(c3.MLProjectSubjectToModelRelation.fetch().objs.toJson())\n", "\n", "# # you can also view this table in the developer console to better view the nested/linked fields with\n", "# # c3Grid(MLProjectSubjectToModelRelation.fetch())"]}, {"cell_type": "code", "execution_count": null, "id": "19af1deb", "metadata": {"ExecuteTime": {"end_time": "2022-06-21T01:20:12.831870Z", "start_time": "2022-06-21T01:20:12.702Z"}}, "outputs": [], "source": ["primary_model_dict = pd.DataFrame(c3.MLProjectSubjectToModelRelation.fetch({\n", "                                                                            \"filter\": \"isPrimary == true\"\n", "                                                                          }).objs.toJson())[\"to\"].tolist()\n", "ids = []\n", "for item in primary_model_dict:\n", "    ids.append(item[\"id\"])\n", "    \n", "ids = list(set(ids))\n", "# print(ids)\n", "if len(ids) == 1:\n", "    primary_model_id = ids[0]\n", "    print(f\"The primary model deployed on the test segment has the id: {primary_model_id}.\")\n", "elif len(ids) > 1: \n", "    print(\"There appears to be more than 1 LIVE model deployed in this project!\")\n", "    print(ids)\n", "else:\n", "    print(\"No LIVE model could be found for this project!\")"]}, {"cell_type": "markdown", "id": "0c31f350", "metadata": {}, "source": ["### Retrieve a MLModel that you wish to deploy as `CHALLENGER`:"]}, {"cell_type": "markdown", "id": "0e290cae", "metadata": {}, "source": ["The id here should be the id of a previously trained and tuned MLModel from **Section 13** of your experimentation notebook:"]}, {"cell_type": "code", "execution_count": null, "id": "25b4ccc8", "metadata": {"ExecuteTime": {"end_time": "2022-06-21T01:20:12.832445Z", "start_time": "2022-06-21T01:20:12.703Z"}}, "outputs": [], "source": ["challenger_model = c3.MLModel.get('MyTrainedAndTunedMLModelId') # MLModel id from the last cell in notebook 04"]}, {"cell_type": "markdown", "id": "bf935ec0", "metadata": {}, "source": ["### Deploy model as a `CHALLENGER` Model on the Test Segment:"]}, {"cell_type": "code", "execution_count": null, "id": "c173323d", "metadata": {"ExecuteTime": {"end_time": "2022-06-21T01:20:12.833012Z", "start_time": "2022-06-21T01:20:12.704Z"}}, "outputs": [], "source": ["prediction_config = test_segment.deployModels([challenger_model.configuration], c3.MLModelLabel.CHALLENGER)"]}, {"cell_type": "code", "execution_count": null, "id": "033cc69c", "metadata": {"ExecuteTime": {"end_time": "2022-06-21T01:20:12.833622Z", "start_time": "2022-06-21T01:20:12.705Z"}}, "outputs": [], "source": ["test_segment.updateModels()"]}, {"cell_type": "markdown", "id": "901eccf1", "metadata": {}, "source": ["### Check that your model has successfully deployed as a `CHALLENGER` Model on the Test Segment:"]}, {"cell_type": "code", "execution_count": null, "id": "cea69d5c", "metadata": {"ExecuteTime": {"end_time": "2022-06-21T01:20:12.834167Z", "start_time": "2022-06-21T01:20:12.707Z"}}, "outputs": [], "source": ["# pd.DataFrame(c3.MLProjectSubjectToModelRelation.fetch().objs.toJson())"]}, {"cell_type": "code", "execution_count": null, "id": "1f6ae611", "metadata": {"ExecuteTime": {"end_time": "2022-06-21T01:20:12.834775Z", "start_time": "2022-06-21T01:20:12.708Z"}}, "outputs": [], "source": ["# pd.DataFrame(pd.DataFrame(c3.MLProjectSubjectToModelRelation.fetch().objs.toJson())[\"status\"])\n", "pd.DataFrame(c3.MLProjectSubjectToModelRelation.fetch({\n", "                                                                            \"filter\": f\"to == '{challenger_model.id}'\"\n", "                                                                          }).objs.toJson())[\"status\"].tolist()[0]"]}, {"cell_type": "markdown", "id": "bf458e3d", "metadata": {"heading_collapsed": true}, "source": ["### \ud83c\udf89\ud83c\udf89\ud83c\udf89\n", "### Awesome! You've just deployed your trained, tuned model in an existing production system as a ```CHALLENGER``` model, using all of the features and hyperparameters you determined, exactly as you designed them.\n", "### \ud83c\udf89\ud83c\udf89\ud83c\udf89"]}, {"cell_type": "markdown", "id": "312268d4", "metadata": {}, "source": ["### Now let's compare the ```CHALLENGER``` model to the ```LIVE``` model."]}, {"cell_type": "markdown", "id": "88db6ab9", "metadata": {}, "source": ["Run a `Prediction Job` to automatically generate and persist predictions for all active models on the test segment:"]}, {"cell_type": "code", "execution_count": null, "id": "112a172f", "metadata": {"ExecuteTime": {"end_time": "2022-06-21T01:20:12.835347Z", "start_time": "2022-06-21T01:20:12.709Z"}}, "outputs": [], "source": ["pred_job = test_segment.predict(None, c3.MLPredictionJobOptions(batchSize=1), \n", "                                      c3.MLModelPredictSpec(allActiveModels=True,\n", "                                      pipelineSpec=c3.MLProcessSpec(disableGpu=True)))\n"]}, {"cell_type": "code", "execution_count": null, "id": "4f289024", "metadata": {"ExecuteTime": {"end_time": "2022-06-21T01:20:12.835964Z", "start_time": "2022-06-21T01:20:12.710Z"}}, "outputs": [], "source": ["# pred_job.status()\n", "\n", "monitor_job_status(pred_job)"]}, {"cell_type": "markdown", "id": "8e839a45", "metadata": {}, "source": ["### Compare `LIVE` and `CHALLENGER` models:"]}, {"cell_type": "markdown", "id": "d323ad58", "metadata": {}, "source": ["Retrieve and plot predictions for one bulb in the test segment:"]}, {"cell_type": "code", "execution_count": null, "id": "4e1aef6c", "metadata": {"ExecuteTime": {"end_time": "2022-06-21T01:20:12.836518Z", "start_time": "2022-06-21T01:20:12.711Z"}}, "outputs": [], "source": ["predictions_emr = c3.MLModel.evalMetrics(spec=c3.EvalMetricsSpec(\n", "    ids=[challenger_model.id], expressions=[\"MLProjectPrediction\"], \n", "    start=\"2016-01-01\", end=\"2021-01-01\",\n", "    bindings=[{\"subjectId\": \"SMBLB23\"}], # change your subject id here to another id in the test segment to see other predictions\n", "    interval=\"HOUR\",\n", "    resultKey=c3.Lambda.fromPython(\"lambda expression, bindings: expression + ('_' + bindings.get('featName', '') if expression == 'MLProjectContribution' else '')\")\n", "))"]}, {"cell_type": "code", "execution_count": null, "id": "844dd4af", "metadata": {"ExecuteTime": {"end_time": "2022-06-21T01:20:12.837158Z", "start_time": "2022-06-21T01:20:12.712Z"}}, "outputs": [], "source": ["c3.EvalMetricsResult.toPandas(predictions_emr, multiIndexed=True).droplevel(0).plot(figsize=(16, 4))"]}, {"cell_type": "markdown", "id": "7969be1b", "metadata": {}, "source": ["Run a `Scoring Job` to automatically generate and persist predictions for all active models on the test segment:"]}, {"cell_type": "code", "execution_count": null, "id": "e0edecb4", "metadata": {"ExecuteTime": {"end_time": "2022-06-21T01:20:12.837663Z", "start_time": "2022-06-21T01:20:12.713Z"}}, "outputs": [], "source": ["score_job = test_segment.score(None, c3.MLScoreJobOptions(batchSize=10), \n", "                                      c3.MLModelScoreSpec(allActiveModels=True))\n"]}, {"cell_type": "code", "execution_count": null, "id": "f29f98a5", "metadata": {"ExecuteTime": {"end_time": "2022-06-21T01:20:12.838261Z", "start_time": "2022-06-21T01:20:12.714Z"}, "scrolled": false}, "outputs": [], "source": ["while (score_job.status().status not in ['completed', 'completed with errors', 'failed']):\n", "    print(score_job.status().status)\n", "    time.sleep(10)\n", "    \n", "# score_job.status()\n", "\n", "monitor_job_status(score_job)"]}, {"cell_type": "markdown", "id": "b50f9fec", "metadata": {}, "source": ["Retrieve Results from the Scoring Job for the `CHALLENGER` model:"]}, {"cell_type": "code", "execution_count": null, "id": "12d58504", "metadata": {"ExecuteTime": {"end_time": "2022-06-21T01:20:12.838863Z", "start_time": "2022-06-21T01:20:12.715Z"}}, "outputs": [], "source": ["from datetime import timedelta\n", "start = challenger_model.get(\"scores.data.this\").scores[0].data[0].start\n", "scores_emr = c3.MLModel.evalMetrics(spec=c3.EvalMetricsSpec(\n", "                ids=[challenger_model.id], expressions=[\"Score\"], \n", "                start=start - timedelta(1), end=start + timedelta(hours=12),\n", "                bindings=[{'scoringMetricName': 'MLF1ScoreMetric'}],\n", "                interval=\"DAY\",\n", "                resultKey=c3.Lambda.fromPython(\"lambda expression, bindings: expression + '_' + bindings['scoringMetricName']\")\n", "))\n"]}, {"cell_type": "code", "execution_count": null, "id": "3813e9b1", "metadata": {"ExecuteTime": {"end_time": "2022-06-21T01:20:12.839377Z", "start_time": "2022-06-21T01:20:12.716Z"}}, "outputs": [], "source": ["scores_df = c3.EvalMetricsResult.toPandas(scores_emr, multiIndexed=True).droplevel(0)"]}, {"cell_type": "code", "execution_count": null, "id": "53b96141", "metadata": {"ExecuteTime": {"end_time": "2022-06-21T01:20:12.840006Z", "start_time": "2022-06-21T01:20:12.717Z"}}, "outputs": [], "source": ["scores_df"]}, {"cell_type": "code", "execution_count": null, "id": "fafbd332", "metadata": {"ExecuteTime": {"end_time": "2022-06-21T01:20:12.840533Z", "start_time": "2022-06-21T01:20:12.717Z"}, "scrolled": true}, "outputs": [], "source": ["c3.EvalMetricsResult.toPandas(scores_emr, multiIndexed=True).droplevel(0).plot(figsize=(12, 4), marker='x', grid=True, subplots=True)"]}, {"cell_type": "markdown", "id": "394d9cec", "metadata": {}, "source": ["Call an instance of the `LIVE` model deployed on the test segment, using the id of the primary model you retrieved earlier in this notebook."]}, {"cell_type": "code", "execution_count": null, "id": "2e9d2061", "metadata": {"ExecuteTime": {"end_time": "2022-06-21T01:20:12.841046Z", "start_time": "2022-06-21T01:20:12.718Z"}}, "outputs": [], "source": ["live_model = c3.MLModel.get(primary_model_id)"]}, {"cell_type": "markdown", "id": "3b511d19", "metadata": {}, "source": ["Retrieve Results from the Scoring Job for the `LIVE` model:"]}, {"cell_type": "code", "execution_count": null, "id": "9ffcf758", "metadata": {"ExecuteTime": {"end_time": "2022-06-21T01:20:12.841615Z", "start_time": "2022-06-21T01:20:12.719Z"}}, "outputs": [], "source": ["start = live_model.get(\"scores.data.this\").scores[0].data[0].start\n", "scores_emr = c3.MLModel.evalMetrics(spec=c3.EvalMetricsSpec(\n", "                ids=[live_model.id], expressions=[\"Score\"], \n", "                start=start - timedelta(1), end=start + timedelta(hours=12),\n", "                bindings=[{'scoringMetricName': 'MLF1ScoreMetric'}],\n", "                interval=\"DAY\",\n", "                resultKey=c3.Lambda.fromPython(\"lambda expression, bindings: expression + '_' + bindings['scoringMetricName']\")\n", "))\n", "\n"]}, {"cell_type": "code", "execution_count": null, "id": "22367e2c", "metadata": {"ExecuteTime": {"end_time": "2022-06-21T01:20:12.842439Z", "start_time": "2022-06-21T01:20:12.720Z"}}, "outputs": [], "source": ["scores_df = c3.EvalMetricsResult.toPandas(scores_emr, multiIndexed=True).droplevel(0)"]}, {"cell_type": "code", "execution_count": null, "id": "015ce1cd", "metadata": {"ExecuteTime": {"end_time": "2022-06-21T01:20:12.842999Z", "start_time": "2022-06-21T01:20:12.721Z"}}, "outputs": [], "source": ["scores_df"]}, {"cell_type": "code", "execution_count": 5, "id": "6b2e60ad", "metadata": {"ExecuteTime": {"end_time": "2022-06-21T01:20:47.274503Z", "start_time": "2022-06-21T01:20:47.266605Z"}}, "outputs": [{"ename": "NameError", "evalue": "name 'scores_emr' is not defined", "output_type": "error", "traceback": ["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m", "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)", "\u001b[0;32m<ipython-input-5-46a60075bdc7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mc3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEvalMetricsResult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoPandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores_emr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultiIndexed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdroplevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmarker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubplots\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m", "\u001b[0;31mNameError\u001b[0m: name 'scores_emr' is not defined"]}], "source": ["c3.EvalMetricsResult.toPandas(scores_emr, multiIndexed=True).droplevel(0).plot(figsize=(12, 4), marker='x', grid=True, subplots=True)"]}, {"cell_type": "markdown", "id": "815c8522", "metadata": {}, "source": ["## **Congratulations** \n", "on successfully deploying multiple models on the test segment and successfully comparing their performance! If you are satisfied with the performance of your `CHALLENGER` model, submit this model's id for your capstone submission. If you would like to go back to notebook 04 and continue to iterate and experiment to improve model performance, feel free to do so -- you can deploy as many `CHALLENGER` models as you would like!"]}], "metadata": {"has_local_update": false, "is_local": true, "is_remote": true, "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.8.10"}, "last_sync_time": "2022-06-19T23:30:04.361825"}, "nbformat": 4, "nbformat_minor": 5}