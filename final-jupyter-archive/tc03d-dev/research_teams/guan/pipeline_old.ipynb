{"cells": [{"cell_type": "code", "execution_count": 1, "metadata": {"ExecuteTime": {"end_time": "2021-09-20T17:50:14.539466Z", "start_time": "2021-09-20T17:50:13.922434Z"}}, "outputs": [], "source": ["from azure.storage.blob import *"]}, {"cell_type": "code", "execution_count": 1, "metadata": {"ExecuteTime": {"end_time": "2021-09-22T21:42:40.977981Z", "start_time": "2021-09-22T21:42:40.819053Z"}}, "outputs": [], "source": ["import gdal"]}, {"cell_type": "code", "execution_count": 1, "metadata": {"ExecuteTime": {"end_time": "2021-09-14T20:11:07.291588Z", "start_time": "2021-09-14T20:11:06.624319Z"}}, "outputs": [], "source": ["# downloading utilities\n", "import requests\n", "import json\n", "from requests.auth import HTTPBasicAuth\n", "import urllib.request\n", "# progress and file \n", "from tqdm import tqdm\n", "# file processing utils\n", "import os\n", "from glob import glob\n", "from multiprocessing import Pool\n", "# geotiff util\n", "import rasterio"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# Download file from Planet\n", "\n", "This downloads the images from PlanetLab API in quads. Each quad is approximately 4000 pixel * 4000 pixels and sizes around 100MB. \n", "\n", "For each year, Champaign has 20 quads, Illinois has 978 quads, and the entire US midwest has about 10,000 quads.\n", "\n", "We want to do this for every year from 2017 to 2021."]}, {"cell_type": "code", "execution_count": 4, "metadata": {"ExecuteTime": {"end_time": "2021-09-14T20:11:26.618394Z", "start_time": "2021-09-14T20:11:26.166944Z"}}, "outputs": [{"ename": "KeyError", "evalue": "'items'", "output_type": "error", "traceback": ["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m", "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)", "\u001b[0;32m/tmp/ipykernel_17811/1037499931.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'items'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pathto/2008w2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;31mKeyError\u001b[0m: 'items'"]}], "source": ["BASE_URL = 'https://api.planet.com/basemaps/v1/mosaics/'\n", "API_KEY = '' # obmitted\n", "auth = HTTPBasicAuth(API_KEY, '')\n", "\n", "mosaic_id = '56f00cc2-6be4-4315-9603-c75d6afab225'\n", "url = f'{BASE_URL}{mosaic_id}/quads'\n", "bbox = '-91.51307900019566, 36.970297999852846, -87.49519900023363, 42.50848099959849' #update bbox and page_size\n", "res = requests.get(url=url, auth=auth, params={'bbox':bbox, '_page_size':99999}) \n", "out = json.loads(res.text)\n", "\n", "for i in tqdm(out['items']):\n", "    if i['id'] in os.listdir('pathto/2008w2'):\n", "        continue\n", "    urllib.request.urlretrieve(i['_links']['download'], f\"pathto/2008w2/original/{i['id']}.tif\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# Preprocess\n", "\n", "This reprojects quad into a different coordinates and upscales the quad. The upscaled size is around 250MB.\n", "\n", "Note:\n", " - Memory is fine since each quad will take 350MB at max (I think). I have 16Gb on local machine and 10 processes are OK.\n", " - It will probably be faster if we do upscale while downloading.\n", " - Also we probably need to replace the system call to python gdal package (according to the meeting).\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["\n", "def upscale(fname):\n", "    print(\"processing \", fname)\n", "    out_fname = fname.replace('original', 'warp')\n", "    if os.path.isfile(out_fname):\n", "        print(\"already exists\")\n", "        return\n", "    os.system(f'gdalwarp -t_srs EPSG:32616 -tr 3 3 -r bilinear {fname} {out_fname}')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# pool multiple thread to preprocess image\n", "files = glob('pathto/2008w2/original/*tif')\n", "print(files)\n", "p = Pool(10)\n", "p.map(upscale, files)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# Prediction"]}, {"cell_type": "code", "execution_count": 4, "metadata": {"ExecuteTime": {"end_time": "2021-09-23T19:05:26.622515Z", "start_time": "2021-09-23T19:05:26.557895Z"}}, "outputs": [], "source": ["# TF stuffs\n", "from tensorflow.keras import Model\n", "from tensorflow.keras.layers import (\n", "    Conv2D, \n", "    concatenate, \n", "    Dropout, \n", "    Input, \n", "    Reshape,\n", "    BatchNormalization, \n", "    MaxPooling2D, \n", "    UpSampling2D, \n", "    ReLU, \n", "    Conv2DTranspose\n", ")\n", "# data processing pacakges\n", "import numpy as np\n", "import matplotlib.pyplot as plt"]}, {"cell_type": "code", "execution_count": 7, "metadata": {"ExecuteTime": {"end_time": "2021-09-23T19:06:32.421349Z", "start_time": "2021-09-23T19:06:32.412180Z"}}, "outputs": [{"name": "stderr", "output_type": "stream", "text": ["2021-09-23 19:06:32.413259: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n", "2021-09-23 19:06:32.414179: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n", "pciBusID: 0001:00:00.0 name: Tesla K80 computeCapability: 3.7\n", "coreClock: 0.8235GHz coreCount: 13 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 223.96GiB/s\n", "2021-09-23 19:06:32.414224: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n", "2021-09-23 19:06:32.414256: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n", "2021-09-23 19:06:32.414276: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n", "2021-09-23 19:06:32.414294: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n", "2021-09-23 19:06:32.414312: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n", "2021-09-23 19:06:32.414330: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n", "2021-09-23 19:06:32.414348: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n", "2021-09-23 19:06:32.414367: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n", "2021-09-23 19:06:32.415874: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n", "2021-09-23 19:06:32.415920: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n", "2021-09-23 19:06:32.415932: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n", "2021-09-23 19:06:32.415939: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n", "2021-09-23 19:06:32.417454: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/device:GPU:0 with 10623 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0001:00:00.0, compute capability: 3.7)\n"]}, {"data": {"text/plain": ["True"]}, "execution_count": 7, "metadata": {}, "output_type": "execute_result"}], "source": ["import tensorflow.compat.v1 as tf\n", "tf.test.is_gpu_available()"]}, {"cell_type": "code", "execution_count": 6, "metadata": {"ExecuteTime": {"end_time": "2021-09-23T19:05:31.269355Z", "start_time": "2021-09-23T19:05:31.236719Z"}}, "outputs": [{"ename": "AttributeError", "evalue": "module 'tensorflow.compat.v1.test' has no attribute 'is_bult_with_cuda'", "output_type": "error", "traceback": ["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m", "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)", "\u001b[0;32m/tmp/ipykernel_6064/4237098594.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_bult_with_cuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m", "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow.compat.v1.test' has no attribute 'is_bult_with_cuda'"]}], "source": ["tf.test.is_bult_with_cuda()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Define model"]}, {"cell_type": "code", "execution_count": 3, "metadata": {"ExecuteTime": {"end_time": "2021-09-14T20:11:17.863805Z", "start_time": "2021-09-14T20:11:17.850198Z"}}, "outputs": [], "source": ["# unet model\n", "def conv2d_block(input_tensor, n_filters, kernel_size = 3, batchnorm = True):\n", "    \"\"\"Function to add 2 convolutional layers with the parameters passed to it\"\"\"\n", "    # first layer\n", "    x = Conv2D(filters = n_filters, kernel_size = (kernel_size, kernel_size),\\\n", "              kernel_initializer = 'he_normal', padding = 'same')(input_tensor)\n", "    if batchnorm:\n", "        x = BatchNormalization()(x)\n", "    x = ReLU()(x)\n", "    \n", "    # second layer\n", "    x = Conv2D(filters = n_filters, kernel_size = (kernel_size, kernel_size),\\\n", "              kernel_initializer = 'he_normal', padding = 'same')(x)\n", "    if batchnorm:\n", "        x = BatchNormalization()(x)\n", "    x = ReLU()(x)\n", "    \n", "    return x\n", "\n", "def get_unet(input_img, n_filters = 16, dropout = 0.1, batchnorm = True):\n", "    \"\"\"Function to define the UNET Model\"\"\"\n", "    # Contracting Path\n", "    c1 = conv2d_block(input_img, n_filters * 1, kernel_size = 3, batchnorm = batchnorm)\n", "    p1 = MaxPooling2D((2, 2))(c1)\n", "    p1 = Dropout(dropout)(p1)\n", "    \n", "    c2 = conv2d_block(p1, n_filters * 2, kernel_size = 3, batchnorm = batchnorm)\n", "    p2 = MaxPooling2D((2, 2))(c2)\n", "    p2 = Dropout(dropout)(p2)\n", "    \n", "    c3 = conv2d_block(p2, n_filters * 4, kernel_size = 3, batchnorm = batchnorm)\n", "    p3 = MaxPooling2D((2, 2))(c3)\n", "    p3 = Dropout(dropout)(p3)\n", "    \n", "    c4 = conv2d_block(p3, n_filters * 8, kernel_size = 3, batchnorm = batchnorm)\n", "    p4 = MaxPooling2D((2, 2))(c4)\n", "    p4 = Dropout(dropout)(p4)\n", "    \n", "    c5 = conv2d_block(p4, n_filters = n_filters * 16, kernel_size = 3, batchnorm = batchnorm)\n", "    \n", "    # Expansive Path\n", "    u6 = Conv2DTranspose(n_filters * 8, (3, 3), strides = (2, 2), padding = 'same')(c5)\n", "    u6 = concatenate([u6, c4])\n", "    u6 = Dropout(dropout)(u6)\n", "    c6 = conv2d_block(u6, n_filters * 8, kernel_size = 3, batchnorm = batchnorm)\n", "    \n", "    u7 = Conv2DTranspose(n_filters * 4, (3, 3), strides = (2, 2), padding = 'same')(c6)\n", "    u7 = concatenate([u7, c3])\n", "    u7 = Dropout(dropout)(u7)\n", "    c7 = conv2d_block(u7, n_filters * 4, kernel_size = 3, batchnorm = batchnorm)\n", "    \n", "    u8 = Conv2DTranspose(n_filters * 2, (3, 3), strides = (2, 2), padding = 'same')(c7)\n", "    u8 = concatenate([u8, c2])\n", "    u8 = Dropout(dropout)(u8)\n", "    c8 = conv2d_block(u8, n_filters * 2, kernel_size = 3, batchnorm = batchnorm)\n", "    \n", "    u9 = Conv2DTranspose(n_filters * 1, (3, 3), strides = (2, 2), padding = 'same')(c8)\n", "    u9 = concatenate([u9, c1])\n", "    u9 = Dropout(dropout)(u9)\n", "    c9 = conv2d_block(u9, n_filters * 1, kernel_size = 3, batchnorm = batchnorm)\n", "    \n", "    outputs = Conv2D(1, (1, 1), activation='sigmoid')(c9)\n", "    model = Model(input_img, outputs)\n", "    model.summary()\n", "    return model"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# some constant and define tf memory behavior\n", "CKPT_DIR = 'pathto/ckpt1/unet_train_100.tf'\n", "FILE_DIR = 'pathto/2008w2/warp/*tif'\n", "OUT_DIR = 'pathto/2008w2/pred/'\n", "THRESHOLD = 0.5\n", "img_size = (224, 224, 5)\n", "physical_devices = tf.config.list_physical_devices('GPU')\n", "tf.config.experimental.set_memory_growth(physical_devices[0], True) # this needs to be changed if multiple GPU"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Get model and load trained model"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# load trained model\n", "input_img = Input(img_size, name='img')\n", "model = get_unet(input_img, n_filters=32, dropout=0.15, batchnorm=True)\n", "model.load_weights(CKPT_DIR)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Prediction function that handles a file"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def predict_tiff(net, tiff_path, add_gcvi=False):\n", "    base_img = rasterio.open(tiff_path).read()\n", "    base_img = np.transpose(base_img, [1, 2, 0])\n", "    base_img = base_img[:, :, :4]\n", "    if add_gcvi:\n", "        gcvi = base_img[:, :, 3] / base_img[:, :, 1]\n", "        gcvi = gcvi - 1\n", "        gcvi[gcvi > 20] = 20\n", "        gcvi[gcvi < 0] = 0\n", "        gcvi = np.nan_to_num(gcvi, False, 0, 0, 0)\n", "        gcvi = np.expand_dims(gcvi, -1)\n", "        base_img = np.concatenate([base_img, gcvi], 2) \n", "    \n", "    # track original size and calc how many cuts\n", "    h, w, c = base_img.shape\n", "    h_count = int(h/img_size) + 1\n", "    w_count = int(w/img_size) + 1\n", "\n", "    # calculate padded height and width\n", "    h_padded = h_count * img_size\n", "    w_padded = w_count * img_size\n", "\n", "    # Pad image and cut into img_size * img_size\n", "    base_img = np.pad(base_img, ((0, h_padded - h), (0, w_padded-w), (0,0)), 'constant')\n", "    base_img = np.reshape(base_img, (h_count, img_size, w_count, img_size, c))\n", "    base_img = np.transpose(base_img, axes=(0, 2, 1, 3, 4))\n", "    base_img = np.reshape(base_img, (-1, img_size, img_size, c)) # nhwc\n", "\n", "    # Predict\n", "    out = net.predict(base_img, batch_size = 8)\n", "\n", "    # Convert back\n", "    combined = np.zeros((h_padded, w_padded))\n", "    x = 0\n", "    idx = 0\n", "    while x < combined.shape[0]:\n", "        y = 0\n", "        while y < combined.shape[1]:\n", "            combined[x:x+img_size, y:y+img_size] = np.squeeze(out[idx], 2)\n", "            y += img_size\n", "            idx += 1\n", "        x += img_size\n", "    combined_cut = np.array(combined)\n", "    # Trim\n", "    return combined_cut[:h, :w]\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def export_tif(fn, file_name, mask):\n", "    meta = rasterio.open(fn).meta.copy()\n", "    meta.update({\n", "        'count':1,\n", "        'dtype':np.uint8\n", "    })\n", "    mask[mask > 0.5] = 1\n", "    mask[mask < 1] = 0\n", "    mask = mask.astype(np.uint8)\n", "    with rasterio.open(os.path.join(OUT_DIR,file_name), 'w', **meta) as dest:\n", "        dest.write(np.expand_dims(mask, 0))\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Prediction driver\n", "\n", "Essential loops through every file, pipe them through the model and save the output.\n", "\n", "We could streamline is process, i.e., schedule load - predict - save for better performance."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["for fn in tqdm(glob(FILE_DIR)):\n", "    if 'udm' in fn:\n", "        continue\n", "\n", "    if 'tif' not in fn:\n", "        continue\n", "\n", "    file_name = fn.split('\\\\')[-1]    \n", "    if file_name in os.listdir(OUT_DIR):\n", "        print(f'Already Found: {file_name}...skipping')\n", "        continue\n", "\n", "    out_fn = os.path.join(OUT_DIR, file_name)\n", "    mask = predict_tiff(net = model,\n", "                tiff_path = fn,\n", "                add_gcvi = True)\n", "    # we can probably throw this to a different thread\n", "    export_tif(fn, file_name, mask)\n", "    # it's optional to save these two formats\n", "    np.save(os.path.join(OUT_DIR, file_name.split('.')[0] + '.npy'), mask)\n", "    plt.imsave(os.path.join(OUT_DIR, file_name.split('.')[0] + '.png'), mask)\n"]}], "metadata": {"has_local_update": false, "is_local": true, "is_remote": true, "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.8.8"}, "last_sync_time": "2021-12-16T21:23:13.298308"}, "nbformat": 4, "nbformat_minor": 2}