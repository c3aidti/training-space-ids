{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {"ExecuteTime": {"end_time": "2022-01-25T22:11:16.172016Z", "start_time": "2022-01-25T22:11:16.006061Z"}}, "outputs": [], "source": ["# downloading utilities\n", "import requests\n", "import json\n", "from requests.auth import HTTPBasicAuth\n", "import urllib.request\n", "# progress and file \n", "from tqdm import tqdm\n", "# file processing utils\n", "import os\n", "from glob import glob\n", "from multiprocessing import Pool\n", "# geotiff util\n", "import rasterio"]}, {"cell_type": "code", "execution_count": null, "metadata": {"ExecuteTime": {"end_time": "2022-01-25T20:16:43.600406Z", "start_time": "2022-01-25T20:16:43.590459Z"}}, "outputs": [], "source": ["os.getcwd()"]}, {"cell_type": "code", "execution_count": null, "metadata": {"ExecuteTime": {"end_time": "2022-01-25T20:16:43.818064Z", "start_time": "2022-01-25T20:16:43.601844Z"}}, "outputs": [], "source": ["from azure.storage.blob import BlobServiceClient, BlobClient, ContainerClient, __version__ "]}, {"cell_type": "code", "execution_count": null, "metadata": {"ExecuteTime": {"end_time": "2022-01-25T20:16:43.883204Z", "start_time": "2022-01-25T20:16:43.820073Z"}}, "outputs": [], "source": ["connect_str = \"DefaultEndpointsProtocol=https;AccountName=yihongponding;AccountKey=hnvkEWfrIeYEyLUFcYYKyjujkSWiWcPdV/mS8O5GJ51iWPAkni7opzaA7klbwIGpGY0JANb5pRjGBe1ekHbX9Q==;EndpointSuffix=core.windows.net\"\n", "blob_service_client = BlobServiceClient.from_connection_string(connect_str)\n", "container_client = blob_service_client.get_container_client(\"ponding-il\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {"ExecuteTime": {"end_time": "2022-01-25T20:16:45.847727Z", "start_time": "2022-01-25T20:16:45.536099Z"}, "scrolled": true}, "outputs": [], "source": ["blobs = container_client.list_blobs()\n", "for b in blobs:\n", "    print(b.name)"]}, {"cell_type": "code", "execution_count": null, "metadata": {"ExecuteTime": {"end_time": "2022-01-25T20:16:59.926493Z", "start_time": "2022-01-25T20:16:57.213710Z"}}, "outputs": [], "source": ["blob_client = blob_service_client.get_blob_client(container=\"ponding-il\", blob=\"503-1291.tif\")\n", "download_file_path = \"503-1291.tif\"\n", "with open(download_file_path, \"wb\") as download_file:\n", "    download_file.write(blob_client.download_blob().readall())"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# Download file from Planet\n", "\n", "This downloads the images from PlanetLab API in quads. Each quad is approximately 4000 pixel * 4000 pixels and sizes around 100MB. \n", "\n", "For each year, Champaign has 20 quads, Illinois has 978 quads, and the entire US midwest has about 10,000 quads.\n", "\n", "We want to do this for every year from 2017 to 2021."]}, {"cell_type": "code", "execution_count": null, "metadata": {"ExecuteTime": {"end_time": "2021-09-22T19:51:37.065880Z", "start_time": "2021-09-22T19:51:24.265110Z"}}, "outputs": [], "source": ["BASE_URL = 'https://api.planet.com/basemaps/v1/mosaics/'\n", "API_KEY = '8fb5d85cdcfc40f6b4b9d3f44227142b' # obmitted\n", "auth = HTTPBasicAuth(API_KEY, '')\n", "\n", "mosaic_id = '56f00cc2-6be4-4315-9603-c75d6afab225'\n", "url = f'{BASE_URL}{mosaic_id}/quads'\n", "bbox = '-91.51307900019566, 36.970297999852846, -87.49519900023363, 42.50848099959849' #update bbox and page_size\n", "res = requests.get(url=url, auth=auth, params={'bbox':bbox, '_page_size':99999}) \n", "out = json.loads(res.text)\n", "\n", "for i in tqdm(out['items']):\n", "    if i['id'] in os.listdir('./tmp_img/'):\n", "        continue\n", "    urllib.request.urlretrieve(i['_links']['download'], f\"./tmp_img/{i['id']}.tif\")\n", "    break"]}, {"cell_type": "code", "execution_count": null, "metadata": {"ExecuteTime": {"end_time": "2021-09-23T21:03:46.004125Z", "start_time": "2021-09-23T21:03:44.748685Z"}}, "outputs": [], "source": ["arr = rasterio.open(\"503-1291.tif\").read()"]}, {"cell_type": "code", "execution_count": null, "metadata": {"ExecuteTime": {"end_time": "2021-12-02T08:51:30.445798Z", "start_time": "2021-12-02T08:51:24.683482Z"}}, "outputs": [], "source": ["help(\"modules\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# Preprocess\n", "\n", "This reprojects quad into a different coordinates and upscales the quad. The upscaled size is around 250MB.\n", "\n", "Note:\n", " - Memory is fine since each quad will take 350MB at max (I think). I have 16Gb on local machine and 10 processes are OK.\n", " - It will probably be faster if we do upscale while downloading.\n", " - Also we probably need to replace the system call to python gdal package (according to the meeting).\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"ExecuteTime": {"end_time": "2022-01-25T21:51:39.888837Z", "start_time": "2022-01-25T21:51:39.883885Z"}}, "outputs": [], "source": ["'''\n", "def upscale(fname):\n", "    print(\"processing \", fname)\n", "    out_fname = fname.replace('.tif', '-warp.tif')\n", "    if os.path.isfile(out_fname):\n", "        print(\"already exists\")\n", "        return\n", "    os.system(f'gdalwarp -t_srs EPSG:32616 -tr 3 3 -r bilinear {fname} {out_fname}')\n", "    \n", "    # pool multiple thread to preprocess image\n", "files = glob('./*tif')\n", "print(files)\n", "p = Pool(10)\n", "p.map(upscale, files)\n", "'''\n"]}, {"cell_type": "code", "execution_count": 12, "metadata": {"ExecuteTime": {"end_time": "2022-01-27T22:14:56.881051Z", "start_time": "2022-01-27T22:14:56.873904Z"}}, "outputs": [{"ename": "ModuleNotFoundError", "evalue": "No module named 'pyproj'", "output_type": "error", "traceback": ["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m", "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)", "\u001b[0;32m/tmp/ipykernel_2365/3151878560.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpyproj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m", "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pyproj'"]}], "source": ["import pyproj"]}, {"cell_type": "code", "execution_count": 1, "metadata": {"ExecuteTime": {"end_time": "2022-01-28T16:07:01.679997Z", "start_time": "2022-01-28T16:07:01.582140Z"}}, "outputs": [{"data": {"text/plain": ["'3000200'"]}, "execution_count": 1, "metadata": {}, "output_type": "execute_result"}], "source": ["import gdal\n", "gdal.VersionInfo()"]}, {"cell_type": "code", "execution_count": 2, "metadata": {"ExecuteTime": {"end_time": "2022-01-28T16:07:01.684109Z", "start_time": "2022-01-28T16:07:01.681230Z"}}, "outputs": [], "source": ["import os\n", "os.environ['PROJ_LIB'] = os.getenv('HOME') + '/.conda/envs/py-image_preprocess/share/proj'\n", "os.environ['GDAL_DATA'] = os.getenv('HOME') + '/.conda/envs/py-image_preprocess/share'"]}, {"cell_type": "code", "execution_count": 11, "metadata": {"ExecuteTime": {"end_time": "2022-01-28T15:38:48.412018Z", "start_time": "2022-01-28T15:38:48.407821Z"}}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["/home/c3\n", "/home/c3/.conda/envs/py-image_preprocess/share/proj\n"]}], "source": ["print(os.getenv('HOME'))\n", "print(os.environ['PROJ_LIB'])"]}, {"cell_type": "code", "execution_count": 1, "metadata": {"ExecuteTime": {"end_time": "2022-01-27T22:03:26.692785Z", "start_time": "2022-01-27T22:03:26.603778Z"}}, "outputs": [{"data": {"text/plain": ["'3.0.2'"]}, "execution_count": 1, "metadata": {}, "output_type": "execute_result"}], "source": ["import osgeo.gdal\n", "osgeo.gdal.__version__"]}, {"cell_type": "code", "execution_count": 2, "metadata": {"ExecuteTime": {"end_time": "2022-01-27T22:03:37.028409Z", "start_time": "2022-01-27T22:03:37.024445Z"}}, "outputs": [{"data": {"text/plain": ["(6, 2)"]}, "execution_count": 2, "metadata": {}, "output_type": "execute_result"}], "source": ["from osgeo import osr\n", "osr.GetPROJVersionMajor(), osr.GetPROJVersionMinor()"]}, {"cell_type": "code", "execution_count": 3, "metadata": {"ExecuteTime": {"end_time": "2022-01-28T16:07:03.261092Z", "start_time": "2022-01-28T16:07:03.251537Z"}, "scrolled": false}, "outputs": [], "source": ["options = gdal.WarpOptions(srcSRS='EPSG:3857', dstSRS = 'EPSG:32616', yRes=3, xRes=3)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# New heading"]}, {"cell_type": "code", "execution_count": 5, "metadata": {"ExecuteTime": {"end_time": "2022-01-28T16:09:09.611045Z", "start_time": "2022-01-28T16:09:07.280612Z"}}, "outputs": [{"data": {"text/plain": ["<osgeo.gdal.Dataset; proxy of <Swig Object of type 'GDALDatasetShadow *' at 0x7f711e699570> >"]}, "execution_count": 5, "metadata": {}, "output_type": "execute_result"}], "source": ["gdal.Warp(destNameOrDestDS='./503-1291-warp.tif', srcDSOrSrcDSTab='./503-1291.tif', options=options)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# Prediction"]}, {"cell_type": "code", "execution_count": null, "metadata": {"ExecuteTime": {"end_time": "2021-09-23T21:04:56.807298Z", "start_time": "2021-09-23T21:04:54.972286Z"}}, "outputs": [], "source": ["# TF stuffs\n", "import tensorflow as tf\n", "from tensorflow.keras import Model\n", "from tensorflow.keras.layers import (\n", "    Conv2D, \n", "    concatenate, \n", "    Dropout, \n", "    Input, \n", "    Reshape,\n", "    BatchNormalization, \n", "    MaxPooling2D, \n", "    UpSampling2D, \n", "    ReLU, \n", "    Conv2DTranspose\n", ")\n", "# data processing pacakges\n", "import numpy as np\n", "import matplotlib.pyplot as plt"]}, {"cell_type": "code", "execution_count": null, "metadata": {"ExecuteTime": {"end_time": "2021-09-23T20:49:09.324503Z", "start_time": "2021-09-23T20:49:09.319358Z"}}, "outputs": [], "source": ["tf.__version__"]}, {"cell_type": "code", "execution_count": null, "metadata": {"ExecuteTime": {"end_time": "2021-09-23T20:49:11.513807Z", "start_time": "2021-09-23T20:49:10.913394Z"}}, "outputs": [], "source": ["tf.config.list_physical_devices()"]}, {"cell_type": "code", "execution_count": null, "metadata": {"ExecuteTime": {"end_time": "2021-09-23T20:50:03.486006Z", "start_time": "2021-09-23T20:49:14.446349Z"}}, "outputs": [], "source": ["print(tf.test.is_gpu_available())\n", "print(tf.test.is_built_with_cuda())"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Define model"]}, {"cell_type": "code", "execution_count": null, "metadata": {"ExecuteTime": {"end_time": "2021-09-23T21:04:59.323083Z", "start_time": "2021-09-23T21:04:59.310213Z"}}, "outputs": [], "source": ["# unet model\n", "def conv2d_block(input_tensor, n_filters, kernel_size = 3, batchnorm = True):\n", "    \"\"\"Function to add 2 convolutional layers with the parameters passed to it\"\"\"\n", "    # first layer\n", "    x = Conv2D(filters = n_filters, kernel_size = (kernel_size, kernel_size),\\\n", "              kernel_initializer = 'he_normal', padding = 'same')(input_tensor)\n", "    if batchnorm:\n", "        x = BatchNormalization()(x)\n", "    x = ReLU()(x)\n", "    \n", "    # second layer\n", "    x = Conv2D(filters = n_filters, kernel_size = (kernel_size, kernel_size),\\\n", "              kernel_initializer = 'he_normal', padding = 'same')(x)\n", "    if batchnorm:\n", "        x = BatchNormalization()(x)\n", "    x = ReLU()(x)\n", "    \n", "    return x\n", "\n", "def get_unet(input_img, n_filters = 16, dropout = 0.1, batchnorm = True):\n", "    \"\"\"Function to define the UNET Model\"\"\"\n", "    # Contracting Path\n", "    c1 = conv2d_block(input_img, n_filters * 1, kernel_size = 3, batchnorm = batchnorm)\n", "    p1 = MaxPooling2D((2, 2))(c1)\n", "    p1 = Dropout(dropout)(p1)\n", "    \n", "    c2 = conv2d_block(p1, n_filters * 2, kernel_size = 3, batchnorm = batchnorm)\n", "    p2 = MaxPooling2D((2, 2))(c2)\n", "    p2 = Dropout(dropout)(p2)\n", "    \n", "    c3 = conv2d_block(p2, n_filters * 4, kernel_size = 3, batchnorm = batchnorm)\n", "    p3 = MaxPooling2D((2, 2))(c3)\n", "    p3 = Dropout(dropout)(p3)\n", "    \n", "    c4 = conv2d_block(p3, n_filters * 8, kernel_size = 3, batchnorm = batchnorm)\n", "    p4 = MaxPooling2D((2, 2))(c4)\n", "    p4 = Dropout(dropout)(p4)\n", "    \n", "    c5 = conv2d_block(p4, n_filters = n_filters * 16, kernel_size = 3, batchnorm = batchnorm)\n", "    \n", "    # Expansive Path\n", "    u6 = Conv2DTranspose(n_filters * 8, (3, 3), strides = (2, 2), padding = 'same')(c5)\n", "    u6 = concatenate([u6, c4])\n", "    u6 = Dropout(dropout)(u6)\n", "    c6 = conv2d_block(u6, n_filters * 8, kernel_size = 3, batchnorm = batchnorm)\n", "    \n", "    u7 = Conv2DTranspose(n_filters * 4, (3, 3), strides = (2, 2), padding = 'same')(c6)\n", "    u7 = concatenate([u7, c3])\n", "    u7 = Dropout(dropout)(u7)\n", "    c7 = conv2d_block(u7, n_filters * 4, kernel_size = 3, batchnorm = batchnorm)\n", "    \n", "    u8 = Conv2DTranspose(n_filters * 2, (3, 3), strides = (2, 2), padding = 'same')(c7)\n", "    u8 = concatenate([u8, c2])\n", "    u8 = Dropout(dropout)(u8)\n", "    c8 = conv2d_block(u8, n_filters * 2, kernel_size = 3, batchnorm = batchnorm)\n", "    \n", "    u9 = Conv2DTranspose(n_filters * 1, (3, 3), strides = (2, 2), padding = 'same')(c8)\n", "    u9 = concatenate([u9, c1])\n", "    u9 = Dropout(dropout)(u9)\n", "    c9 = conv2d_block(u9, n_filters * 1, kernel_size = 3, batchnorm = batchnorm)\n", "    \n", "    outputs = Conv2D(1, (1, 1), activation='sigmoid')(c9)\n", "    model = Model(input_img, outputs)\n", "    model.summary()\n", "    return model"]}, {"cell_type": "code", "execution_count": null, "metadata": {"ExecuteTime": {"end_time": "2021-09-23T21:05:04.324757Z", "start_time": "2021-09-23T21:05:04.257498Z"}}, "outputs": [], "source": ["# some constant and define tf memory behavior\n", "CKPT_DIR = './model_ckpt/unet_train_100.tf'\n", "FILE_DIR = './tmp_img/*tif'\n", "OUT_DIR = './tmp_pred/'\n", "THRESHOLD = 0.5\n", "img_size = (224, 224, 5)\n", "physical_devices = tf.config.list_physical_devices('GPU')\n", "tf.config.experimental.set_memory_growth(physical_devices[0], True) # this needs to be changed if multiple GPU"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Get model and load trained model"]}, {"cell_type": "code", "execution_count": null, "metadata": {"ExecuteTime": {"end_time": "2021-09-23T21:05:20.413427Z", "start_time": "2021-09-23T21:05:18.787439Z"}}, "outputs": [], "source": ["# load trained model\n", "input_img = Input(img_size, name='img')\n", "model = get_unet(input_img, n_filters=32, dropout=0.15, batchnorm=True)\n", "model.load_weights(CKPT_DIR)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Prediction function that handles a file"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def predict_tiff(net, tiff_path, add_gcvi=False):\n", "    base_img = rasterio.open(tiff_path).read()\n", "    base_img = np.transpose(base_img, [1, 2, 0])\n", "    base_img = base_img[:, :, :4]\n", "    if add_gcvi:\n", "        gcvi = base_img[:, :, 3] / base_img[:, :, 1]\n", "        gcvi = gcvi - 1\n", "        gcvi[gcvi > 20] = 20\n", "        gcvi[gcvi < 0] = 0\n", "        gcvi = np.nan_to_num(gcvi, False, 0, 0, 0)\n", "        gcvi = np.expand_dims(gcvi, -1)\n", "        base_img = np.concatenate([base_img, gcvi], 2) \n", "    \n", "    # track original size and calc how many cuts\n", "    h, w, c = base_img.shape\n", "    h_count = int(h/img_size) + 1\n", "    w_count = int(w/img_size) + 1\n", "\n", "    # calculate padded height and width\n", "    h_padded = h_count * img_size\n", "    w_padded = w_count * img_size\n", "\n", "    # Pad image and cut into img_size * img_size\n", "    base_img = np.pad(base_img, ((0, h_padded - h), (0, w_padded-w), (0,0)), 'constant')\n", "    base_img = np.reshape(base_img, (h_count, img_size, w_count, img_size, c))\n", "    base_img = np.transpose(base_img, axes=(0, 2, 1, 3, 4))\n", "    base_img = np.reshape(base_img, (-1, img_size, img_size, c)) # nhwc\n", "\n", "    # Predict\n", "    out = net.predict(base_img, batch_size = 8)\n", "\n", "    # Convert back\n", "    combined = np.zeros((h_padded, w_padded))\n", "    x = 0\n", "    idx = 0\n", "    while x < combined.shape[0]:\n", "        y = 0\n", "        while y < combined.shape[1]:\n", "            combined[x:x+img_size, y:y+img_size] = np.squeeze(out[idx], 2)\n", "            y += img_size\n", "            idx += 1\n", "        x += img_size\n", "    combined_cut = np.array(combined)\n", "    # Trim\n", "    return combined_cut[:h, :w]\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def export_tif(fn, file_name, mask):\n", "    meta = rasterio.open(fn).meta.copy()\n", "    meta.update({\n", "        'count':1,\n", "        'dtype':np.uint8\n", "    })\n", "    mask[mask > 0.5] = 1\n", "    mask[mask < 1] = 0\n", "    mask = mask.astype(np.uint8)\n", "    with rasterio.open(os.path.join(OUT_DIR,file_name), 'w', **meta) as dest:\n", "        dest.write(np.expand_dims(mask, 0))\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Prediction driver\n", "\n", "Essential loops through every file, pipe them through the model and save the output.\n", "\n", "We could streamline is process, i.e., schedule load - predict - save for better performance."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["for fn in tqdm(glob(FILE_DIR)):\n", "    if 'udm' in fn:\n", "        continue\n", "\n", "    if 'tif' not in fn:\n", "        continue\n", "\n", "    file_name = fn.split('\\\\')[-1]    \n", "    if file_name in os.listdir(OUT_DIR):\n", "        print(f'Already Found: {file_name}...skipping')\n", "        continue\n", "\n", "    out_fn = os.path.join(OUT_DIR, file_name)\n", "    mask = predict_tiff(net = model,\n", "                tiff_path = fn,\n", "                add_gcvi = True)\n", "    # we can probably throw this to a different thread\n", "    export_tif(fn, file_name, mask)\n", "    # it's optional to save these two formats\n", "    np.save(os.path.join(OUT_DIR, file_name.split('.')[0] + '.npy'), mask)\n", "    plt.imsave(os.path.join(OUT_DIR, file_name.split('.')[0] + '.png'), mask)\n"]}], "metadata": {"has_local_update": false, "is_local": true, "is_remote": true, "kernelspec": {"display_name": "py-image_preprocess", "language": "Python", "name": "py-image_preprocess"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.7.11"}, "last_sync_time": "2022-01-28T15:45:15.232565"}, "nbformat": 4, "nbformat_minor": 2}