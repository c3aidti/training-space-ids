{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Verify device with Torch"]}, {"cell_type": "code", "execution_count": 1, "metadata": {"ExecuteTime": {"end_time": "2021-08-09T22:03:20.519184Z", "start_time": "2021-08-09T22:03:20.333800Z"}}, "outputs": [], "source": ["import torch"]}, {"cell_type": "code", "execution_count": 2, "metadata": {"ExecuteTime": {"end_time": "2021-08-09T22:03:20.525595Z", "start_time": "2021-08-09T22:03:20.521113Z"}}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["No CUDA-GPU available from Torch perspective.\n"]}], "source": ["use_cuda = torch.cuda.is_available()\n", "if use_cuda:\n", "    print('Number of CUDA Devices:', torch.cuda.device_count())\n", "    print('CUDA Device Name:',torch.cuda.get_device_name(0))\n", "    print('CUDA Device Total Memory [GB]:',torch.cuda.get_device_properties(0).total_memory/1e9)\n", "    print('CUDA version:', torch.version.cuda)\n", "else:\n", "    print('No CUDA-GPU available from Torch perspective.')"]}, {"cell_type": "code", "execution_count": 3, "metadata": {"ExecuteTime": {"end_time": "2021-08-09T22:03:20.575770Z", "start_time": "2021-08-09T22:03:20.527717Z"}}, "outputs": [{"data": {"text/plain": ["False"]}, "execution_count": 3, "metadata": {}, "output_type": "execute_result"}], "source": ["torch.cuda.is_available()"]}, {"cell_type": "code", "execution_count": 4, "metadata": {"ExecuteTime": {"end_time": "2021-08-09T22:03:20.612138Z", "start_time": "2021-08-09T22:03:20.577493Z"}}, "outputs": [{"data": {"text/plain": ["0"]}, "execution_count": 4, "metadata": {}, "output_type": "execute_result"}], "source": ["torch.cuda.device_count()"]}, {"cell_type": "code", "execution_count": 5, "metadata": {"ExecuteTime": {"end_time": "2021-08-09T22:03:20.755573Z", "start_time": "2021-08-09T22:03:20.613531Z"}}, "outputs": [{"ename": "AssertionError", "evalue": "Torch not compiled with CUDA enabled", "output_type": "error", "traceback": ["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m", "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)", "\u001b[0;32m<ipython-input-5-3380d2c12118>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m", "\u001b[0;32m~/.conda/envs/py-copycat/lib/python3.6/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36mcurrent_device\u001b[0;34m()\u001b[0m\n\u001b[1;32m    384\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcurrent_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m     \u001b[0;34mr\"\"\"Returns the index of a currently selected device.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 386\u001b[0;31m     \u001b[0m_lazy_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    387\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_getDevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;32m~/.conda/envs/py-copycat/lib/python3.6/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    190\u001b[0m             raise RuntimeError(\n\u001b[1;32m    191\u001b[0m                 \"Cannot re-initialize CUDA in forked subprocess. \" + msg)\n\u001b[0;32m--> 192\u001b[0;31m         \u001b[0m_check_driver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0m_cudart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_load_cudart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;32m~/.conda/envs/py-copycat/lib/python3.6/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_check_driver\u001b[0;34m()\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_check_driver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_cuda_isDriverSufficient'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Torch not compiled with CUDA enabled\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_isDriverSufficient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_getDriverVersion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"]}], "source": ["torch.cuda.current_device()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# Verify device with Tensorflow-gpu"]}, {"cell_type": "code", "execution_count": 6, "metadata": {"ExecuteTime": {"end_time": "2021-08-09T22:05:13.479401Z", "start_time": "2021-08-09T22:05:11.051278Z"}, "scrolled": true}, "outputs": [{"name": "stderr", "output_type": "stream", "text": ["/home/c3/.conda/envs/py-copycat/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:458: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n", "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n", "/home/c3/.conda/envs/py-copycat/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:459: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n", "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n", "/home/c3/.conda/envs/py-copycat/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:460: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n", "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n", "/home/c3/.conda/envs/py-copycat/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:461: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n", "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n", "/home/c3/.conda/envs/py-copycat/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:462: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n", "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n", "/home/c3/.conda/envs/py-copycat/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:465: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n", "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"]}], "source": ["import tensorflow as tf\n", "from tensorflow.python.client import device_lib"]}, {"cell_type": "code", "execution_count": 7, "metadata": {"ExecuteTime": {"end_time": "2021-08-09T22:05:13.807622Z", "start_time": "2021-08-09T22:05:13.481416Z"}}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["[name: \"/cpu:0\"\n", "device_type: \"CPU\"\n", "memory_limit: 268435456\n", "locality {\n", "}\n", "incarnation: 4692077885660092708\n", ", name: \"/gpu:0\"\n", "device_type: \"GPU\"\n", "memory_limit: 11338085172\n", "locality {\n", "  bus_id: 1\n", "}\n", "incarnation: 208304305281607498\n", "physical_device_desc: \"device: 0, name: Tesla K80, pci bus id: 0001:00:00.0\"\n", "]\n"]}], "source": ["print(device_lib.list_local_devices())"]}, {"cell_type": "code", "execution_count": 8, "metadata": {"ExecuteTime": {"end_time": "2021-08-09T22:05:13.814212Z", "start_time": "2021-08-09T22:05:13.809678Z"}}, "outputs": [{"data": {"text/plain": ["True"]}, "execution_count": 8, "metadata": {}, "output_type": "execute_result"}], "source": ["# is it really a cuda device?\n", "tf.test.is_built_with_cuda()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# Matrix operations using Tensorflow-gpu"]}, {"cell_type": "code", "execution_count": 9, "metadata": {"ExecuteTime": {"end_time": "2021-08-09T22:05:13.867895Z", "start_time": "2021-08-09T22:05:13.815829Z"}}, "outputs": [], "source": ["import numpy as np\n", "import tensorflow as tf\n", "from time import perf_counter"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Define matrix multiplication function with TF"]}, {"cell_type": "code", "execution_count": 10, "metadata": {"ExecuteTime": {"end_time": "2021-08-09T22:05:16.150251Z", "start_time": "2021-08-09T22:05:16.146504Z"}}, "outputs": [], "source": ["def matpow(M, n):\n", "    \"\"\"\n", "    Takes in matrix M and multiplies it by itself n-1 times.\n", "    \"\"\"\n", "    if n < 1:\n", "        return M\n", "    else:\n", "        return tf.matmul(M, matpow(M,n-1))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Define matrices A and B, n to calculate (A^n + B^n )"]}, {"cell_type": "code", "execution_count": 11, "metadata": {"ExecuteTime": {"end_time": "2021-08-09T22:05:19.811176Z", "start_time": "2021-08-09T22:05:17.350510Z"}}, "outputs": [], "source": ["size = 10000\n", "A = np.random.rand(size, size).astype('float32')\n", "B = np.random.rand(size, size).astype('float32')\n", "n = 10"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## GPU multiplication\n", "\n", "This is pretty much all taken from: https://gist.github.com/j-min/baae1aa56e861cab9831b3722755ae6d"]}, {"cell_type": "code", "execution_count": 12, "metadata": {"ExecuteTime": {"end_time": "2021-08-09T22:05:28.320312Z", "start_time": "2021-08-09T22:05:19.813106Z"}}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["GPU time: 8.47029 s\n"]}], "source": ["c1 = []\n", "c2 = []\n", "\n", "with tf.device('/gpu:0'):\n", "    a = tf.placeholder(tf.float32, [size, size])\n", "    b = tf.placeholder(tf.float32, [size, size])\n", "    c1.append(matpow(a, n))\n", "    c2.append(matpow(b, n))\n", "\n", "with tf.device('/cpu:0'):\n", "  sum = tf.add_n(c1)\n", "\n", "start_time = perf_counter()\n", "with tf.Session(config=tf.ConfigProto(log_device_placement=True)) as sess:\n", "    # Run the op.\n", "    sess.run(sum, {a:A, b:B})\n", "stop_time = perf_counter()\n", "\n", "print('GPU time: %g s' % (stop_time-start_time))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## CPU multiplication"]}, {"cell_type": "code", "execution_count": 13, "metadata": {"ExecuteTime": {"end_time": "2021-08-09T22:20:27.689103Z", "start_time": "2021-08-09T22:06:10.084416Z"}}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["CPU time: 857.143 s\n"]}], "source": ["c1 = []\n", "c2 = []\n", "\n", "with tf.device('/cpu:0'):\n", "    a = tf.placeholder(tf.float32, [size, size])\n", "    b = tf.placeholder(tf.float32, [size, size])\n", "    c1.append(matpow(a, n))\n", "    c2.append(matpow(b, n))\n", "\n", "with tf.device('/cpu:0'):\n", "  sum = tf.add_n(c1)\n", "\n", "start_time = perf_counter()\n", "with tf.Session(config=tf.ConfigProto(log_device_placement=True)) as sess:\n", "    # Run the op.\n", "    sess.run(sum, {a:A, b:B})\n", "stop_time = perf_counter()\n", "\n", "print('CPU time: %g s' % (stop_time-start_time))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["# Numba vectorization in the GPU -- WIP"]}, {"cell_type": "code", "execution_count": 14, "metadata": {"ExecuteTime": {"end_time": "2021-08-09T22:20:27.806256Z", "start_time": "2021-08-09T22:20:27.691010Z"}}, "outputs": [{"ename": "ModuleNotFoundError", "evalue": "No module named 'numba'", "output_type": "error", "traceback": ["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m", "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)", "\u001b[0;32m<ipython-input-14-a2e47c41f80f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtime\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mperf_counter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mnumba\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mvectorize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m", "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'numba'"]}], "source": ["import numpy as np\n", "from time import perf_counter\n", "from numba import vectorize"]}, {"cell_type": "code", "execution_count": null, "metadata": {"ExecuteTime": {"end_time": "2021-08-09T22:20:27.808295Z", "start_time": "2021-08-09T22:06:18.794Z"}}, "outputs": [], "source": ["@vectorize(['float32(float32, float32)'], target='cuda')\n", "def add_vec(v1, v2):\n", "    return v1 + v2\n", "\n", "\n", "\n", "N=1<<12\n", "\n", "a = np.ones(N, dtype=np.float32)\n", "b = np.ones(N, dtype=np.float32)\n", "c = np.empty_like(a, dtype=a.dtype)\n", "\n", "start_time = perf_counter()\n", "c = add_vec(a,b)\n", "stop_time = perf_counter()\n", "\n", "print(c)\n", "print('Elapsed time: %g s' % (stop_time-start_time))\n", "\n", "del a\n", "del b\n", "del c"]}, {"cell_type": "code", "execution_count": null, "metadata": {"ExecuteTime": {"end_time": "2021-08-09T22:20:27.809189Z", "start_time": "2021-08-09T22:06:20.069Z"}}, "outputs": [], "source": ["del a\n", "del b\n", "del c"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "code", "execution_count": null, "metadata": {"ExecuteTime": {"end_time": "2021-08-09T22:03:20.779332Z", "start_time": "2021-08-09T22:03:20.307Z"}}, "outputs": [], "source": ["# Testing the version of packages #\n", "tf.__version__"]}, {"cell_type": "code", "execution_count": null, "metadata": {"ExecuteTime": {"end_time": "2021-08-09T22:03:20.780284Z", "start_time": "2021-08-09T22:03:20.308Z"}}, "outputs": [], "source": ["import tensorflow as tf\n", "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}], "metadata": {"has_local_update": false, "is_local": true, "is_remote": true, "kernelspec": {"display_name": "py-copycat", "language": "Python", "name": "py-copycat"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.13"}, "last_sync_time": "2021-08-09T21:58:36.485573"}, "nbformat": 4, "nbformat_minor": 2}