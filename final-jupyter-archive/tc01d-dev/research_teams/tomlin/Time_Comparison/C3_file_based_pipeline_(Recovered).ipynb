{"cells": [{"cell_type": "code", "execution_count": 1, "metadata": {"ExecuteTime": {"end_time": "2021-11-10T09:08:00.255235Z", "start_time": "2021-11-10T09:08:00.237305Z"}}, "outputs": [], "source": ["from datetime import datetime, timedelta\n", "import netCDF4\n", "import numpy as np\n", "import bisect\n", "import math"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# 1) Current implementation of subsetting from nc file example"]}, {"cell_type": "code", "execution_count": 2, "metadata": {"ExecuteTime": {"end_time": "2021-11-10T09:08:00.296280Z", "start_time": "2021-11-10T09:08:00.257122Z"}, "code_folding": [0]}, "outputs": [], "source": ["def get_current_data_subset(nc_file, x_0, x_T, deg_around_x0_xT_box, fixed_time=None,\n", "                            temporal_stride=1, temp_horizon_in_h=None):\n", "    \"\"\" Function to read a subset of the nc_file current data bounded by a box spanned by the x_0 and x_T points.\n", "    Inputs:\n", "        nc_file                 full path to nc file\n", "        x_0                     [lon, lat, charge, timestamp in POSIX]\n", "        x_T                     [lon, lat] goal locations\n", "        deg_around_x0_xT_box    float, buffer around the box in degrees\n", "        fixed_time              if None returns time-varying currents, \n", "                                otherwise datetime object of the fixed time -> returns ocean current grid at or before time\n", "                                the time of x_0 is then ignored\n", "        temporal_stride         int, if a stride of the temporal values is used (every temporal_stride hours)\n", "        temp_horizon            if None: all available time of the file will be provided\n", "                                otherwise float, maximum temp_horizon to look ahead of x_0 time in hours\n", "                                \n", "    Outputs:\n", "        grids_dict              dict containing x_grid, y_grid, t_grid, fixed_time_idx\n", "        u_data                  [T, Y, X] matrix of the ocean currents in x direction in m/s\n", "        v_data                  [T, Y, X] matrix of the ocean currents in y direction in m/s\n", "        \n", "    \"\"\"\n", "    \n", "    f = netCDF4.Dataset(nc_file)\n", "\n", "    # extract positiond & start_time for the indexing\n", "    x_0_pos = x_0[:2]\n", "    x_0_posix_time = x_0[3]\n", "    x_T = x_T[:2]\n", "\n", "    # Step 1: get the grids\n", "    xgrid = f.variables['lon'][:]\n", "    ygrid = f.variables['lat'][:]\n", "    t_grid = f.variables['time'][:] # not this is in hours from HYCOM data!\n", "    \n", "    # this is needed because the time origin in hindcast and forecase nc files is different. Very handcrafted.\n", "    try:\n", "        time_origin = datetime.strptime(f.variables['time'].__dict__['time_origin'] + ' +0000',\n", "                                        '%Y-%m-%d %H:%M:%S %z')\n", "    except:\n", "        time_origin = datetime.strptime(f.variables['time'].__dict__['units'] + ' +0000',\n", "                                                 'hours since %Y-%m-%d %H:%M:%S.000 UTC %z')\n", "\n", "    # Step 2: find the sub-setting\n", "    # find the lat & lon sub-set bounds\n", "    lon_bnds = [min(x_0_pos[0], x_T[0]) - deg_around_x0_xT_box, max(x_0_pos[0], x_T[0]) + deg_around_x0_xT_box]\n", "    lat_bnds = [min(x_0_pos[1], x_T[1]) - deg_around_x0_xT_box, max(x_0_pos[1], x_T[1]) + deg_around_x0_xT_box]\n", "\n", "    # get the respective indices from the grids\n", "    ygrid_inds = np.where((ygrid >= lat_bnds[0]) & (ygrid <= lat_bnds[1]))[0]\n", "    xgrid_inds = np.where((xgrid >= lon_bnds[0]) & (xgrid <= lon_bnds[1]))[0]\n", "\n", "    # for time indexing transform to POSIX time\n", "    abs_t_grid = [(time_origin + timedelta(hours=X)).timestamp() for X in t_grid.data]\n", "    \n", "    # get the idx of the value left of the demanded time (for interpolation function)\n", "    t_start_idx = bisect.bisect_right(abs_t_grid, x_0_posix_time) - 1\n", "    if t_start_idx == len(abs_t_grid) - 1 or t_start_idx == -1:\n", "        raise ValueError(\"Requested subset time is outside of the nc4 file.\")\n", "\n", "    # get the max time if provided as input\n", "    if temp_horizon_in_h is None:   # all data provided\n", "        t_end_idx = len(abs_t_grid)-1\n", "    else:\n", "        t_end_idx = bisect.bisect_right(abs_t_grid, x_0_posix_time + temp_horizon_in_h*3600.)\n", "        if t_end_idx == len(abs_t_grid):\n", "            raise ValueError(\"nc4 file does not contain requested temporal horizon.\")\n", "\n", "    # fixed time logic if necessary\n", "    if fixed_time is None:\n", "        slice_for_time_dim = np.s_[t_start_idx:(t_end_idx+1):temporal_stride]\n", "        fixed_time_idx = None\n", "    else:\n", "        fixed_time_idx = bisect.bisect_right(abs_t_grid, fixed_time.timestamp()) - 1\n", "        slice_for_time_dim = np.s_[fixed_time_idx]\n", "\n", "    # Step 2: extract data\n", "    # raw water_u is [tdim, zdim, ydim, xdim]\n", "    if len(f.variables['water_u'].shape) == 4:  # if there is a depth dimension in the dataset\n", "        u_data = f.variables['water_u'][slice_for_time_dim, 0, ygrid_inds, xgrid_inds]\n", "        v_data = f.variables['water_v'][slice_for_time_dim, 0, ygrid_inds, xgrid_inds]\n", "    # raw water_u is [tdim, ydim, xdim]\n", "    elif len(f.variables['water_u'].shape) == 3:  # if there is no depth dimension in the dataset\n", "        u_data = f.variables['water_u'][slice_for_time_dim, ygrid_inds, xgrid_inds]\n", "        v_data = f.variables['water_v'][slice_for_time_dim, ygrid_inds, xgrid_inds]\n", "    else:\n", "        raise ValueError(\"Current data in nc file has neither 3 nor 4 dimensions. Check file.\")\n", "\n", "    # create dict to output\n", "    grids_dict = {'x_grid': xgrid[xgrid_inds], 'y_grid': ygrid[ygrid_inds],\n", "                  't_grid': abs_t_grid[slice_for_time_dim], 'fixed_time_idx': fixed_time_idx}\n", "\n", "    # log what data has been subsetted\n", "    if fixed_time is None:\n", "        print(\"Subsetted data from {start} to {end} in {n_steps} time steps of {time:.2f} hour(s) resolution\".format(\n", "            start=datetime.utcfromtimestamp(grids_dict['t_grid'][0]).strftime('%Y-%m-%d %H:%M:%S UTC'),\n", "            end=datetime.utcfromtimestamp(grids_dict['t_grid'][-1]).strftime('%Y-%m-%d %H:%M:%S UTC'),\n", "            n_steps=len(grids_dict['t_grid']), time=(grids_dict['t_grid'][1] - grids_dict['t_grid'][0])/3600.))\n", "    else:\n", "        print(\"Subsetted data to fixed time at: {time}\".format(\n", "            time=datetime.utcfromtimestamp(grids_dict['t_grid'][0]).strftime('%Y-%m-%d %H:%M:%S UTC')))\n", "\n", "    #TODO: we replace the masked array with fill value 0 because otherwise interpolation doesn't work.\n", "    # Though that means we cannot anymore detect if we're on land or not (need a way to do that/detect stranding)\n", "    # not sure yet if we'll do it in the simulator or where.\n", "    return grids_dict, u_data.filled(fill_value=0.), v_data.filled(fill_value=0.)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# 2) C3 function loading data using file-based approach"]}, {"cell_type": "code", "execution_count": 3, "metadata": {"ExecuteTime": {"end_time": "2021-11-10T09:08:00.346151Z", "start_time": "2021-11-10T09:08:00.298167Z"}, "code_folding": [11, 32]}, "outputs": [], "source": ["def get_current_data_subset_from_c3(\n", "    t_interval, #temp_res_in_h,   ----> separate function\n", "    lat_interval, #lat_res_in_deg,\n", "    lon_interval, #lon_res_in_deg,\n", "    #depth_interval_to_avg_over\n", "):\n", "    \n", "    # scipy.interpolate.interp1d\n", "    \n", "    \"\"\" Function to get a subset of current data via the C3 data integration.\n", "    \n", "    Inputs:\n", "        t_interval              if time-varying: [t_0, t_T] in POSIX time\n", "                                where t_0 and t_T are the start and end timestamps respectively\n", "                                if fixed_time:   [fixed_timestamp] in POSIX\n", "        temp_res_in_h           which temporal resolution the time-axis should have\n", "                                e.g. if temp_res_in_h = 1, t_grid = [t_0, t_0 + 3600s, ... t_T]\n", "                                if temp_res_in_h = 5,      t_grid = [t_0, t_0 + 5*3600s, ... t_T]\n", "                                if temp_res_in_h = 0.5,      t_grid = [t_0, t_0 + 1800s, ... t_T]\n", "                                => so either averaging or interpolation needs to be done in the backend\n", "        lat_interval            [y_lower, y_upper] in degrees\n", "        lat_res_in_deg          which spatial resolution in y direction in degrees\n", "                                e.g. if lat_res_in_deg = 1, y_grid = [y_lower, y_lower + 1, ... y_upper]\n", "                                 => so either averaging or interpolation needs to be done in the backend\n", "        lon_interval            [x_lower, x_upper] in degrees\n", "        lon_res_in_deg          which spatial resolution in x direction in degrees\n", "                                e.g. if lon_res_in_deg = 1, x_grid = [x_lower, x_lower + 1, ... x_upper]\n", "                                 => so either averaging or interpolation needs to be done in the backend\n", "        depth_interval_to_avg_over\n", "                                Interval to average over the current dimension in meters\n", "                                e.g. [0, 10] then the currents are averaged over the depth 0-10m.\n", "                                \n", "    Outputs:\n", "        grids_dict              dict containing x_grid, y_grid, t_grid\n", "        u_data                  [T, Y, X] matrix of the ocean currents in x direction in m/s\n", "        v_data                  [T, Y, X] matrix of the ocean currents in y direction in m/s\n", "    \"\"\"\n", "    \n", "    # Step 1: get required file references and data from C3 file DB\n", "    # Step 1.1: Getting time and formatting for the db query\n", "    start_date = datetime.utcfromtimestamp(t_interval[0]).strftime(\"%Y-%m-%d\")\n", "    end_date = datetime.utcfromtimestamp(t_interval[1]).strftime(\"%Y-%m-%d\")\n", "\n", "    \n", "    # Step 1.2: Getting correct range of nc files from database\n", "    filter_string = 'start>=' + '\"'+ start_date + '\"' + ' && end<=' + '\"' + end_date + \"T23:00:00.000\" + '\"'\n", "    objs_list = c3.HindcastFile.fetch({'filter':filter_string, \"order\": \"start\"}).objs\n", "    if objs_list is None:\n", "        raise ValueError(\"No files in the database for the selected t_interval\")\n", "    \n", "    # Step 1.3: extract url and start list from the query results\n", "    urls_list = [obj.file.url for obj in objs_list]\n", "    start_list = [obj.start for obj in objs_list]\n", "    \n", "    # Step 2: Prepare the stacking loop by getting the x, y grids and subsetting indices in x, y \n", "    # Note: these stay constant across files in this case where all files have same lat-lon range\n", "    \n", "    # Step 2.1: open the file and get the x and y grid\n", "    f = c3.HycomUtil.nc_open(urls_list[0])\n", "    xgrid = f.variables['lon'][:].data\n", "    ygrid = f.variables['lat'][:].data\n", "    \n", "    # Step 2.2: get the respective indices of the lat, lon subset from the file grids\n", "    ygrid_inds = np.where((ygrid >= lat_interval[0]) & (ygrid <= lat_interval[1]))[0]\n", "    xgrid_inds = np.where((xgrid >= lon_interval[0]) & (xgrid <= lon_interval[1]))[0]\n", "    \n", "    # Step 2.3 initialze t_grid stacking variable\n", "    full_t_grid = []\n", "\n", "    # Step 3: iterate over all files in order and stack the current data and absolute t_grids\n", "    for idx in range(len(start_list)):\n", "        # Step 3.0: load the current data file\n", "        f = c3.HycomUtil.nc_open(urls_list[idx])\n", "        # set the default start and end time\n", "        start_hr, end_hr = 0, 24\n", "        \n", "        # Step 3.1: do the time-subsetting\n", "        #Case 1: file is first -- get data from the file from the hour before or at t_0\n", "        if idx == 0:\n", "            start_hr = math.floor((t_interval[0] - start_list[idx].timestamp())/3600)\n", "        #Case 2: file is last -- get data from file until or after the hour t_T\n", "        if idx == len(start_list)-1:\n", "            end_hr = math.ceil((t_interval[1] - start_list[idx].timestamp())/3600)+1\n", "\n", "        # Step 3.2: extract data from the file\n", "        u_data = f.variables['water_u'][start_hr:end_hr, 0, ygrid_inds, xgrid_inds]\n", "        v_data = f.variables['water_v'][start_hr:end_hr, 0, ygrid_inds, xgrid_inds]\n", "\n", "        # Step 3.3: stack the sub-setted abs_t_grid and current data\n", "        full_t_grid = full_t_grid + [start_list[idx].timestamp() + i*3600 for i in range(start_hr, end_hr)]\n", "        \n", "        if idx == 0:\n", "            full_u_data = u_data\n", "            full_v_data = v_data\n", "        else:\n", "            full_u_data = np.concatenate((full_u_data, u_data), axis=0)\n", "            full_v_data = np.concatenate((full_v_data, v_data), axis=0)\n", "\n", "    # Step 4: create dict to output\n", "    grids_dict = {'x_grid': xgrid[xgrid_inds], 'y_grid': ygrid[ygrid_inds], 't_grid': full_t_grid}\n", "    \n", "    # Step 5: # log what data has been subsetted\n", "    print(\"Subsetted data from {start} to {end} in {n_steps} time steps of {time:.2f} hour(s) resolution\".format(\n", "        start=datetime.utcfromtimestamp(grids_dict['t_grid'][0]).strftime('%Y-%m-%d %H:%M:%S UTC'),\n", "        end=datetime.utcfromtimestamp(grids_dict['t_grid'][-1]).strftime('%Y-%m-%d %H:%M:%S UTC'),\n", "        n_steps=len(grids_dict['t_grid']), time=(grids_dict['t_grid'][1] - grids_dict['t_grid'][0])/3600.))\n", "\n", "    # Step 6: return the grids_dict and the stacked data\n", "    # TODO: currently, we just do fill_value =0 but then we can't detect if we're on land. \n", "    # We need a way to do that in the simulator, doing it via the currents could be one way.\n", "    return grids_dict, full_u_data.filled(fill_value=0.), full_v_data.filled(fill_value=0.)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# 3) Sanity check if data directly from subsetted file and via c3 files is same"]}, {"cell_type": "code", "execution_count": 4, "metadata": {"ExecuteTime": {"end_time": "2021-11-10T09:08:02.570335Z", "start_time": "2021-11-10T09:08:02.555748Z"}}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Subsetted data from 2021-09-02 12:00:00 UTC to 2021-09-03 12:00:00 UTC in 25 time steps of 1.00 hour(s) resolution\n"]}], "source": ["# settings for directly from subsetted file and old approach\n", "hindcast_file = 'Sanity_check_data.nc4'\n", "x_0 = [-90.0, 24.0, 1, 1630584000.0]  # lon, lat, battery, posix_time\n", "x_T = [-89.0, 25.0]\n", "deg_around_x0_xT_box = 0.\n", "fixed_time = None\n", "temporal_stride = 1\n", "\n", "# function callfile_\n", "file_grids_dict, file_u_data, file_v_data = get_current_data_subset(hindcast_file,\n", "                                                     x_0, x_T,\n", "                                                     deg_around_x0_xT_box,\n", "                                                     fixed_time,\n", "                                                     temporal_stride,\n", "                                                              temp_horizon_in_h=None)"]}, {"cell_type": "code", "execution_count": 5, "metadata": {"ExecuteTime": {"end_time": "2021-11-10T09:08:06.088083Z", "start_time": "2021-11-10T09:08:03.902391Z"}}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Subsetted data from 2021-09-02 12:00:00 UTC to 2021-09-03 12:00:00 UTC in 25 time steps of 1.00 hour(s) resolution\n"]}], "source": ["# running same query via the data pipeline using the files from the C3 database\n", "lon_interval = [-90,-89]\n", "lat_interval = [24, 25]\n", "# t_interval = [1630584000.0, 1630670400.0] # that's two days 2021-09-02-12 to 2021-09-04-12\n", "t_interval = [file_grids_dict['t_grid'][0], file_grids_dict['t_grid'][-1]] # that's two days 2021-09-02-12 to 2021-09-04-12\n", "c3_grids_dict, c3_u_data, c3_v_data = get_current_data_subset_from_c3(t_interval, lat_interval, lon_interval)"]}, {"cell_type": "code", "execution_count": 6, "metadata": {"ExecuteTime": {"end_time": "2021-11-10T09:08:07.873761Z", "start_time": "2021-11-10T09:08:07.862318Z"}}, "outputs": [{"data": {"text/plain": ["True"]}, "execution_count": 6, "metadata": {}, "output_type": "execute_result"}], "source": ["# compare if they output matrices are the same (they should)\n", "np.all(file_u_data==c3_u_data)"]}], "metadata": {"has_local_update": false, "is_local": true, "is_remote": true, "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.7.9"}, "last_sync_time": "2021-11-14T02:47:56.596399"}, "nbformat": 4, "nbformat_minor": 4}