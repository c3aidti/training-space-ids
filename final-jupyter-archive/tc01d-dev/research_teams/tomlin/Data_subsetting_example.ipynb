{"cells": [{"cell_type": "code", "execution_count": 1, "metadata": {"ExecuteTime": {"end_time": "2021-11-09T01:07:41.177772Z", "start_time": "2021-11-09T01:07:41.158178Z"}}, "outputs": [], "source": ["from datetime import datetime, timedelta\n", "import netCDF4\n", "import numpy as np\n", "import bisect"]}, {"cell_type": "markdown", "metadata": {"ExecuteTime": {"end_time": "2021-09-30T22:33:31.449649Z", "start_time": "2021-09-30T22:33:31.446691Z"}, "code_folding": []}, "source": ["# Overview of flexible data-loading functionality\n", "\n", "1) Below you'll find the function I currently use to subset the data.\n", "All this would subsetting in space & time and more (like averaging currents over time instead of the current temporal slides) should be done via the C3 platform by dynamically loading the hindcast data from the server and/or the \n", "archive of forecast files. And then just return the right current matrices and grids back for use in the simulator.\n", "\n", "2) A sketch of how the function may look like in the end\n", "Of course we can start a lot simpler without any of the averaging/interpolation yet =)\n", "\n", "Thanks a lot for looking into this for us, that helps a lot!"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# 1) Current implementation of subsetting from nc file example"]}, {"cell_type": "code", "execution_count": 2, "metadata": {"ExecuteTime": {"end_time": "2021-11-08T22:58:33.085711Z", "start_time": "2021-11-08T22:58:33.081664Z"}}, "outputs": [{"data": {"text/plain": ["5.831533477321814"]}, "execution_count": 2, "metadata": {}, "output_type": "execute_result"}], "source": ["1.5*24*5*3600/111120"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["1x1"]}, {"cell_type": "code", "execution_count": 2, "metadata": {"ExecuteTime": {"end_time": "2021-11-05T03:46:22.741357Z", "start_time": "2021-11-05T03:46:22.722378Z"}, "code_folding": []}, "outputs": [], "source": ["def get_current_data_subset(nc_file, x_0, x_T, deg_around_x0_xT_box, fixed_time=None,\n", "                            temporal_stride=1, temp_horizon_in_h=None):\n", "    \"\"\" Function to read a subset of the nc_file current data bounded by a box spanned by the x_0 and x_T points.\n", "    Inputs:\n", "        nc_file                 full path to nc file\n", "        x_0                     [lat, lon, charge, timestamp in POSIX]\n", "        x_T                     [lon, lat] goal locations\n", "        deg_around_x0_xT_box    float, buffer around the box in degrees\n", "        fixed_time              if None returns time-varying currents, \n", "                                otherwise datetime object of the fixed time -> returns ocean current grid at or before time\n", "                                the time of x_0 is then ignored\n", "        temporal_stride         int, if a stride of the temporal values is used (every temporal_stride hours)\n", "        temp_horizon            if None: all available time of the file will be provided\n", "                                otherwise float, maximum temp_horizon to look ahead of x_0 time in hours\n", "                                \n", "    Outputs:\n", "        grids_dict              dict containing x_grid, y_grid, t_grid, fixed_time_idx\n", "        u_data                  [T, Y, X] matrix of the ocean currents in x direction in m/s\n", "        v_data                  [T, Y, X] matrix of the ocean currents in y direction in m/s\n", "        \n", "    \"\"\"\n", "    \n", "    f = netCDF4.Dataset(nc_file)\n", "\n", "    # extract positiond & start_time for the indexing\n", "    x_0_pos = x_0[:2]\n", "    x_0_posix_time = x_0[3]\n", "    x_T = x_T[:2]\n", "\n", "    # Step 1: get the grids\n", "    xgrid = f.variables['lon'][:]\n", "    ygrid = f.variables['lat'][:]\n", "    t_grid = f.variables['time'][:] # not this is in hours from HYCOM data!\n", "    \n", "    # this is needed because the time origin in hindcast and forecase nc files is different. Very handcrafted.\n", "    try:\n", "        time_origin = datetime.strptime(f.variables['time'].__dict__['time_origin'] + ' +0000',\n", "                                        '%Y-%m-%d %H:%M:%S %z')\n", "    except:\n", "        time_origin = datetime.strptime(f.variables['time'].__dict__['units'] + ' +0000',\n", "                                                 'hours since %Y-%m-%d %H:%M:%S.000 UTC %z')\n", "\n", "    # Step 2: find the sub-setting\n", "    # find the lat & lon sub-set bounds\n", "    lon_bnds = [min(x_0_pos[0], x_T[0]) - deg_around_x0_xT_box, max(x_0_pos[0], x_T[0]) + deg_around_x0_xT_box]\n", "    lat_bnds = [min(x_0_pos[1], x_T[1]) - deg_around_x0_xT_box, max(x_0_pos[1], x_T[1]) + deg_around_x0_xT_box]\n", "\n", "    # get the respective indices from the grids\n", "    ygrid_inds = np.where((ygrid > lat_bnds[0]) & (ygrid < lat_bnds[1]))[0]\n", "    xgrid_inds = np.where((xgrid > lon_bnds[0]) & (xgrid < lon_bnds[1]))[0]\n", "\n", "    # for time indexing transform to POSIX time\n", "    abs_t_grid = [(time_origin + timedelta(hours=X)).timestamp() for X in t_grid.data]\n", "    \n", "    # get the idx of the value left of the demanded time (for interpolation function)\n", "    t_start_idx = bisect.bisect_right(abs_t_grid, x_0_posix_time) - 1\n", "    if t_start_idx == len(abs_t_grid) - 1 or t_start_idx == -1:\n", "        raise ValueError(\"Requested subset time is outside of the nc4 file.\")\n", "\n", "    # get the max time if provided as input\n", "    if temp_horizon_in_h is None:   # all data provided\n", "        t_end_idx = len(abs_t_grid)-1\n", "    else:\n", "        t_end_idx = bisect.bisect_right(abs_t_grid, x_0_posix_time + temp_horizon_in_h*3600.)\n", "        if t_end_idx == len(abs_t_grid):\n", "            raise ValueError(\"nc4 file does not contain requested temporal horizon.\")\n", "\n", "    # fixed time logic if necessary\n", "    if fixed_time is None:\n", "        slice_for_time_dim = np.s_[t_start_idx:(t_end_idx+1):temporal_stride]\n", "        fixed_time_idx = None\n", "    else:\n", "        fixed_time_idx = bisect.bisect_right(abs_t_grid, fixed_time.timestamp()) - 1\n", "        slice_for_time_dim = np.s_[fixed_time_idx]\n", "\n", "    # Step 2: extract data\n", "    # raw water_u is [tdim, zdim, ydim, xdim]\n", "    if len(f.variables['water_u'].shape) == 4:  # if there is a depth dimension in the dataset\n", "        u_data = f.variables['water_u'][slice_for_time_dim, 0, ygrid_inds, xgrid_inds]\n", "        v_data = f.variables['water_v'][slice_for_time_dim, 0, ygrid_inds, xgrid_inds]\n", "    # raw water_u is [tdim, ydim, xdim]\n", "    elif len(f.variables['water_u'].shape) == 3:  # if there is no depth dimension in the dataset\n", "        u_data = f.variables['water_u'][slice_for_time_dim, ygrid_inds, xgrid_inds]\n", "        v_data = f.variables['water_v'][slice_for_time_dim, ygrid_inds, xgrid_inds]\n", "    else:\n", "        raise ValueError(\"Current data in nc file has neither 3 nor 4 dimensions. Check file.\")\n", "\n", "    # create dict to output\n", "    grids_dict = {'x_grid': xgrid[xgrid_inds], 'y_grid': ygrid[ygrid_inds],\n", "                  't_grid': abs_t_grid[slice_for_time_dim], 'fixed_time_idx': fixed_time_idx}\n", "\n", "    # log what data has been subsetted\n", "    if fixed_time is None:\n", "        print(\"Subsetted data from {start} to {end} in {n_steps} time steps of {time:.2f} hour(s) resolution\".format(\n", "            start=datetime.utcfromtimestamp(grids_dict['t_grid'][0]).strftime('%Y-%m-%d %H:%M:%S UTC'),\n", "            end=datetime.utcfromtimestamp(grids_dict['t_grid'][-1]).strftime('%Y-%m-%d %H:%M:%S UTC'),\n", "            n_steps=len(grids_dict['t_grid']), time=(grids_dict['t_grid'][1] - grids_dict['t_grid'][0])/3600.))\n", "    else:\n", "        print(\"Subsetted data to fixed time at: {time}\".format(\n", "            time=datetime.utcfromtimestamp(grids_dict['t_grid'][0]).strftime('%Y-%m-%d %H:%M:%S UTC')))\n", "\n", "    #TODO: we replace the masked array with fill value 0 because otherwise interpolation doesn't work.\n", "    # Though that means we cannot anymore detect if we're on land or not (need a way to do that/detect stranding)\n", "    # not sure yet if we'll do it in the simulator or where.\n", "    # return grids_dict, u_data.filled(fill_value=0.), v_data.filled(fill_value=0.)\n", "    return grids_dict, u_data, v_data"]}, {"cell_type": "code", "execution_count": 3, "metadata": {"ExecuteTime": {"end_time": "2021-11-05T03:46:24.517649Z", "start_time": "2021-11-05T03:46:24.431845Z"}, "code_folding": [], "scrolled": true}, "outputs": [{"ename": "FileNotFoundError", "evalue": "[Errno 2] No such file or directory: b'2021_06_1-05_hourly.nc4'", "output_type": "error", "traceback": ["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m", "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)", "\u001b[0;32m<ipython-input-3-b1b8877e6770>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m                                                      \u001b[0mdeg_around_x0_xT_box\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                                                      \u001b[0mfixed_time\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m                                                      temporal_stride)\n\u001b[0m", "\u001b[0;32m<ipython-input-2-e855da9312a9>\u001b[0m in \u001b[0;36mget_current_data_subset\u001b[0;34m(nc_file, x_0, x_T, deg_around_x0_xT_box, fixed_time, temporal_stride, temp_horizon_in_h)\u001b[0m\n\u001b[1;32m     21\u001b[0m     \"\"\"\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetCDF4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnc_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;31m# extract positiond & start_time for the indexing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;32msrc/netCDF4/_netCDF4.pyx\u001b[0m in \u001b[0;36mnetCDF4._netCDF4.Dataset.__init__\u001b[0;34m()\u001b[0m\n", "\u001b[0;32msrc/netCDF4/_netCDF4.pyx\u001b[0m in \u001b[0;36mnetCDF4._netCDF4._ensure_nc_success\u001b[0;34m()\u001b[0m\n", "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: b'2021_06_1-05_hourly.nc4'"]}], "source": ["# example execution\n", "\n", "# settings\n", "hindcast_file = '2021_06_1-05_hourly.nc4'\n", "x_0 = [-88.0, 25.0, 1, 1622549410.0]  # lon, lat, battery, posix_time\n", "x_T = [-88.0, 26.3]\n", "deg_around_x0_xT_box = 0.5\n", "fixed_time = None\n", "temporal_stride = 1\n", "\n", "# function call\n", "grids_dict, u_data, v_data = get_current_data_subset(hindcast_file,\n", "                                                     x_0, x_T,\n", "                                                     deg_around_x0_xT_box,\n", "                                                     fixed_time,\n", "                                                     temporal_stride)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["c3Grid(SurfaceHindcastData.fetch({\"include\": \"id\", \"filter\": 'parent==HNDCST_SRFC_1-0'}))"]}, {"cell_type": "code", "execution_count": 10, "metadata": {"ExecuteTime": {"end_time": "2021-11-05T01:45:41.977270Z", "start_time": "2021-11-05T01:45:41.852603Z"}}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["[18.12000084 18.15999985 18.20000076 18.23999977 18.28000069 18.31999969\n", " 18.36000061 18.39999962 18.44000053 18.47999954 18.52000046 18.55999947\n", " 18.60000038 18.63999939 18.68000031 18.71999931 18.76000023 18.79999924\n", " 18.84000015 18.87999916 18.92000008 18.95999908]\n"]}], "source": ["import numpy as np\n", "# Step 1: Get the id's of the subset of LatLonPairs via a DB Query\n", "objs_list = c3.HycomLatLongPair.fetch(\n", "spec={\"include\": \"id, lat, lon\", \"filter\": \"lat > 18 && lat < 19 && lon > -98 && lon < -97\", \"order\": \"j,i\"}).objs\n", "\n", "\n", "ids_list = [obj.id for obj in objs_list]\n", "lat_list = [obj.lat for obj in objs_list]\n", "lon_list = [obj.lon for obj in objs_list]\n", "\n", "# create the x, y grids\n", "lat_grid = np.unique(np.array(lat_list))\n", "lon_grid = np.unique(np.array(lon_list))\n", "# ids_list\n", "\n", "print(lat_grid)\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# 2) Sketch of how C3 function interface might look like"]}, {"cell_type": "code", "execution_count": 171, "metadata": {"ExecuteTime": {"end_time": "2021-11-09T10:30:08.421939Z", "start_time": "2021-11-09T10:30:08.407244Z"}, "code_folding": []}, "outputs": [], "source": ["def get_current_data_subset_from_c3( \n", "    t_interval, #temp_res_in_h,\n", "    lat_interval, #lat_res_in_deg,\n", "    lon_interval, #lon_res_in_deg,\n", "    #depth_interval_to_avg_over\n", "):\n", "    # scipy.interpolate.interp1d\n", "    \n", "    \"\"\" Function to get a subset of current data via the C3 data integration.\n", "    \n", "    Inputs:\n", "        t_interval              if time-varying: [t_0, t_T] in POSIX time\n", "                                where t_0 and t_T are the start and end timestamps respectively\n", "                                if fixed_time:   [fixed_timestamp] in POSIX\n", "        temp_res_in_h           which temporal resolution the time-axis should have\n", "                                e.g. if temp_res_in_h = 1, t_grid = [t_0, t_0 + 3600s, ... t_T]\n", "                                if temp_res_in_h = 5,      t_grid = [t_0, t_0 + 5*3600s, ... t_T]\n", "                                if temp_res_in_h = 0.5,      t_grid = [t_0, t_0 + 1800s, ... t_T]\n", "                                => so either averaging or interpolation needs to be done in the backend\n", "        lat_interval            [y_lower, y_upper] in degrees\n", "        lat_res_in_deg          which spatial resolution in y direction in degrees\n", "                                e.g. if lat_res_in_deg = 1, y_grid = [y_lower, y_lower + 1, ... y_upper]\n", "                                 => so either averaging or interpolation needs to be done in the backend\n", "        lon_interval            [x_lower, x_upper] in degrees\n", "        lon_res_in_deg          which spatial resolution in x direction in degrees\n", "                                e.g. if lon_res_in_deg = 1, x_grid = [x_lower, x_lower + 1, ... x_upper]\n", "                                 => so either averaging or interpolation needs to be done in the backend\n", "        depth_interval_to_avg_over\n", "                                Interval to average over the current dimension in meters\n", "                                e.g. [0, 10] then the currents are averaged over the depth 0-10m.\n", "                                \n", "    Outputs:\n", "        grids_dict              dict containing x_grid, y_grid, t_grid\n", "        u_data                  [T, Y, X] matrix of the ocean currents in x direction in m/s\n", "        v_data                  [T, Y, X] matrix of the ocean currents in y direction in m/s\n", "    \"\"\"\n", "    \n", "    # some C3 magic =)\n", "    \n", "    grids_dict = {}\n", "    #Getting time and formatting \n", "    t_0 = t_interval[0]\n", "    t_T = t_interval[1]\n", "    t_grid = [t_0+i*3600 for i in range(num_interval)]\n", "    if t_T%3600!=0:\n", "        t_grid.append(t_T)\n", "    start_time = datetime.utcfromtimestamp(t_0).strftime(\"%Y-%m-%d\")\n", "    end_time = datetime.utcfromtimestamp(t_T).strftime(\"%Y-%m-%d\") \n", "\n", "    #Getting correct range of nc files from database\n", "    filter_string = 'start>=' + '\"'+ start_time + '\"' + ' && end<=' + '\"' + end_time + \"T23:00:00.000\" + '\"'\n", "    '''===Note===\n", "    I checked the fetch results and found out that the ordering was preserved. Since original ordering was based\n", "    on date, the dates were preserved. If the files in the db themselves are not sorted, we can apply an additional \n", "    order keyword. For now we don't need it because that might cause extra runtime'''\n", "    objs_list = c3.HindcastFile.fetch({'filter':filter_string}).objs\n", "    ids_list = [obj.id for obj in objs_list]\n", "    \n", "    #Get the first file and use it to extract grid information for us\n", "    # Step 1: Getting the grids\n", "    first_file = c3.HindcastFile.get(ids_list[0])\n", "    first_f = c3.HycomUtil.nc_open(first_file.file.url) \n", "    xgrid = first_f.variables['lon'][:]\n", "    ygrid = first_f.variables['lat'][:]\n", "    #Get the respective indices from the grids (Same for every file)\n", "    ygrid_inds = np.where((ygrid >= lat_interval[0]) & (ygrid <= lat_interval[1]))[0]\n", "    xgrid_inds = np.where((xgrid >= lon_interval[0]) & (xgrid <= lon_interval[1]))[0]\n", "    print(ygrid.shape)\n", "    print(ygrid_inds)\n", "    \n", "    #Step 2: Getting data from files \n", "    u_data, v_data = np.array([]), np.array([])\n", "    for i, file_id in enumerate(ids_list):\n", "        file = c3.HindcastFile.get(file_id)\n", "        f = c3.HycomUtil.nc_open(file.file.url)    #water_u dimension: (time,depth,lat,lon)\n", "        start_hr = 0\n", "        end_hr = 24\n", "\n", "        #Case 1: file is first -- get data from the file from the hour t_0 is in \n", "        if i == 0:\n", "            file_t_0 = time.mktime(file.start.timetuple())\n", "            start_hr = int((t_0 - file_t_0)/3600)\n", "        #Case 2: file is last -- get data from file until the hour t_T is in \n", "        if i == len(ids_list)-1:\n", "            file_t_0 = time.mktime(file.start.timetuple())\n", "            end_hr = math.ceil((t_T-file_t_0)/3600)+1\n", "                 \n", "        #extract data\n", "        curr_u_data = f.variables['water_u'][:][start_hr:end_hr, 0, ygrid_inds, xgrid_inds]\n", "        curr_v_data = f.variables['water_v'][:][start_hr:end_hr, 0, ygrid_inds, xgrid_inds]\n", "        if i == 0:     #if it's the first file, use it to initialize the np array that we are going to append to \n", "            u_data = np.array(curr_u_data)\n", "            v_data = np.array(curr_v_data)\n", "        else:\n", "            u_data = np.vstack((u_data, curr_u_data))\n", "            v_data = np.vstack((v_data, curr_v_data))\n", "\n", "    #Construct grid for output:\n", "    grids_dict = {'x_grid': xgrid[xgrid_inds], 'y_grid': ygrid[ygrid_inds],\n", "                  't_grid': t_grid}\n", "    #Getting data\n", "    return grids_dict, u_data, v_data"]}, {"cell_type": "code", "execution_count": 172, "metadata": {"ExecuteTime": {"end_time": "2021-11-09T10:30:10.935236Z", "start_time": "2021-11-09T10:30:09.412451Z"}}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["(346,)\n", "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22]\n"]}, {"ename": "IndexError", "evalue": "shape mismatch: indexing arrays could not be broadcast together with shapes (23,) (26,) ", "output_type": "error", "traceback": ["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m", "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)", "\u001b[0;32m<ipython-input-172-34345020028a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgrids_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_current_data_subset_from_c3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1630540800.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1630544400.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m18\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m19\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m98\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m97\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m", "\u001b[0;32m<ipython-input-171-3da51d500cf2>\u001b[0m in \u001b[0;36mget_current_data_subset_from_c3\u001b[0;34m(t_interval, lat_interval, lon_interval)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0;31m#extract data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0mcurr_u_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'water_u'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart_hr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mend_hr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mygrid_inds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxgrid_inds\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m         \u001b[0mcurr_v_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'water_v'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart_hr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mend_hr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mygrid_inds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxgrid_inds\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m     \u001b[0;31m#if it's the first file, use it to initialize the np array that we are going to append to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;32m~/.conda/envs/py-hycom_1_0_0/lib/python3.6/site-packages/numpy/ma/core.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, indx)\u001b[0m\n\u001b[1;32m   3223\u001b[0m         \u001b[0;31m# mask of being reshaped if it hasn't been set up properly yet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3224\u001b[0m         \u001b[0;31m# So it's easier to stick to the current version\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3225\u001b[0;31m         \u001b[0mdout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3226\u001b[0m         \u001b[0m_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;31mIndexError\u001b[0m: shape mismatch: indexing arrays could not be broadcast together with shapes (23,) (26,) "]}], "source": ["grids_dict, u_data, v_data = get_current_data_subset_from_c3([1630540800.0,1630544400.0],[18,19],[-98,-97])"]}, {"cell_type": "code", "execution_count": 163, "metadata": {"ExecuteTime": {"end_time": "2021-11-09T10:24:47.584112Z", "start_time": "2021-11-09T10:24:47.580061Z"}}, "outputs": [{"data": {"text/plain": ["(2,)"]}, "execution_count": 163, "metadata": {}, "output_type": "execute_result"}], "source": []}, {"cell_type": "code", "execution_count": 116, "metadata": {"ExecuteTime": {"end_time": "2021-11-09T10:07:57.935497Z", "start_time": "2021-11-09T10:07:57.049602Z"}}, "outputs": [], "source": ["#time, depth, lat, lon\n", "lon_interval = [-98,-97]\n", "lat_interval = [18,19]\n", "deg_around_x0_xT_box = 0.5\n", "file = c3.HindcastFile.get('9438b440-e200-4764-b6fe-ee6a278aff55/GOMu0.04-expt_90.1m000-2021-2021-09-04T00:00:00Z-2021-09-04T23:00:00Z.nc')\n", "f = c3.HycomUtil.nc_open(file.file.url)\n", "xgrid = f.variables['lon'][:]\n", "ygrid = f.variables['lat'][:]\n", "lon_bnds = [min(lon_interval[0], lon_interval[1]) - deg_around_x0_xT_box, max(lon_interval[0], lon_interval[1]) + deg_around_x0_xT_box]\n", "lat_bnds = [min(lat_interval[0], lat_interval[1]) - deg_around_x0_xT_box, max(lat_interval[0], lat_interval[1]) + deg_around_x0_xT_box]\n", "# get the respective indices from the grids\n", "ygrid_inds = np.where((ygrid > lat_bnds[0]) & (ygrid < lat_bnds[1]))[0]\n", "xgrid_inds = np.where((xgrid > lon_bnds[0]) & (xgrid < lon_bnds[1]))[0]"]}, {"cell_type": "code", "execution_count": 159, "metadata": {"ExecuteTime": {"end_time": "2021-11-09T10:22:44.796452Z", "start_time": "2021-11-09T10:22:44.705718Z"}}, "outputs": [{"ename": "IndexError", "evalue": "shape mismatch: indexing arrays could not be broadcast together with shapes (1,2) (1,3) ", "output_type": "error", "traceback": ["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m", "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)", "\u001b[0;32m<ipython-input-159-9dee28e57db9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'water_u'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m24\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mix_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mix_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m", "\u001b[0;32m~/.conda/envs/py-hycom_1_0_0/lib/python3.6/site-packages/numpy/ma/core.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, indx)\u001b[0m\n\u001b[1;32m   3223\u001b[0m         \u001b[0;31m# mask of being reshaped if it hasn't been set up properly yet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3224\u001b[0m         \u001b[0;31m# So it's easier to stick to the current version\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3225\u001b[0;31m         \u001b[0mdout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3226\u001b[0m         \u001b[0m_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;31mIndexError\u001b[0m: shape mismatch: indexing arrays could not be broadcast together with shapes (1,2) (1,3) "]}], "source": ["f.variables['water_u'][:][0:24,0,[0,1],[0,1,2]].shape"]}, {"cell_type": "code", "execution_count": 156, "metadata": {"ExecuteTime": {"end_time": "2021-11-09T10:20:29.160079Z", "start_time": "2021-11-09T10:20:29.154792Z"}}, "outputs": [{"data": {"text/plain": ["(2,)"]}, "execution_count": 156, "metadata": {}, "output_type": "execute_result"}], "source": ["np.array([0,1]).shape"]}, {"cell_type": "code", "execution_count": 40, "metadata": {"ExecuteTime": {"end_time": "2021-11-09T07:56:20.273157Z", "start_time": "2021-11-09T07:56:20.249850Z"}}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["9438b440-e200-4764-b6fe-ee6a278aff55/GOMu0.04-expt_90.1m000-2021-2021-09-02T00:00:00Z-2021-09-02T23:00:00Z.nc\n", "9438b440-e200-4764-b6fe-ee6a278aff55/GOMu0.04-expt_90.1m000-2021-2021-09-03T00:00:00Z-2021-09-03T23:00:00Z.nc\n", "9438b440-e200-4764-b6fe-ee6a278aff55/GOMu0.04-expt_90.1m000-2021-2021-09-04T00:00:00Z-2021-09-04T23:00:00Z.nc\n", "9438b440-e200-4764-b6fe-ee6a278aff55/GOMu0.04-expt_90.1m000-2021-2021-09-05T00:00:00Z-2021-09-05T23:00:00Z.nc\n"]}], "source": ["ids = c3.HindcastFile.fetch({'filter':'start>=\"2021-09-02\" && end<=\"2021-09-06\"'}).objs\n", "for x in ids:\n", "    print(x.id)"]}, {"cell_type": "code", "execution_count": 41, "metadata": {"ExecuteTime": {"end_time": "2021-11-09T07:56:20.888544Z", "start_time": "2021-11-09T07:56:20.878853Z"}}, "outputs": [{"data": {"text/plain": ["masked_array(data=[18.12000084, 18.15999985, 18.20000076, 18.23999977,\n", "                   18.28000069, 18.31999969, 18.36000061, 18.39999962,\n", "                   18.44000053, 18.47999954, 18.52000046, 18.55999947,\n", "                   18.60000038, 18.63999939, 18.68000031, 18.71999931,\n", "                   18.76000023, 18.79999924, 18.84000015, 18.87999916,\n", "                   18.92000008, 18.95999908, 19.        , 19.04000092,\n", "                   19.07999992, 19.12000084, 19.15999985, 19.20000076,\n", "                   19.23999977, 19.28000069, 19.31999969, 19.36000061,\n", "                   19.39999962, 19.44000053, 19.47999954, 19.52000046,\n", "                   19.55999947, 19.60000038, 19.63999939, 19.68000031,\n", "                   19.71999931, 19.76000023, 19.79999924, 19.84000015,\n", "                   19.87999916, 19.92000008, 19.95999908, 20.        ,\n", "                   20.04000092, 20.07999992, 20.12000084, 20.15999985,\n", "                   20.20000076, 20.23999977, 20.28000069, 20.31999969,\n", "                   20.36000061, 20.39999962, 20.44000053, 20.47999954,\n", "                   20.52000046, 20.55999947, 20.60000038, 20.63999939,\n", "                   20.68000031, 20.71999931, 20.76000023, 20.79999924,\n", "                   20.84000015, 20.87999916, 20.92000008, 20.95999908,\n", "                   21.        , 21.04000092, 21.07999992, 21.12000084,\n", "                   21.15999985, 21.20000076, 21.23999977, 21.28000069,\n", "                   21.31999969, 21.36000061, 21.39999962, 21.44000053,\n", "                   21.47999954, 21.52000046, 21.55999947, 21.60000038,\n", "                   21.63999939, 21.68000031, 21.71999931, 21.76000023,\n", "                   21.79999924, 21.84000015, 21.87999916, 21.92000008,\n", "                   21.95999908, 22.        , 22.04000092, 22.07999992,\n", "                   22.12000084, 22.15999985, 22.20000076, 22.23999977,\n", "                   22.28000069, 22.31999969, 22.36000061, 22.39999962,\n", "                   22.44000053, 22.47999954, 22.52000046, 22.55999947,\n", "                   22.60000038, 22.63999939, 22.68000031, 22.71999931,\n", "                   22.76000023, 22.79999924, 22.84000015, 22.87999916,\n", "                   22.92000008, 22.95999908, 23.        , 23.04000092,\n", "                   23.07999992, 23.12000084, 23.15999985, 23.20000076,\n", "                   23.23999977, 23.28000069, 23.31999969, 23.36000061,\n", "                   23.39999962, 23.44000053, 23.47999954, 23.52000046,\n", "                   23.55999947, 23.60000038, 23.63999939, 23.68000031,\n", "                   23.71999931, 23.76000023, 23.79999924, 23.84000015,\n", "                   23.87999916, 23.92000008, 23.95999908, 24.        ,\n", "                   24.04000092, 24.07999992, 24.12000084, 24.15999985,\n", "                   24.20000076, 24.23999977, 24.28000069, 24.31999969,\n", "                   24.36000061, 24.39999962, 24.44000053, 24.47999954,\n", "                   24.52000046, 24.55999947, 24.60000038, 24.63999939,\n", "                   24.68000031, 24.71999931, 24.76000023, 24.79999924,\n", "                   24.84000015, 24.87999916, 24.92000008, 24.95999908,\n", "                   25.        , 25.04000092, 25.07999992, 25.12000084,\n", "                   25.15999985, 25.20000076, 25.23999977, 25.28000069,\n", "                   25.31999969, 25.36000061, 25.39999962, 25.44000053,\n", "                   25.47999954, 25.52000046, 25.55999947, 25.60000038,\n", "                   25.63999939, 25.68000031, 25.71999931, 25.76000023,\n", "                   25.79999924, 25.84000015, 25.87999916, 25.92000008,\n", "                   25.95999908, 26.        , 26.04000092, 26.07999992,\n", "                   26.12000084, 26.15999985, 26.20000076, 26.23999977,\n", "                   26.28000069, 26.31999969, 26.36000061, 26.39999962,\n", "                   26.44000053, 26.47999954, 26.52000046, 26.55999947,\n", "                   26.60000038, 26.63999939, 26.68000031, 26.71999931,\n", "                   26.76000023, 26.79999924, 26.84000015, 26.87999916,\n", "                   26.92000008, 26.95999908, 27.        , 27.04000092,\n", "                   27.07999992, 27.12000084, 27.15999985, 27.20000076,\n", "                   27.23999977, 27.28000069, 27.31999969, 27.36000061,\n", "                   27.39999962, 27.44000053, 27.47999954, 27.52000046,\n", "                   27.55999947, 27.60000038, 27.63999939, 27.68000031,\n", "                   27.71999931, 27.76000023, 27.79999924, 27.84000015,\n", "                   27.87999916, 27.92000008, 27.95999908, 28.        ,\n", "                   28.04000092, 28.07999992, 28.12000084, 28.15999985,\n", "                   28.20000076, 28.23999977, 28.28000069, 28.31999969,\n", "                   28.36000061, 28.39999962, 28.44000053, 28.47999954,\n", "                   28.52000046, 28.55999947, 28.60000038, 28.63999939,\n", "                   28.68000031, 28.71999931, 28.76000023, 28.79999924,\n", "                   28.84000015, 28.87999916, 28.92000008, 28.95999908,\n", "                   29.        , 29.04000092, 29.07999992, 29.12000084,\n", "                   29.15999985, 29.20000076, 29.23999977, 29.28000069,\n", "                   29.31999969, 29.36000061, 29.39999962, 29.44000053,\n", "                   29.47999954, 29.52000046, 29.55999947, 29.60000038,\n", "                   29.63999939, 29.68000031, 29.71999931, 29.76000023,\n", "                   29.79999924, 29.84000015, 29.87999916, 29.92000008,\n", "                   29.95999908, 30.        , 30.04000092, 30.07999992,\n", "                   30.12000084, 30.15999985, 30.20000076, 30.23999977,\n", "                   30.28000069, 30.31999969, 30.36000061, 30.39999962,\n", "                   30.44000053, 30.47999954, 30.52000046, 30.55999947,\n", "                   30.60000038, 30.63999939, 30.68000031, 30.71999931,\n", "                   30.76000023, 30.79999924, 30.84000015, 30.87999916,\n", "                   30.92000008, 30.95999908, 31.        , 31.04000092,\n", "                   31.07999992, 31.12000084, 31.15999985, 31.20000076,\n", "                   31.23999977, 31.28000069, 31.31999969, 31.36000061,\n", "                   31.39999962, 31.44000053, 31.47999954, 31.52000046,\n", "                   31.55999947, 31.60000038, 31.63999939, 31.68000031,\n", "                   31.71999931, 31.76000023, 31.79999924, 31.84000015,\n", "                   31.87999916, 31.92000008],\n", "             mask=False,\n", "       fill_value=1e+20)"]}, "execution_count": 41, "metadata": {}, "output_type": "execute_result"}], "source": ["f.variables[\"lat\"][:]"]}, {"cell_type": "code", "execution_count": 22, "metadata": {"ExecuteTime": {"end_time": "2021-11-09T05:29:18.057883Z", "start_time": "2021-11-09T05:29:18.050884Z"}}, "outputs": [], "source": ["t_grid = f.variables['time'][:]\n", "time_origin = datetime.strptime(f.variables['time'].__dict__['time_origin'] + ' +0000','%Y-%m-%d %H:%M:%S %z')\n", "abs_t_grid = [(time_origin + timedelta(hours=X)).timestamp() for X in t_grid.data]\n", "t_0 = 1630540800.0\n", "t_T = 1630567000.0\n", "num_interval = int((t_T - t_0)/(3600*1)+1)\n", "t_grid = [t_0 + i*1*3600 for i in range(num_interval)]"]}, {"cell_type": "code", "execution_count": 101, "metadata": {"ExecuteTime": {"end_time": "2021-11-05T08:13:14.218667Z", "start_time": "2021-11-05T08:13:14.214067Z"}}, "outputs": [{"data": {"text/plain": ["[1630540800.0,\n", " 1630544400.0,\n", " 1630548000.0,\n", " 1630551600.0,\n", " 1630555200.0,\n", " 1630558800.0,\n", " 1630562400.0,\n", " 1630566000.0,\n", " 1630569600.0,\n", " 1630573200.0,\n", " 1630576800.0,\n", " 1630580400.0,\n", " 1630584000.0,\n", " 1630587600.0,\n", " 1630591200.0,\n", " 1630594800.0,\n", " 1630598400.0,\n", " 1630602000.0,\n", " 1630605600.0,\n", " 1630609200.0,\n", " 1630612800.0,\n", " 1630616400.0,\n", " 1630620000.0,\n", " 1630623600.0]"]}, "execution_count": 101, "metadata": {}, "output_type": "execute_result"}], "source": ["    # create dict to output\n", "    grids_dict = {'x_grid': xgrid[xgrid_inds], 'y_grid': ygrid[ygrid_inds],\n", "                  't_grid': abs_t_grid[slice_for_time_dim], 'fixed_time_idx': fixed_time_idx}\n", "\n", "    # log what data has been subsetted\n", "    if fixed_time is None:\n", "        print(\"Subsetted data from {start} to {end} in {n_steps} time steps of {time:.2f} hour(s) resolution\".format(\n", "            start=datetime.utcfromtimestamp(grids_dict['t_grid'][0]).strftime('%Y-%m-%d %H:%M:%S UTC'),\n", "            end=datetime.utcfromtimestamp(grids_dict['t_grid'][-1]).strftime('%Y-%m-%d %H:%M:%S UTC'),\n", "            n_steps=len(grids_dict['t_grid']), time=(grids_dict['t_grid'][1] - grids_dict['t_grid'][0])/3600.))\n", "    else:\n", "        print(\"Subsetted data to fixed time at: {time}\".format(\n", "            time=datetime.utcfromtimestamp(grids_dict['t_grid'][0]).strftime('%Y-%m-%d %H:%M:%S UTC')))\n"]}, {"cell_type": "code", "execution_count": 99, "metadata": {"ExecuteTime": {"end_time": "2021-11-09T09:59:30.211141Z", "start_time": "2021-11-09T09:59:30.204773Z"}}, "outputs": [{"data": {"text/plain": ["(1, 1, 1)"]}, "execution_count": 99, "metadata": {}, "output_type": "execute_result"}], "source": []}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    #Finding t_grid according to temp_res_in_h\n", "    #num_interval = (t_T - t_0)/(3600*temp_res_in_h)+1\n", "    #t_grid = [t_0+i*temp_res_in_h*3600 for i in range(num_interval)]\n", "    #if t_T%temp_res_in_h!=0:\n", "        #t_grid.append(t_T)\n", "    "]}], "metadata": {"has_local_update": false, "is_local": true, "is_remote": true, "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.7.9"}, "last_sync_time": "2021-11-14T05:51:12.391000"}, "nbformat": 4, "nbformat_minor": 4}