{"cells": [{"cell_type": "markdown", "metadata": {"heading_collapsed": true}, "source": ["## File Processing"]}, {"cell_type": "code", "execution_count": 1, "metadata": {"ExecuteTime": {"end_time": "2021-10-18T13:59:58.490948Z", "start_time": "2021-10-18T13:59:58.272584Z"}, "hidden": true}, "outputs": [{"data": {"text/plain": ["c3.FetchResult<HindcastFile>(\n", " objs=c3.Arry<HindcastFile>([c3.HindcastFile(\n", "         id='007e2816-3905-434b-b957-f7b0d0b03f46',\n", "         name='GOMu0.04-expt_90.1m000-2021-2021-09-15T04:00:00Z.nc',\n", "         meta=c3.Meta(\n", "                tenantTagId=150,\n", "                tenant='dev',\n", "                tag='tc01d',\n", "                created=datetime.datetime(2021, 10, 15, 16, 9, 43, tzinfo=datetime.timezone.utc),\n", "                createdBy='dadams@illinois.edu',\n", "                updated=datetime.datetime(2021, 10, 15, 16, 11, 12, tzinfo=datetime.timezone.utc),\n", "                updatedBy='worker',\n", "                timestamp=datetime.datetime(2021, 10, 15, 16, 11, 12, tzinfo=datetime.timezone.utc),\n", "                fetchInclude='[]',\n", "                fetchType='HindcastFile'),\n", "         version=3,\n", "         hindcastArchive=c3.HindcastArchive(\n", "                           id='7a187ef2-d88d-4658-b19f-451aef87535f'),\n", "         subsetOptions=c3.HycomSubsetOptions(\n", "                         timeRange=c3.TimeRange(\n", "                                     start=datetime.datetime(2021, 9, 15, 4, 0),\n", "                                     end=datetime.datetime(2021, 9, 15, 4, 0)),\n", "                         timeStride=1,\n", "                         vars='water_u,water_v',\n", "                         disableLLSubset='off',\n", "                         geospatialCoverage=c3.GeospatialCoverage(\n", "                                              start=c3.LatLong(\n", "                                                      latitude=22.3,\n", "                                                      longitude=-96.5),\n", "                                              end=c3.LatLong(\n", "                                                    latitude=28.6,\n", "                                                    longitude=-85.5)),\n", "                         disableProjSubset='on',\n", "                         horizStride=1,\n", "                         vertStride=1,\n", "                         addLatLon='false',\n", "                         accept='netcdf4'),\n", "         status='downloaded',\n", "         file=c3.File(\n", "                contentLength=3238548,\n", "                contentLocation='fs/dti/mpodolsky/hycom-test/hindcast/7a187ef2-d88d-4658-b19f-451aef87535f/GOMu0.04-expt_90.1m000-2021-2021-09-15T04:00:00Z.nc',\n", "                contentType='application/json',\n", "                eTag='\"0x8D98FF6681E34C9\"',\n", "                contentMD5='UBPIG+hhhjXu2AxW66icDw==',\n", "                hasMetadata=True,\n", "                url='hycom-test/hindcast/7a187ef2-d88d-4658-b19f-451aef87535f/GOMu0.04-expt_90.1m000-2021-2021-09-15T04:00:00Z.nc')),\n", "        c3.HindcastFile(\n", "         id='007e88f7-b86d-4379-a194-a73e2d003afb',\n", "         name='GOMu0.04-expt_90.1m000-2021-2021-09-23T23:00:00Z.nc',\n", "         meta=c3.Meta(\n", "                tenantTagId=150,\n", "                tenant='dev',\n", "                tag='tc01d',\n", "                created=datetime.datetime(2021, 10, 15, 16, 9, 43, tzinfo=datetime.timezone.utc),\n", "                createdBy='dadams@illinois.edu',\n", "                updated=datetime.datetime(2021, 10, 15, 16, 13, 20, tzinfo=datetime.timezone.utc),\n", "                updatedBy='worker',\n", "                timestamp=datetime.datetime(2021, 10, 15, 16, 13, 20, tzinfo=datetime.timezone.utc),\n", "                fetchInclude='[]',\n", "                fetchType='HindcastFile'),\n", "         version=3,\n", "         hindcastArchive=c3.HindcastArchive(\n", "                           id='7a187ef2-d88d-4658-b19f-451aef87535f'),\n", "         subsetOptions=c3.HycomSubsetOptions(\n", "                         timeRange=c3.TimeRange(\n", "                                     start=datetime.datetime(2021, 9, 23, 23, 0),\n", "                                     end=datetime.datetime(2021, 9, 23, 23, 0)),\n", "                         timeStride=1,\n", "                         vars='water_u,water_v',\n", "                         disableLLSubset='off',\n", "                         geospatialCoverage=c3.GeospatialCoverage(\n", "                                              start=c3.LatLong(\n", "                                                      latitude=22.3,\n", "                                                      longitude=-96.5),\n", "                                              end=c3.LatLong(\n", "                                                    latitude=28.6,\n", "                                                    longitude=-85.5)),\n", "                         disableProjSubset='on',\n", "                         horizStride=1,\n", "                         vertStride=1,\n", "                         addLatLon='false',\n", "                         accept='netcdf4'),\n", "         status='downloaded',\n", "         file=c3.File(\n", "                contentLength=3235316,\n", "                contentLocation='fs/dti/mpodolsky/hycom-test/hindcast/7a187ef2-d88d-4658-b19f-451aef87535f/GOMu0.04-expt_90.1m000-2021-2021-09-23T23:00:00Z.nc',\n", "                contentType='application/json',\n", "                eTag='\"0x8D98FF6B4AA03CF\"',\n", "                contentMD5='uIrd0le7Cbn3dOkwAJvj/g==',\n", "                hasMetadata=True,\n", "                url='hycom-test/hindcast/7a187ef2-d88d-4658-b19f-451aef87535f/GOMu0.04-expt_90.1m000-2021-2021-09-23T23:00:00Z.nc')),\n", "        c3.HindcastFile(\n", "         id='00b02e51-b42e-485f-94b3-0aaf32635544',\n", "         name='GOMu0.04-expt_90.1m000-2021-2021-09-29T11:00:00Z.nc',\n", "         meta=c3.Meta(\n", "                tenantTagId=150,\n", "                tenant='dev',\n", "                tag='tc01d',\n", "                created=datetime.datetime(2021, 10, 15, 16, 9, 43, tzinfo=datetime.timezone.utc),\n", "                createdBy='dadams@illinois.edu',\n", "                updated=datetime.datetime(2021, 10, 15, 16, 13, 39, tzinfo=datetime.timezone.utc),\n", "                updatedBy='worker',\n", "                timestamp=datetime.datetime(2021, 10, 15, 16, 13, 39, tzinfo=datetime.timezone.utc),\n", "                fetchInclude='[]',\n", "                fetchType='HindcastFile'),\n", "         version=3,\n", "         hindcastArchive=c3.HindcastArchive(\n", "                           id='7a187ef2-d88d-4658-b19f-451aef87535f'),\n", "         subsetOptions=c3.HycomSubsetOptions(\n", "                         timeRange=c3.TimeRange(\n", "                                     start=datetime.datetime(2021, 9, 29, 11, 0),\n", "                                     end=datetime.datetime(2021, 9, 29, 11, 0)),\n", "                         timeStride=1,\n", "                         vars='water_u,water_v',\n", "                         disableLLSubset='off',\n", "                         geospatialCoverage=c3.GeospatialCoverage(\n", "                                              start=c3.LatLong(\n", "                                                      latitude=22.3,\n", "                                                      longitude=-96.5),\n", "                                              end=c3.LatLong(\n", "                                                    latitude=28.6,\n", "                                                    longitude=-85.5)),\n", "                         disableProjSubset='on',\n", "                         horizStride=1,\n", "                         vertStride=1,\n", "                         addLatLon='false',\n", "                         accept='netcdf4'),\n", "         status='downloaded',\n", "         file=c3.File(\n", "                contentLength=3246079,\n", "                contentLocation='fs/dti/mpodolsky/hycom-test/hindcast/7a187ef2-d88d-4658-b19f-451aef87535f/GOMu0.04-expt_90.1m000-2021-2021-09-29T11:00:00Z.nc',\n", "                contentType='application/json',\n", "                eTag='\"0x8D98FF6C012A88D\"',\n", "                contentMD5='C06yKqtd2OzjBSdBcPWfcA==',\n", "                hasMetadata=True,\n", "                url='hycom-test/hindcast/7a187ef2-d88d-4658-b19f-451aef87535f/GOMu0.04-expt_90.1m000-2021-2021-09-29T11:00:00Z.nc')),\n", "        c3.HindcastFile(\n", "         id='00b425f7-6d17-4c82-97c2-06e223919a60',\n", "         name='GOMu0.04-expt_90.1m000-2021-2021-09-07T06:00:00Z.nc',\n", "         meta=c3.Meta(\n", "                tenantTagId=150,\n", "                tenant='dev',\n", "                tag='tc01d',\n", "                created=datetime.datetime(2021, 10, 15, 16, 9, 43, tzinfo=datetime.timezone.utc),\n", "                createdBy='dadams@illinois.edu',\n", "                updated=datetime.datetime(2021, 10, 15, 16, 13, 43, tzinfo=datetime.timezone.utc),\n", "                updatedBy='worker',\n", "                timestamp=datetime.datetime(2021, 10, 15, 16, 13, 43, tzinfo=datetime.timezone.utc),\n", "                fetchInclude='[]',\n", "                fetchType='HindcastFile'),\n", "         version=3,\n", "         hindcastArchive=c3.HindcastArchive(\n", "                           id='7a187ef2-d88d-4658-b19f-451aef87535f'),\n", "         subsetOptions=c3.HycomSubsetOptions(\n", "                         timeRange=c3.TimeRange(\n", "                                     start=datetime.datetime(2021, 9, 7, 6, 0),\n", "                                     end=datetime.datetime(2021, 9, 7, 6, 0)),\n", "                         timeStride=1,\n", "                         vars='water_u,water_v',\n", "                         disableLLSubset='off',\n", "                         geospatialCoverage=c3.GeospatialCoverage(\n", "                                              start=c3.LatLong(\n", "                                                      latitude=22.3,\n", "                                                      longitude=-96.5),\n", "                                              end=c3.LatLong(\n", "                                                    latitude=28.6,\n", "                                                    longitude=-85.5)),\n", "                         disableProjSubset='on',\n", "                         horizStride=1,\n", "                         vertStride=1,\n", "                         addLatLon='false',\n", "                         accept='netcdf4'),\n", "         status='downloaded',\n", "         file=c3.File(\n", "                contentLength=3248496,\n", "                contentLocation='fs/dti/mpodolsky/hycom-test/hindcast/7a187ef2-d88d-4658-b19f-451aef87535f/GOMu0.04-expt_90.1m000-2021-2021-09-07T06:00:00Z.nc',\n", "                contentType='application/json',\n", "                eTag='\"0x8D98FF6C21FA1BB\"',\n", "                contentMD5='hSca/Hs9VThyTsEr8qjNYA==',\n", "                hasMetadata=True,\n", "                url='hycom-test/hindcast/7a187ef2-d88d..."]}, "execution_count": 1, "metadata": {}, "output_type": "execute_result"}], "source": ["files = c3.HindcastFile.fetch(\n", "    {\n", "        'include': \"this\",\n", "        'filter': 'status==\"downloaded\"'\n", "    })\n", "files"]}, {"cell_type": "code", "execution_count": 56, "metadata": {"ExecuteTime": {"end_time": "2021-10-20T18:22:40.778949Z", "start_time": "2021-10-20T18:22:40.770423Z"}, "hidden": true}, "outputs": [], "source": ["# Prototype for prosessing hindcast files\n", "from datetime import datetime, timedelta\n", "\n", "def process(this):\n", "    \"\"\" Process a single Hindcast NetCDF file into the Hindcast__Data types\"\"\"\n", "    # extract surface data for a variable\n", "    hycom_file = c3.HycomUtil.nc_open(this.file.url)\n", "    time_origin = datetime.strptime(hycom_file.variables['time'].__dict__['time_origin'] + ' +0000',\n", "                                        '%Y-%m-%d %H:%M:%S %z')\n", "    \n", "    # extract lat-long, or derive this from types\n", "    # Not yet done:determine the offset for each based on the subsetOptions for this file\n", "    # Note: for now it's just an integer list\n", "    latitudes = range(len(hycom_file['lat']))\n", "    longitudes = range(len(hycom_file['lon']))\n", "    time = time_origin + timedelta(hours=hycom_file.variables['time'][:][0])\n", "\n", "    # Create list of instantiated SurfaceHindcastData types\n", "    # Create a parent id for each lat-long pair in the file.\n", "    # use lat-long indicies to create a string parent id\n", "\n", "    data_records = [\n", "        c3.SurfaceHindcastData( # look at the code to understand, TimeDataPoint (Check out Type)\n", "            **{\n", "                'start': time,\n", "                'parent': 'HNDCST_SRFC_' + str(i) + '-' + str(j),\n", "                'name': 'water_u',  # variable\n", "                'for': time,           # timestamp\n", "                'water_u': hycom_file.variables['water_u'][:].data[0,0,i,j],\n", "                'water_v': hycom_file.variables['water_v'][:].data[0,0,i,j]\n", "            }\n", "        )\n", "        for i in latitudes[:2]\n", "            for j in longitudes[:2]\n", "    ]\n", "    # upsert to data store\n", "    c3.SurfaceHindcastData.upsertBatch(data_records)\n", "\n", "    # close the file ds, url\n", "    c3.HycomUtil.nc_close(ds=hycom_file, url=this.file.url)\n", "    \n", "    # aggregation in space is possible but a bit more complex"]}, {"cell_type": "code", "execution_count": 60, "metadata": {"ExecuteTime": {"end_time": "2021-10-20T18:30:56.621490Z", "start_time": "2021-10-20T18:25:27.800703Z"}, "hidden": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["0\n", "1\n", "2\n", "3\n", "4\n", "5\n", "6\n", "7\n", "8\n", "9\n", "10\n", "11\n", "12\n", "13\n", "14\n", "15\n", "16\n", "17\n", "18\n", "19\n", "20\n", "21\n", "22\n", "23\n", "24\n", "25\n", "26\n", "27\n", "28\n", "29\n", "30\n", "31\n", "32\n", "33\n", "34\n", "35\n", "36\n", "37\n", "38\n", "39\n", "40\n", "41\n", "42\n", "43\n", "44\n", "45\n", "46\n", "47\n", "48\n", "49\n", "50\n", "51\n", "52\n", "53\n", "54\n", "55\n", "56\n", "57\n", "58\n", "59\n", "60\n", "61\n", "62\n", "63\n", "64\n", "65\n", "66\n", "67\n", "68\n", "69\n", "70\n", "71\n", "72\n", "73\n", "74\n", "75\n", "76\n", "77\n", "78\n", "79\n", "80\n", "81\n", "82\n", "83\n", "84\n", "85\n", "86\n", "87\n", "88\n", "89\n", "90\n", "91\n", "92\n", "93\n", "94\n", "95\n", "96\n", "97\n", "98\n", "99\n", "100\n", "101\n", "102\n", "103\n", "104\n", "105\n", "106\n", "107\n", "108\n", "109\n", "110\n", "111\n", "112\n", "113\n", "114\n", "115\n", "116\n", "117\n", "118\n", "119\n", "120\n", "121\n", "122\n", "123\n", "124\n", "125\n", "126\n", "127\n", "128\n", "129\n", "130\n", "131\n", "132\n", "133\n", "134\n", "135\n", "136\n", "137\n", "138\n", "139\n", "140\n", "141\n", "142\n", "143\n", "144\n", "145\n", "146\n", "147\n", "148\n", "149\n", "150\n", "151\n", "152\n", "153\n", "154\n", "155\n", "156\n", "157\n", "158\n", "159\n", "160\n", "161\n", "162\n", "163\n", "164\n", "165\n", "166\n", "167\n"]}], "source": ["files = c3.HindcastFile.fetch({\n", "    'include': \"this,file.file.url\",\n", "    'filter': 'hindcastArchive==\"ef9fdcb6-050e-4986-8fda-4868c9a67db7\"'\n", "}).objs\n", "cntr = 0\n", "for file in files:\n", "    print(cntr)\n", "    process(file)\n", "    cntr+=1\n", "    "]}, {"cell_type": "markdown", "metadata": {"heading_collapsed": true}, "source": ["## Time Check\n", "It should not be neccasary to introspect the file for time since the time information that was used to request teh file is soted in the db record.  Below is a verification of this assumption."]}, {"cell_type": "code", "execution_count": 11, "metadata": {"ExecuteTime": {"end_time": "2021-10-20T12:06:44.946562Z", "start_time": "2021-10-20T12:06:40.577025Z"}, "hidden": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["time origin: 2000-01-01 00:00:00+00:00\n", "time: 2021-10-01 12:00:00+00:00\n", "db times: [datetime.datetime(2021, 10, 1, 12, 0)]\n"]}], "source": ["from datetime import datetime, timedelta\n", "# Grab a file from an archive\n", "arid = 'ef9fdcb6-050e-4986-8fda-4868c9a67db7'\n", "ar = c3.HindcastArchive.get(arid)\n", "file = c3.HindcastFile.fetch(spec={\n", "    'filter': 'hindcastArchive==\"'+arid+'\" && status==\"downloaded\"'\n", "}).objs[0]\n", "\n", "# Open to netCDF dataset\n", "ds = c3.HycomUtil.nc_open(file.file.url)\n", "# Check time in NetCDF file\n", "time_origin = datetime.strptime(ds.variables['time'].__dict__['time_origin'] + ' +0000',\n", "                                        '%Y-%m-%d %H:%M:%S %z')\n", "print(f\"time origin: {time_origin}\")\n", "time = time_origin + timedelta(hours=ds.variables['time'][:][0])\n", "print(f\"time: {time}\")\n", "c3.HycomUtil.nc_close(ds,file.file.url)\n", "\n", "# Cross check time from NetCDF file with time in DB\n", "timeRange = file.subsetOptions.timeRange\n", "timeStep = timedelta(hours = file.subsetOptions.timeStride)\n", "def gentimes():\n", "    t = timeRange.start\n", "    while t <= timeRange.end:\n", "        yield t\n", "        t += timeStep\n", "times = list(gentimes())\n", "print (f\"db times: {times}\")"]}, {"cell_type": "markdown", "metadata": {"heading_collapsed": true}, "source": ["## Lat Long Check"]}, {"cell_type": "code", "execution_count": 45, "metadata": {"ExecuteTime": {"end_time": "2021-10-20T16:54:46.539028Z", "start_time": "2021-10-20T16:54:45.467031Z"}, "hidden": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["From file: [-96.47998047 -96.44000244 -96.40002441]\n", "Diffs from file: [0.03997802734375, 0.03997802734375]\n", "From subsetOptions: -96.5\n", "38.02137404580153\n", "38\n", "-96.47998046875\n"]}], "source": ["\n", "# Grab a file from an archive\n", "arid = 'ef9fdcb6-050e-4986-8fda-4868c9a67db7'\n", "ar = c3.HindcastArchive.get(arid)\n", "file = c3.HindcastFile.fetch(spec={\n", "    'include': \"this,hindcastArchive.hindcast.dataset.geospatialCoverage,hindcastArchive.hindcast.dataset.geospatialResolution\",\n", "    'filter': 'hindcastArchive==\"'+arid+'\" && status==\"downloaded\"'\n", "}).objs[0]\n", "\n", "# Open to netCDF dataset\n", "ds = c3.HycomUtil.nc_open(file.file.url)\n", "xgrid = ds.variables['lon'][:]\n", "print(f\"From file: {xgrid[0:3]}\")\n", "print(f\"Diffs from file: {[xgrid[1]-xgrid[0],xgrid[2]-xgrid[1]]}\")\n", "print(f\"From subsetOptions: {file.subsetOptions.geospatialCoverage.start.longitude}\")\n", "\n", "# compute expected offset\n", "#dataset = c3.HycomDataset.get('GOMu0.04/expt_90.1m000')\n", "xres = file.hindcastArchive.hindcast.dataset.geospatialResolution.lonResolution\n", "big_xgrid_start = file.hindcastArchive.hindcast.dataset.geospatialCoverage.start.longitude\n", "big_xgrid_end = file.hindcastArchive.hindcast.dataset.geospatialCoverage.end.longitude\n", "xsteps = (xgrid[0] - big_xgrid_start)/xres\n", "xstart_offset = int (xsteps)\n", "print (xsteps)\n", "print (xstart_offset)\n", "\n", "# Cross check location in the HycomXGrid type\n", "big_xgrid = c3.HycomXGrid.fetch(spec={\n", "    'order': \"ascending(index)\",\n", "    'filter': f\"index=={diff}\"\n", "}).objs\n", "for x in big_xgrid:\n", "    print(x.longitude)\n"]}, {"cell_type": "code", "execution_count": 1, "metadata": {"ExecuteTime": {"end_time": "2021-10-20T19:46:02.135867Z", "start_time": "2021-10-20T19:46:00.476108Z"}, "hidden": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["38 -96.47998046875 0.0\n"]}], "source": ["# Grab a file from an archive\n", "arid = 'ef9fdcb6-050e-4986-8fda-4868c9a67db7'\n", "ar = c3.HindcastArchive.get(arid)\n", "file = c3.HindcastFile.fetch(spec={\n", "    'include': \"this,hindcastArchive.hindcast.dataset.geospatialCoverage,hindcastArchive.hindcast.dataset.geospatialResolution\",\n", "    'filter': 'hindcastArchive==\"'+arid+'\" && status==\"downloaded\"'\n", "}).objs[0]\n", "\n", "# Open to netCDF dataset\n", "ds = c3.HycomUtil.nc_open(file.file.url)\n", "xgrid = ds.variables['lon'][:]\n", "big_xgrid = c3.HycomXGrid.fetch(spec={\n", "    'order': \"ascending(abs(\"+str(xgrid[0])+\"-longitude))\",\n", "    'limit': 1\n", "}).objs\n", "for x in big_xgrid:\n", "    print(x.index,x.longitude, abs(xgrid[0] - x.longitude))"]}, {"cell_type": "markdown", "metadata": {"heading_collapsed": true}, "source": ["## Use EvalMetricsSourceSpec"]}, {"cell_type": "code", "execution_count": 123, "metadata": {"ExecuteTime": {"end_time": "2021-10-25T10:55:46.896526Z", "start_time": "2021-10-25T10:55:46.886052Z"}, "hidden": true}, "outputs": [], "source": ["from datetime import datetime\n", "import numpy as np\n", "\n", "def getDataSubset(imin,jmin,imax,jmax,metric,start,end,batchSize=100):\n", "    \"\"\"Returns a subset for the given metric data from the given start and end time.\n", "\n", "    Args:\n", "        imin (int): Minimum longitude from lat-long pair indices\n", "        jmin (int): Minimum latitude from lat-long pair indices\n", "        imax (int): Maximum longitude from lat-long pair indices\n", "        jmax (int): Maximum latitude from lat-long pair indices\n", "        metric (str): Metric to be extracted from the dataset\n", "        start (datetime): Start time of the subset\n", "        end (datetime): End time of the subset\n", "        batchSize (int): Number of lat-long pairs to be extracted in each batch\n", "\n", "    Returns:\n", "        array: Numpy array of the subsetted data ordered as [time,lat,lon]\n", "\n", "    Notes:\n", "        - Currently limited to hour resolution\n", "        - Only handles a single metric\n", "        - The data indexing is not efficient since the indices must be parsed from the\n", "        lat-long pair ids.  If the HycomLatLong pair table was ordered by i,j, then\n", "        the pairs would get extracted in i,j order and there would be no need to parse.\n", "        this could be done by defining a new id that is a simple ascending integer.\n", "\n", "    \"\"\"\n", "    \n", "    my_spec = c3.EvalMetricsSpec(\n", "            filter = \"i>=\"+str(imin)+\" && i<=\"+str(imax)+\" && j>=\"+str(jmin)+\" && j<=\"+str(jmax),\n", "            limit = -1,\n", "            expressions = [metric],\n", "            start = start.strftime(\"%Y-%m-%d\"),\n", "            end = end.strftime(\"%Y-%m-%d\"),\n", "            interval = \"HOUR\" \n", "        )\n", "    # Evaluate the Spec using EvalSourceSpec which returns a stream of numpy arrays\n", "    sourceType = c3.TypeRef(typeName=\"HycomLatLongPair\")\n", "    em_source_spec = c3.EvalMetricsSourceSpec.createNdArraySourceSpec(my_spec, sourceType)\n", "    em_source_spec.batchExport()\n", "    stream_spec = c3.BatchStreamSpec(batchSize=batchSize)\n", "    source_stream = em_source_spec.toStream(stream_spec)\n", "    \n", "    # Process the data in to a (time,long,lat) data array\n", "    duration = end - start\n", "    duration_in_s = duration.total_seconds()\n", "    nt = int(divmod(duration_in_s, 3600)[0]) # total duration in hours\n", "    data = np.zeros((nt,imax-imin+1,jmax-jmin+1))\n", "    while source_stream.hasNext():\n", "        stream = source_stream.next()\n", "        idi = -1\n", "        # Transpose time series\n", "        for id in stream.indices[0]:\n", "            idi += 1\n", "            istr,jstr = id.split('_')[1].split('-')\n", "            i = int(istr) - imin\n", "            j = int(jstr) - jmin\n", "            ti = 0\n", "            for t in stream.indices[2]:\n", "                data[ti,i,j] = stream.data[idi,0,ti]\n", "                ti += 1\n", "    \n", "    # Cleans up any persisted files storing snapshot of data source\n", "    em_source_spec.cleanUp()\n", "    # Removes spec from database\n", "    em_source_spec.remove()\n", "    return data"]}, {"cell_type": "code", "execution_count": 128, "metadata": {"ExecuteTime": {"end_time": "2021-10-25T10:59:10.205996Z", "start_time": "2021-10-25T10:58:54.880095Z"}, "hidden": true}, "outputs": [{"data": {"text/plain": ["(168, 10, 10)"]}, "execution_count": 128, "metadata": {}, "output_type": "execute_result"}], "source": ["udata = getDataSubset(\n", "    imin = 81,\n", "    jmin = 81,\n", "    imax = 90,\n", "    jmax = 90,\n", "    metric = \"TestAverageWaterU\",\n", "    start = datetime(2021,10,1),\n", "    end = datetime(2021,10,8)\n", ")\n", "udata.shape"]}, {"cell_type": "markdown", "metadata": {"heading_collapsed": true}, "source": ["## Current implementation of subsetting from nc file example"]}, {"cell_type": "code", "execution_count": 23, "metadata": {"ExecuteTime": {"end_time": "2021-10-23T10:49:42.833083Z", "start_time": "2021-10-23T10:49:42.816109Z"}, "hidden": true}, "outputs": [], "source": ["from statistics import mean\n", "from datetime import datetime, timedelta\n", "import os\n", "import netCDF4\n", "import numpy as np\n", "import bisect\n", "def get_current_data_subset(nc_file, x_0, x_T, deg_around_x0_xT_box, fixed_time=None,\n", "                            temporal_stride=1, temp_horizon_in_h=None):\n", "    \"\"\" Function to read a subset of the nc_file current data bounded by a box spanned by the x_0 and x_T points.\n", "    Inputs:\n", "        nc_file                 full path to nc file\n", "        x_0                     [lat, lon, charge, timestamp in POSIX]\n", "        x_T                     [lon, lat] goal locations\n", "        deg_around_x0_xT_box    float, buffer around the box in degrees\n", "        fixed_time              if None returns time-varying currents, \n", "                                otherwise datetime object of the fixed time -> returns ocean current grid at or before time\n", "                                the time of x_0 is then ignored\n", "        temporal_stride         int, if a stride of the temporal values is used (every temporal_stride hours)\n", "        temp_horizon            if None: all available time of the file will be provided\n", "                                otherwise float, maximum temp_horizon to look ahead of x_0 time in hours\n", "                                \n", "    Outputs:\n", "        grids_dict              dict containing x_grid, y_grid, t_grid, fixed_time_idx\n", "        u_data                  [T, Y, X] matrix of the ocean currents in x direction in m/s\n", "        v_data                  [T, Y, X] matrix of the ocean currents in y direction in m/s\n", "        \n", "    \"\"\"\n", "    \n", "    f = netCDF4.Dataset(nc_file)\n", "\n", "    # extract positiond & start_time for the indexing\n", "    x_0_pos = x_0[:2]\n", "    x_0_posix_time = x_0[3]\n", "    x_T = x_T[:2]\n", "\n", "    # Step 1: get the grids\n", "    xgrid = f.variables['lon'][:]\n", "    ygrid = f.variables['lat'][:]\n", "    t_grid = f.variables['time'][:] # not this is in hours from HYCOM data!\n", "    \n", "    # this is needed because the time origin in hindcast and forecase nc files is different. Very handcrafted.\n", "    try:\n", "        time_origin = datetime.strptime(f.variables['time'].__dict__['time_origin'] + ' +0000',\n", "                                    '%Y-%m-%d %H:%M:%S %z')\n", "    except:\n", "        time_origin = datetime.strptime(f.variables['time'].__dict__['units'] + ' +0000',\n", "                                                 'hours since %Y-%m-%d %H:%M:%S.000 UTC %z')\n", "\n", "    # Step 2: find the sub-setting\n", "    # find the lat & lon sub-set bounds\n", "    lon_bnds = [min(x_0_pos[0], x_T[0]) - deg_around_x0_xT_box, max(x_0_pos[0], x_T[0]) + deg_around_x0_xT_box]\n", "    lat_bnds = [min(x_0_pos[1], x_T[1]) - deg_around_x0_xT_box, max(x_0_pos[1], x_T[1]) + deg_around_x0_xT_box]\n", "\n", "    # get the respective indices from the grids\n", "    ygrid_inds = np.where((ygrid > lat_bnds[0]) & (ygrid < lat_bnds[1]))[0]\n", "    xgrid_inds = np.where((xgrid > lon_bnds[0]) & (xgrid < lon_bnds[1]))[0]\n", "    print(xgrid_inds)\n", "\n", "    # for time indexing transform to POSIX time\n", "    abs_t_grid = [(time_origin + timedelta(hours=X)).timestamp() for X in t_grid.data]\n", "    \n", "    # get the idx of the value left of the demanded time (for interpolation function)\n", "    t_start_idx = bisect.bisect_right(abs_t_grid, x_0_posix_time) - 1\n", "    if t_start_idx == len(abs_t_grid) - 1 or t_start_idx == -1:\n", "        raise ValueError(\"Requested subset time is outside of the nc4 file.\")\n", "\n", "    # get the max time if provided as input\n", "    if temp_horizon_in_h is None:   # all data provided\n", "        t_end_idx = len(abs_t_grid)-1\n", "    else:\n", "        t_end_idx = bisect.bisect_right(abs_t_grid, x_0_posix_time + temp_horizon_in_h*3600.)\n", "        if t_end_idx == len(abs_t_grid):\n", "            raise ValueError(\"nc4 file does not contain requested temporal horizon.\")\n", "\n", "    # fixed time logic if necessary\n", "    if fixed_time is None:\n", "        slice_for_time_dim = np.s_[t_start_idx:(t_end_idx+1):temporal_stride]\n", "        fixed_time_idx = None\n", "    else:\n", "        fixed_time_idx = bisect.bisect_right(abs_t_grid, fixed_time.timestamp()) - 1\n", "        slice_for_time_dim = np.s_[fixed_time_idx]\n", "\n", "    # Step 2: extract data\n", "    # raw water_u is [tdim, zdim, ydim, xdim]\n", "    if len(f.variables['water_u'].shape) == 4:  # if there is a depth dimension in the dataset\n", "        u_data = f.variables['water_u'][slice_for_time_dim, 0, ygrid_inds, xgrid_inds]\n", "        v_data = f.variables['water_v'][slice_for_time_dim, 0, ygrid_inds, xgrid_inds]\n", "    # raw water_u is [tdim, ydim, xdim]\n", "    elif len(f.variables['water_u'].shape) == 3:  # if there is no depth dimension in the dataset\n", "        u_data = f.variables['water_u'][slice_for_time_dim, ygrid_inds, xgrid_inds]\n", "        v_data = f.variables['water_v'][slice_for_time_dim, ygrid_inds, xgrid_inds]\n", "    else:\n", "        raise ValueError(\"Current data in nc file has neither 3 nor 4 dimensions. Check file.\")\n", "\n", "    # create dict to output\n", "    grids_dict = {'x_grid': xgrid[xgrid_inds], 'y_grid': ygrid[ygrid_inds],\n", "                  't_grid': abs_t_grid[slice_for_time_dim], 'fixed_time_idx': fixed_time_idx}\n", "\n", "    # log what data has been subsetted\n", "    if fixed_time is None:\n", "        print(\"Subsetted data from {start} to {end} in {n_steps} time steps of {time:.2f} hour(s) resolution\".format(\n", "            start=datetime.utcfromtimestamp(grids_dict['t_grid'][0]).strftime('%Y-%m-%d %H:%M:%S UTC'),\n", "            end=datetime.utcfromtimestamp(grids_dict['t_grid'][-1]).strftime('%Y-%m-%d %H:%M:%S UTC'),\n", "            n_steps=len(grids_dict['t_grid']), time=(grids_dict['t_grid'][1] - grids_dict['t_grid'][0])/3600.))\n", "    else:\n", "        print(\"Subsetted data to fixed time at: {time}\".format(\n", "            time=datetime.utcfromtimestamp(grids_dict['t_grid'][0]).strftime('%Y-%m-%d %H:%M:%S UTC')))\n", "\n", "    #TODO: we replace the masked array with fill value 0 because otherwise interpolation doesn't work.\n", "    # Though that means we cannot anymore detect if we're on land or not (need a way to do that/detect stranding)\n", "    # not sure yet if we'll do it in the simulator or where.\n", "    # return grids_dict, u_data.filled(fill_value=0.), v_data.filled(fill_value=0.)\n", "    return grids_dict, u_data, v_data"]}, {"cell_type": "code", "execution_count": 19, "metadata": {"ExecuteTime": {"end_time": "2021-10-23T10:48:04.590951Z", "start_time": "2021-10-23T10:48:03.172994Z"}, "hidden": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["GOMu0.04-expt_90.1m000-2021-2021-01-01T12:00:00Z-2021-01-02T12:00:00Z.nc\r\n", "GOMu0.04-expt_90.1m000-2021-2021-01-01T12:00:00Z.nc\r\n", "GOMu0.04-expt_90.1m000-2021-2021-01-03T12:00:00Z.nc\r\n", "GOMu0.04-expt_90.1m000-2021-2021-05-01T12:00:00Z-2021-01-05T12:00:00Z.nc\r\n", "GOMu0.04-expt_90.1m000-2021-2021-10-01T12:00:00Z.nc\r\n"]}], "source": ["# Grab a file from an archive\n", "arid = 'ef9fdcb6-050e-4986-8fda-4868c9a67db7'\n", "ar = c3.HindcastArchive.get(arid)\n", "file = c3.HindcastFile.fetch(spec={\n", "    'include': \"this\",\n", "    'filter': 'hindcastArchive==\"'+arid+'\" && status==\"downloaded\"'\n", "}).objs[0]\n", "\n", "# Open to netCDF dataset\n", "ds = c3.HycomUtil.nc_open(file.file.url)\n", "!ls /tmp"]}, {"cell_type": "code", "execution_count": 24, "metadata": {"ExecuteTime": {"end_time": "2021-10-23T10:49:45.310878Z", "start_time": "2021-10-23T10:49:45.294102Z"}, "hidden": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["[200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217\n", " 218 219 220 221 222 223 224]\n"]}, {"ename": "ValueError", "evalue": "Requested subset time is outside of the nc4 file.", "output_type": "error", "traceback": ["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m", "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)", "\u001b[0;32m<ipython-input-24-aa21bca6c9c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m                                                      \u001b[0mdeg_around_x0_xT_box\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m                                                      \u001b[0mfixed_time\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m                                                      temporal_stride)\n\u001b[0m", "\u001b[0;32m<ipython-input-23-a9e96556d7fc>\u001b[0m in \u001b[0;36mget_current_data_subset\u001b[0;34m(nc_file, x_0, x_T, deg_around_x0_xT_box, fixed_time, temporal_stride, temp_horizon_in_h)\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0mt_start_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbisect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbisect_right\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mabs_t_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_0_posix_time\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mt_start_idx\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mabs_t_grid\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt_start_idx\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Requested subset time is outside of the nc4 file.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;31m# get the max time if provided as input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;31mValueError\u001b[0m: Requested subset time is outside of the nc4 file."]}], "source": ["# settings\n", "hindcast_file = '/tmp/GOMu0.04-expt_90.1m000-2021-2021-10-01T12:00:00Z.nc'\n", "x_0 = [-88.0, 25.0, 1, 1622549410.0]  # lon, lat, battery, posix_time\n", "x_T = [-88.0, 26.3]\n", "deg_around_x0_xT_box = 0.5\n", "fixed_time = None\n", "temporal_stride = 1\n", "\n", "# function call\n", "grids_dict, u_data, v_data = get_current_data_subset(hindcast_file,\n", "                                                     x_0, x_T,\n", "                                                     deg_around_x0_xT_box,\n", "                                                     fixed_time,\n", "                                                     temporal_stride)"]}, {"cell_type": "code", "execution_count": null, "metadata": {"hidden": true}, "outputs": [], "source": []}], "metadata": {"has_local_update": false, "is_local": true, "is_remote": true, "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.7.9"}, "last_sync_time": "2021-11-17T19:32:10.104384"}, "nbformat": 4, "nbformat_minor": 4}