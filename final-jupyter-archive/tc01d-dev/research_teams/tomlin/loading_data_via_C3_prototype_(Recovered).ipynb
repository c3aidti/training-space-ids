{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Step 1: Formulate the query to the DB"]}, {"cell_type": "code", "execution_count": 25, "metadata": {"ExecuteTime": {"end_time": "2021-11-08T22:42:53.761823Z", "start_time": "2021-11-08T22:42:53.563883Z"}}, "outputs": [], "source": ["import numpy as np\n", "# Step 1: Get the id's of the subset of LatLonPairs via a DB Query\n", "objs_list = c3.HycomLatLongPair.fetch(\n", "    spec={\"include\": \"id, lat, lon\", \"filter\": \"lat > 24 && lat < 25 && lon > -95 && lon < -94\", \"order\": \"j,i\"}).objs\n", "\n", "\n", "\n", "ids_list = [obj.id for obj in objs_list]\n", "lat_list = [obj.lat for obj in objs_list]\n", "lon_list = [obj.lon for obj in objs_list]\n", "\n", "# create the x, y grids\n", "lat_grid = np.unique(np.array(lat_list))\n", "lon_grid = np.unique(np.array(lon_list))\n", "# ids_list\n"]}, {"cell_type": "code", "execution_count": 26, "metadata": {"ExecuteTime": {"end_time": "2021-11-08T22:42:55.289713Z", "start_time": "2021-11-08T22:42:55.285503Z"}}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["576\n"]}], "source": ["print(len(ids_list))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# Step 2: Query the DB"]}, {"cell_type": "code", "execution_count": 29, "metadata": {"ExecuteTime": {"end_time": "2021-11-08T22:43:30.825150Z", "start_time": "2021-11-08T22:43:19.967272Z"}}, "outputs": [], "source": ["# Step 2: Query with Metadata\n", "my_metric = c3.SimpleMetric(id = \"AverageWaterU_HycomLatLongPair\",\n", "                            name = \"AverageWaterU\",\n", "                            description = \"Calculates average surface X-velocity for the given interval\",\n", "                            srcType = \"HycomLatLongPair\",\n", "                            path = \"surfaceHindcastData\",\n", "                            expression = \"avg(avg(normalized.data.water_u))\"\n", "                           )\n", "\n", "my_metric.toJson()\n", "# Note: the above metric can also be specified in the /seed folder in the tags repo to be broadly available\n", "\n", "# Step 3: Create EvalMetricsSpec\n", "my_spec = c3.EvalMetricsSpec(\n", "            ids = ids_list[0:10],\n", "            expressions = [\"AverageWaterU\"],\n", "            start = \"2021-09-02T23:00:00\",\n", "            end = \"2021-09-15T00:00:00\",\n", "            interval = \"HOUR\", \n", "        )\n", "\n", "# Query the server with Metadata\n", "evalMetricsResult = c3.HycomLatLongPair.evalMetricsWithMetadata(spec=my_spec,\n", "                                                      overrideMetrics=[my_metric])\n", "\n"]}, {"cell_type": "code", "execution_count": 30, "metadata": {"ExecuteTime": {"end_time": "2021-11-08T22:43:30.854514Z", "start_time": "2021-11-08T22:43:30.827053Z"}}, "outputs": [{"data": {"text/plain": ["c3.Mapp<string, map<string,Timeseries>>({'GOMu0.04_76-148': c3.Mapp<string, Timeseries>({'AverageWaterU': c3.NormTimeseriesDouble(\n", "                                       m_start=datetime.datetime(2021, 9, 2, 23, 0),\n", "                                       m_end=datetime.datetime(2021, 9, 15, 0, 0),\n", "                                       m_data=c3.Arry<double>([-0.01900000125169754,\n", "                                                0.015000000596046448,\n", "                                                0.04800000041723251,\n", "                                                0.07300000637769699,\n", "                                                0.09000000357627869,\n", "                                                0.10100000351667404,\n", "                                                0.10000000149011612,\n", "                                                0.09000000357627869,\n", "                                                0.07500000298023224,\n", "                                                0.06000000238418579,\n", "                                                0.04400000348687172,\n", "                                                0.029000001028180122,\n", "                                                0.014000000432133675,\n", "                                                -0.003000000026077032,\n", "                                                -0.013000000268220901,\n", "                                                -0.02800000086426735,\n", "                                                -0.04000000283122063,\n", "                                                -0.052000001072883606,\n", "                                                -0.0690000057220459,\n", "                                                -0.08800000697374344,\n", "                                                -0.10100000351667404,\n", "                                                -0.11000000685453415,\n", "                                                -0.11300000548362732,\n", "                                                -0.10600000619888306,\n", "                                                -0.08900000154972076,\n", "                                                -0.06599999964237213,\n", "                                                -0.04000000283122063,\n", "                                                -0.018000001087784767,\n", "                                                -0.0010000000474974513,\n", "                                                0.01100000087171793,\n", "                                                0.012000000104308128,\n", "                                                0.0,\n", "                                                -0.01600000075995922,\n", "                                                -0.03100000135600567,\n", "                                                -0.04400000348687172,\n", "                                                -0.052000001072883606,\n", "                                                -0.05300000309944153,\n", "                                                -0.06700000166893005,\n", "                                                -0.0560000017285347,\n", "                                                -0.05400000140070915,\n", "                                                -0.052000001072883606,\n", "                                                -0.05300000309944153,\n", "                                                -0.058000002056360245,\n", "                                                -0.06599999964237213,\n", "                                                -0.07800000160932541,\n", "                                                -0.08800000697374344,\n", "                                                -0.09600000083446503,\n", "                                                -0.09800000488758087,\n", "                                                -0.08400000631809235,\n", "                                                -0.06400000303983688,\n", "                                                -0.032999999821186066,\n", "                                                -0.004000000189989805,\n", "                                                0.020000001415610313,\n", "                                                0.03800000250339508,\n", "                                                0.04500000178813934,\n", "                                                0.04100000113248825,\n", "                                                0.026000000536441803,\n", "                                                0.007000000216066837,\n", "                                                -0.010000000707805157,\n", "                                                -0.023000001907348633,\n", "                                                -0.030000001192092896,\n", "                                                -0.039000000804662704,\n", "                                                -0.03100000135600567,\n", "                                                -0.01900000125169754,\n", "                                                -0.014000000432133675,\n", "                                                -0.01100000087171793,\n", "                                                -0.015000000596046448,\n", "                                                -0.02500000037252903,\n", "                                                -0.03700000047683716,\n", "                                                -0.05000000074505806,\n", "                                                -0.06400000303983688,\n", "                                                -0.07400000095367432,\n", "                                                -0.07800000160932541,\n", "                                                -0.05400000140070915,\n", "                                                -0.03400000184774399,\n", "                                                -0.009000000543892384,\n", "                                                0.014000000432133675,\n", "                                                0.03400000184774399,\n", "                                                0.04700000211596489,\n", "                                                0.052000001072883606,\n", "                                                0.04700000211596489,\n", "                                                0.03400000184774399,\n", "                                                0.01900000125169754,\n", "                                                0.005000000353902578,\n", "                                                -0.00800000037997961,\n", "                                                -0.01600000075995922,\n", "                                                -0.01600000075995922,\n", "                                                -0.007000000216066837,\n", "                                                0.007000000216066837,\n", "                                                0.020000001415610313,\n", "                                                0.026000000536441803,\n", "                                                0.023000001907348633,\n", "                                                0.017000000923871994,\n", "                                                0.005000000353902578,\n", "                                                -0.00800000037997961,\n", "                                                -0.01900000125169754,\n", "                                                -0.01900000125169754,\n", "                                                -0.007000000216066837,\n", "                                                0.01100000087171793,\n", "                                                0.03200000151991844,\n", "                                                0.05000000074505806,\n", "                                                0.06200000271201134,\n", "                                                0.06400000303983688,\n", "                                                0.0560000017285347,\n", "                                                0.04000000283122063,\n", "                                                0.015000000596046448,\n", "                                                -0.010000000707805157,\n", "                                                -0.027000000700354576,\n", "                                                -0.03400000184774399,\n", "                                                -0.03700000047683716,\n", "                                                -0.03100000135600567,\n", "                                                -0.013000000268220901,\n", "                                                0.01100000087171793,\n", "                                                0.03700000047683716,\n", "                                                0.0560000017285347,\n", "                                                0.0690000057220459,\n", "                                                0.07000000029802322,\n", "                                                0.06000000238418579,\n", "                                                0.04100000113248825,\n", "                                                0.024000000208616257,\n", "                                                0.01600000075995922,\n", "                                                0.015000000596046448,\n", "                                                0.017000000923871994,\n", "                                                0.023000001907348633,\n", "                                                0.029000001028180122,\n", "                                                0.029000001028180122,\n", "                                                0.027000000700354576,\n", "                                                0.018000001087784767,\n", "                                                0.007000000216066837,\n", "                                                -0.014000000432133675,\n", "                                                -0.0430000014603138,\n", "                                                -0.07100000232458115,\n", "                                                -0.09400000423192978,\n", "                                                -0.09800000488758087,\n", "                                                -0.09800000488758087,\n", "                                                -0.08700000494718552,\n", "                                                -0.06700000166893005,\n", "                                                -0.039000000804662704,\n", "                                                -0.011..."]}, "execution_count": 30, "metadata": {}, "output_type": "execute_result"}], "source": ["evalMetricsResult.result"]}, {"cell_type": "code", "execution_count": null, "metadata": {"ExecuteTime": {"end_time": "2021-11-04T00:19:50.644391Z", "start_time": "2021-11-04T00:19:50.512385Z"}}, "outputs": [], "source": ["# # Step 2 Alternative: Query without Metadata\n", "\n", "# # Query without Metadata using the metric defined in the seed directory\n", "# evalMetricsResult_wo_Meta = c3.HycomLatLongPair.evalMetrics(spec=c3.EvalMetricsSpec(\n", "#             ids = ids_list,\n", "#             expressions = [\"TestAverageWaterU\"], # does this refer to the one above?\n", "#             start = \"2021-09-23T23:00:00\",\n", "#             end = \"2021-09-24T00:00:00\",\n", "#             interval = \"HOUR\", \n", "#         ))"]}, {"cell_type": "code", "execution_count": null, "metadata": {"ExecuteTime": {"end_time": "2021-10-26T05:57:14.959523Z", "start_time": "2021-10-26T05:57:14.956286Z"}, "code_folding": []}, "outputs": [], "source": ["# # inspect the results\n", "# evalMetricsResult.result"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# Step 3: sort into a (lat, lon, time) array"]}, {"cell_type": "code", "execution_count": null, "metadata": {"ExecuteTime": {"end_time": "2021-10-26T05:56:33.669335Z", "start_time": "2021-10-26T05:56:33.650103Z"}}, "outputs": [], "source": ["# Step 3: Sort the results back into a (lat,lon,time) array for use in the simulator\n", "# create a sorted list out of the data in order to get the matrix shape back\n", "data_list = []\n", "for single_id in ids_list:\n", "    data_list.append(evalMetricsResult.result[single_id][\"AverageWaterU\"].m_data)\n", "\n", "# reshape into (T, lat, lon)\n", "data_array = np.array(data_list)\n", "data_array = data_array.reshape(-1, len(lat_grid), len(lon_grid))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# As full function"]}, {"cell_type": "code", "execution_count": null, "metadata": {"ExecuteTime": {"end_time": "2021-10-26T06:18:07.227873Z", "start_time": "2021-10-26T06:18:00.749908Z"}}, "outputs": [], "source": ["# def getDataSubset_dictionary(lon_min, lon_max, lat_min, lat_max, metric, start, end, batchSize=100):\n", "# we can run filter with i,j => might be faster because integer comparisons faster than float\n", "lat_lon_filter = \"lon>\"+str(lon_min)+\" && lon<\"+str(lon_max)+\" && lat>\"+str(lat_min)+\" && lat<\"+str(lat_max)\n", "\n", "# get the lat-lon grid\n", "objs_list = c3.HycomLatLongPair.fetch(\n", "    spec={\"include\": \"id, lat, lon\", \"filter\": lat_lon_filter, \"order\": \"j,i\"}).objs\n", "\n", "ids_list = [obj.id for obj in objs_list]\n", "lat_list = [obj.lat for obj in objs_list]\n", "lon_list = [obj.lon for obj in objs_list]\n", "# create the x, y grids\n", "lat_grid = np.unique(np.array(lat_list))\n", "lon_grid = np.unique(np.array(lon_list))\n", "\n", "my_spec = c3.EvalMetricsSpec(\n", "#             filter = lat_lon_filter,\n", "        ids = ids_list,\n", "        limit = -1,\n", "        expressions = [metric],\n", "        start = start.strftime(\"%Y-%m-%dT%H:%M:%S\"),\n", "        end = end.strftime(\"%Y-%m-%dT%H:%M:%S\"),\n", "        interval = \"HOUR\"\n", "    )\n", "\n", "\n", "# Query the metric on DB\n", "evalMetricsResult = c3.HycomLatLongPair.evalMetrics(spec=my_spec)\n", "\n", "# \n", "data_list = []\n", "for single_id in ids_list:\n", "    data_list.append(evalMetricsResult.result[single_id][metric].m_data)\n", "\n", "# reshape into (T, lat, lon)\n", "data_array = np.array(data_list)\n", "data_array = data_array.reshape(-1, len(lat_grid), len(lon_grid))\n", "\n", "#     return data_array, lat_grid, lon_grid"]}, {"cell_type": "code", "execution_count": null, "metadata": {"ExecuteTime": {"end_time": "2021-10-26T06:18:09.355229Z", "start_time": "2021-10-26T06:18:09.336194Z"}}, "outputs": [], "source": ["data_list"]}, {"cell_type": "code", "execution_count": null, "metadata": {"ExecuteTime": {"end_time": "2021-10-26T06:14:21.375070Z", "start_time": "2021-10-26T06:14:21.371178Z"}}, "outputs": [], "source": ["from datetime import datetime\n", "start = datetime(2021,9,23,23)\n", "end = datetime(2021,9,24,0)"]}, {"cell_type": "code", "execution_count": null, "metadata": {"ExecuteTime": {"end_time": "2021-10-26T06:16:37.960672Z", "start_time": "2021-10-26T06:16:37.957305Z"}}, "outputs": [], "source": ["lon_min=-98\n", "lon_max=-97\n", "lat_min=18\n", "lat_max=19\n", "metric=\"TestAverageWaterU\""]}, {"cell_type": "code", "execution_count": null, "metadata": {"ExecuteTime": {"end_time": "2021-10-26T06:15:07.933127Z", "start_time": "2021-10-26T06:15:00.411657Z"}}, "outputs": [], "source": ["# 18 && lat < 19 && lon > -98 && lon < -97\n", "data_array, lat_grid, lon_grid = getDataSubset_dictionary(lon_min=-98, lon_max=-97, lat_min=18, lat_max=19,\n", "                         metric=\"TestAverageWaterU\",\n", "                         start=start,\n", "                         end=end)"]}, {"cell_type": "code", "execution_count": null, "metadata": {"ExecuteTime": {"end_time": "2021-10-26T06:14:30.469305Z", "start_time": "2021-10-26T06:14:29.791Z"}}, "outputs": [], "source": ["data_array.shape"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# Full Function 2: full loading function from Darren"]}, {"cell_type": "code", "execution_count": 13, "metadata": {"ExecuteTime": {"end_time": "2021-11-13T19:36:25.333804Z", "start_time": "2021-11-13T19:36:25.323660Z"}}, "outputs": [], "source": ["def getDataSubset(imin,jmin,imax,jmax,metric,start,end,batchSize=1):\n", "    \"\"\"Returns a subset for the given metric data from the given start and end time.\n", " \n", "    Args:\n", "        imin (int): Minimum longitude from lat-long pair indices\n", "        jmin (int): Minimum latitude from lat-long pair indices\n", "        imax (int): Maximum longitude from lat-long pair indices\n", "        jmax (int): Maximum latitude from lat-long pair indices\n", "        metric (str): Metric to be extracted from the dataset\n", "        start (datetime): Start time of the subset\n", "        end (datetime): End time of the subset\n", "        batchSize (int): Number of lat-long pairs to be extracted in each batch\n", " \n", "    Returns:\n", "        array: Numpy array of the subsetted data ordered as [time,lat,lon]\n", " \n", "    Notes:\n", "        - Currently limited to hour resolution\n", "        - Only handles a single metric\n", "        - The data indexing is not efficient since the indices must be parsed from the\n", "        lat-long pair ids.  If the HycomLatLong pair table was ordered by i,j, then\n", "        the pairs would get extracted in i,j order and there would be no need to parse.\n", "        this could be done by defining a new id that is a simple ascending integer.\n", " \n", "    \"\"\"\n", "   # we can run filter with i,j => might be faster because integer comparisons faster than float\n", "    my_spec = c3.EvalMetricsSpec(\n", "            filter = \"i>=\"+str(imin)+\" && i<=\"+str(imax)+\" && j>=\"+str(jmin)+\" && j<=\"+str(jmax),\n", "            limit = 10,\n", "            expressions = [metric],\n", "            start = start.strftime(\"%Y-%m-%d\"),\n", "            end = end.strftime(\"%Y-%m-%d\"),\n", "            interval = \"HOUR\"\n", "        )\n", "    # Evaluate the Spec using EvalSourceSpec which returns a stream of numpy arrays\n", "    sourceType = c3.TypeRef(typeName=\"HycomLatLongPair\")\n", "    # creates dumped np.array files\n", "    em_source_spec = c3.EvalMetricsSourceSpec.createNdArraySourceSpec(my_spec, sourceType)\n", "    #em_source_spec.batchExport()\n", "    stream_spec = c3.BatchStreamSpec(batchSize=batchSize)\n", "    source_stream = em_source_spec.toStream(stream_spec)\n", "    # we can get u and v together, multi-metrics.\n", "   \n", "    # Process the data in to a (time,long,lat) data array\n", "    duration = end - start\n", "    duration_in_s = duration.total_seconds()\n", "    nt = int(divmod(duration_in_s, 3600)[0]) # total duration in hours\n", "    data = np.zeros((nt,imax-imin+1,jmax-jmin+1))\n", "\n", "    \n", "    print(\"begin streaming\")\n", "    while source_stream.hasNext(): \n", "        print(\"begin streaming 2\")\n", "        stream = source_stream.next()\n", "        print(type(stream))\n", "        idi = -1\n", "        # Transpose time series\n", "        for id in stream.indices[0]:\n", "            idi += 1\n", "            istr,jstr = id.split('_')[1].split('-')\n", "            i = int(istr) - imin\n", "            j = int(jstr) - jmin\n", "            ti = 0\n", "            for t in stream.indices[2]:\n", "                data[ti,i,j] = stream.data[idi,0,ti]\n", "                ti += 1\n", "   \n", "    # Cleans up any persisted files storing snapshot of data source\n", "    em_source_spec.cleanUp()\n", "    # Removes spec from database\n", "    em_source_spec.remove()\n", "    return data"]}, {"cell_type": "code", "execution_count": 14, "metadata": {"ExecuteTime": {"end_time": "2021-11-13T19:48:03.325452Z", "start_time": "2021-11-13T19:36:26.282668Z"}}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["begin streaming\n"]}, {"ename": "KeyboardInterrupt", "evalue": "", "output_type": "error", "traceback": ["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m", "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)", "\u001b[0;32m<ipython-input-14-924098ba0572>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mmetric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"TestAverageWaterU\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2021\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2021\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m )\n\u001b[1;32m     12\u001b[0m \u001b[0mudata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;32m<ipython-input-13-9833d53b6db5>\u001b[0m in \u001b[0;36mgetDataSubset\u001b[0;34m(imin, jmin, imax, jmax, metric, start, end, batchSize)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"begin streaming\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     \u001b[0;32mwhile\u001b[0m \u001b[0msource_stream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhasNext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"begin streaming 2\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mstream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msource_stream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;32mZ10ac078826d8534179d455db1588a325M_/TypeSystemBase.py\u001b[0m in \u001b[0;36mhasNext\u001b[0;34m(this)\u001b[0m\n", "\u001b[0;32mZ10ac078826d8534179d455db1588a325M_/TypeSystemBase.py\u001b[0m in \u001b[0;36m_c3_member_inline_impl\u001b[0;34m(___args, source_code, py_code, method_name, this_name)\u001b[0m\n", "\u001b[0;32mZ10ac078826d8534179d455db1588a325M_/TypeSystemBase.py\u001b[0m in \u001b[0;36minline_traceback_impl\u001b[0;34m(source_code, fn, ___args, cls)\u001b[0m\n", "\u001b[0;32m<string>\u001b[0m in \u001b[0;36mhasNext\u001b[0;34m(this)\u001b[0m\n", "\u001b[0;32m<string>\u001b[0m in \u001b[0;36m_call_fstream_func\u001b[0;34m(stream, func_name)\u001b[0m\n", "\u001b[0;32m<string>\u001b[0m in \u001b[0;36m_do_export\u001b[0;34m(stream)\u001b[0m\n", "\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}], "source": ["from datetime import datetime \n", "import numpy as np\n", "udata = getDataSubset(\n", "    imin = 81,\n", "    jmin = 81,\n", "    imax = 90,\n", "    jmax = 90,\n", "    metric = \"TestAverageWaterU\",\n", "    start = datetime(2021,10,1),\n", "    end = datetime(2021,10,8)\n", ")\n", "udata.shape"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# Full Process (created by Conor)\n"]}, {"cell_type": "code", "execution_count": 1, "metadata": {"ExecuteTime": {"end_time": "2021-11-13T19:23:10.668747Z", "start_time": "2021-11-13T19:23:10.665755Z"}}, "outputs": [], "source": ["import numpy as np\n", "from datetime import datetime\n", "import time"]}, {"cell_type": "code", "execution_count": 15, "metadata": {"ExecuteTime": {"end_time": "2021-11-13T19:48:11.750720Z", "start_time": "2021-11-13T19:48:11.739280Z"}}, "outputs": [], "source": ["def getDataSubset(t_interval, lat_interval, lon_interval, metric=\"TestAverageWaterU\", interval=\"HOUR\"):\n", "    \"\"\"\n", "    Returns a subset for the given metric data from the given start and end time. \n", "    This version does not using Streaming and so may be slower (?)\n", " \n", "    Args:\n", "        t_interval (float): [t_0, t_T] in POSIX time where t_0 and t_T are the start and end timestamps respectively\n", "        lat_interval (float tuple): [y_lower, y_upper] in degrees\n", "        lon_interval (float tuple): [x_lower, x_upper] in degrees\n", "        \n", "        metric (str): Metric to be extracted from the dataset   \n", "        interval (string): frequency of datapoints to output (only works for \"HOUR\" right now!)\n", " \n", "    Returns:\n", "        array: Numpy array of the subsetted data ordered as [time,lat,lon]\n", " \n", "    Notes:\n", "        - Currently designed/tested for hour resolution\n", "        - Only tested for single metric\n", "        - Comments included with times for different sections of the function. These times are not averaged \n", "          (only one run used) and are there to present an idea of the runtime of different sections of the code.\n", "          NOTE: significnat time variance when fetching from c3\n", "    \"\"\"\n", "    pre_query_start = time.time()\n", "    ###PRE-QUERY SECTION###\n", "    #takes 0.1423 seconds for 1x1 lat-lon, 1 day\n", "    #convert times to datetime\n", "    start_time = datetime.fromtimestamp(t_interval[0])\n", "    end_time = datetime.fromtimestamp(t_interval[1])\n", "\n", "    #filter for query\n", "    filter = \"lat>={} && lat<={} && lon>={} && lon<={}\".format(lat_interval[0], lat_interval[1], \n", "                                                               lon_interval[0], lon_interval[1])\n", "\n", "    #get lat, lon dimensions\n", "    objs_list = c3.HycomLatLongPair.fetch(spec={\"include\": \"id, lat, lon\", \"filter\": filter, \"limit\": -1}).objs\n", "    lat_dim =  len(np.unique([obj.lat for obj in objs_list]))\n", "    lon_dim = len(np.unique([obj.lon for obj in objs_list]))\n", "    \n", "    print(\"pre_query_time: \", time.time() - pre_query_start)\n", "    \n", "    query_start = time.time()\n", "\n", "    ###QUERY SECTION###\n", "    #takes 17.17 seconds for 1x1 lat-lon, 1 day\n", "    # Query the server for EvalMetrics data\n", "    my_spec = c3.EvalMetricsSpec(\n", "                filter = filter,\n", "                limit = -1,\n", "                expressions = [metric],\n", "                start = start_time.strftime(\"%Y-%m-%d\"),\n", "                end = end_time.strftime(\"%Y-%m-%d\"),\n", "                interval = interval\n", "            )\n", "\n", "    evalMetricsResult = c3.HycomLatLongPair.evalMetrics(spec=my_spec)\n", "    \n", "    print(\"query_time: \", time.time() - query_start)\n", "    \n", "    post_query_start = time.time()\n", "    \n", "    ###POST_QUERY SECTION###\n", "    #takes 0.02296 seconds for 1x1 lat-lon, 1 day\n", "    \n", "    #calculate number of discrete time points \n", "    #(currently calculates number of hours, need to modify to work for different intervals)\n", "    duration = end_time - start_time\n", "    duration_in_s = duration.total_seconds()\n", "    num_times = int(divmod(duration_in_s, 3600)[0])\n", "\n", "    #extract data into array\n", "    keys = sorted([key for key in evalMetricsResult.result])\n", "    arr = np.zeros(shape=(num_times,len(keys)))\n", "    for i in range(len(keys)):\n", "        arr[:, i] = np.array(evalMetricsResult.result[keys[i]][\"TestAverageWaterU\"].m_data)\n", "\n", "    arr = np.swapaxes(arr.reshape(num_times, lon_dim, lat_dim), 1, 2)\n", "    \n", "    print(\"post_query_time: \", time.time() - post_query_start)\n", "    \n", "    return arr"]}, {"cell_type": "code", "execution_count": null, "metadata": {"ExecuteTime": {"start_time": "2021-11-13T20:05:41.692Z"}}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["pre_query_time:  1.6925451755523682\n"]}], "source": ["data = getDataSubset(t_interval=(datetime(2021,9,2,12).timestamp(), datetime(2021,9,3,12).timestamp()), \n", "                     lat_interval=(23, 27),\n", "                     lon_interval=(-91, -87))"]}, {"cell_type": "code", "execution_count": 2, "metadata": {"ExecuteTime": {"end_time": "2021-11-09T22:44:14.993979Z", "start_time": "2021-11-09T22:44:14.982255Z"}}, "outputs": [], "source": ["def getDataSubset_latlong(t_interval, lat_interval, lon_interval, \n", "                          metric=\"TestAverageWaterU\", batchSize=100, interval=\"HOUR\"):\n", "    \"\"\"Returns a subset for the given metric data from the given start and end time. \n", "    Conor alterted Darren's function to use lat-long pairs as input + other changes\n", "    \n", "    TODO: get same arguments as get_current_data_subset_from_c3 (in Data_subsetting_example.ipynb)\n", "    \n", "    and for now HOUR time interval\n", " \n", "    Args:\n", "        t_interval (float): [t_0, t_T] in POSIX time where t_0 and t_T are the start and end timestamps respectively\n", "        lat_interval (float tuple): [y_lower, y_upper] in degrees\n", "        lon_interval (float tuple): [x_lower, x_upper] in degrees\n", "        \n", "        metric (str): Metric to be extracted from the dataset   \n", "        batchSize (int): Number of lat-long pairs to be extracted in each batch\n", "        interval (string): frequency of datapoints to output (only works for \"HOUR\" right now!)\n", " \n", "    Returns:\n", "        array: Numpy array of the subsetted data ordered as [time,lat,lon]\n", " \n", "    Notes:\n", "        - Currently limited to hour resolution\n", "        - Only handles a single metric\n", "        - The data indexing is not efficient since the indices must be parsed from the\n", "        lat-long pair ids.  If the HycomLatLong pair table was ordered by i,j, then\n", "        the pairs would get extracted in i,j order and there would be no need to parse.\n", "        this could be done by defining a new id that is a simple ascending integer.\n", " \n", "    \"\"\"\n", "    start_time = datetime.fromtimestamp(t_interval[0])\n", "    end_time = datetime.fromtimestamp(t_interval[1])\n", "   # we can run filter with i,j => might be faster because integer comparisons faster than float\n", "    my_spec = c3.EvalMetricsSpec(\n", "            filter = \"lat>={} && lat<={} && lon>={} && lon<={}\".format(lat_interval[0], lat_interval[1], \n", "                                                                       lon_interval[0], lon_interval[1]),\n", "            limit = 10,\n", "            expressions = [metric],\n", "            start = start_time.strftime(\"%Y-%m-%d\"),\n", "            end = end_time.strftime(\"%Y-%m-%d\"),\n", "            interval = interval\n", "        )\n", "    # Evaluate the Spec using EvalSourceSpec which returns a stream of numpy arrays\n", "    sourceType = c3.TypeRef(typeName=\"HycomLatLongPair\")\n", "    # creates dumped np.array files\n", "    em_source_spec = c3.EvalMetricsSourceSpec.createNdArraySourceSpec(my_spec, sourceType)\n", "#     em_source_spec.batchExport()\n", "    stream_spec = c3.BatchStreamSpec(batchSize=batchSize)\n", "    source_stream = em_source_spec.toStream(stream_spec)\n", "    # we can get u and v together, multi-metrics.\n", "   \n", "    # Process the data in to a (time,long,lat) data array\n", "    duration = end_time - start_time\n", "    duration_in_s = duration.total_seconds()\n", "    nt = int(divmod(duration_in_s, 3600)[0]) # total duration in hours\n", "    \n", "#     data = np.zeros((nt,imax-imin+1,jmax-jmin+1))\n", "    \n", "    \n", "    # How can we get the results back in order to easy reshape them?\n", "    # -> Darren tries it out.\n", "    #TODO: see how to stream to make sure it's in order (final array shape should be (time, y, x) or (time, lat, lon))\n", "    while source_stream.hasNext(): \n", "        stream = source_stream.next()\n", "        idi = -1\n", "        \n", "        # Transpose time series\n", "        for id in stream.indices[0]:\n", "#             idi += 1\n", "#             istr,jstr = id.split('_')[1].split('-')\n", "#             i = int(istr) - imin\n", "#             j = int(jstr) - jmin\n", "#             ti = 0\n", "            for t in stream.indices[2]:\n", "#                 data[ti,i,j] = stream.data[idi,0,ti]\n", "#                 ti += 1\n", "                print(stream.data)\n", "    \n", "    source_stream.close()\n", "   \n", "    # Cleans up any persisted files storing snapshot of data source\n", "    em_source_spec.cleanUp()\n", "    # Removes spec from database\n", "    em_source_spec.remove()\n", "    return data"]}, {"cell_type": "code", "execution_count": null, "metadata": {"ExecuteTime": {"start_time": "2021-11-09T22:44:22.166Z"}}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["created spec\n", "created stream\n", "starting stream\n", "c3.EvalMetricsNdArrayStream(\n", " streamSpec=c3.BatchStreamSpec(batchSize=100, fileFetchTotalMemoryMb=512),\n", " dataSourceSpec=c3.EvalMetricsNdArraySourceSpec(\n", "                  start=datetime.datetime(2021, 9, 2, 0, 0),\n", "                  end=datetime.datetime(2021, 9, 3, 0, 0),\n", "                  timeZone='NONE',\n", "                  interval='HOUR',\n", "                  cache=False,\n", "                  filter='lat>=24 && lat<=25 && lon>=-90 && lon<=-89',\n", "                  limit=-1,\n", "                  expressions={'TestAverageWaterU'},\n", "                  continueOnError=False,\n", "                  id='f357230e-03bf-4411-abb3-0c8a96237861',\n", "                  meta=c3.Meta(\n", "                         tenantTagId=150,\n", "                         tenant='dev',\n", "                         tag='tc01d',\n", "                         created=datetime.datetime(2021, 11, 9, 22, 44, 22, tzinfo=datetime.timezone.utc),\n", "                         createdBy='con-mart@berkeley.edu',\n", "                         updated=datetime.datetime(2021, 11, 9, 22, 44, 22, tzinfo=datetime.timezone.utc),\n", "                         updatedBy='con-mart@berkeley.edu',\n", "                         timestamp=datetime.datetime(2021, 11, 9, 22, 44, 22, tzinfo=datetime.timezone.utc),\n", "                         fetchInclude='[]',\n", "                         fetchType='EvalMetricsNdArraySourceSpec'),\n", "                  version=2,\n", "                  typeIdent='BESS:EMASS:EMNDASS',\n", "                  sourceType=c3.TypeRef(typeName='HycomLatLongPair'),\n", "                  exportJob=c3.Export(\n", "                              id='export-3d326692345afedf9e98075dfe76c1738df088b4')))\n"]}], "source": ["t_interval=(datetime(2021,9,2).timestamp(), datetime(2021,9,3).timestamp())\n", "lat_interval=(24, 25)\n", "lon_interval=(-90, -89) \n", "metric=\"TestAverageWaterU\"\n", "batchSize=100\n", "interval=\"HOUR\"\n", "\n", "start_time = datetime.fromtimestamp(t_interval[0])\n", "end_time = datetime.fromtimestamp(t_interval[1])\n", "# we can run filter with i,j => might be faster because integer comparisons faster than float\n", "my_spec = c3.EvalMetricsSpec(\n", "        filter = \"lat>={} && lat<={} && lon>={} && lon<={}\".format(lat_interval[0], lat_interval[1], \n", "                                                                   lon_interval[0], lon_interval[1]),\n", "        limit = -1,\n", "        expressions = [metric],\n", "        start = start_time.strftime(\"%Y-%m-%d\"),\n", "        end = end_time.strftime(\"%Y-%m-%d\"),\n", "        interval = interval\n", "    )\n", "print(\"created spec\")\n", "# Evaluate the Spec using EvalSourceSpec which returns a stream of numpy arrays\n", "sourceType = c3.TypeRef(typeName=\"HycomLatLongPair\")\n", "# creates dumped np.array files\n", "em_source_spec = c3.EvalMetricsSourceSpec.createNdArraySourceSpec(my_spec, sourceType)\n", "# em_source_spec.batchExport()\n", "stream_spec = c3.BatchStreamSpec(batchSize=batchSize)\n", "source_stream = em_source_spec.toStream(stream_spec)\n", "\n", "print(\"created stream\")\n", "# we can get u and v together, multi-metrics.\n", "\n", "# Process the data in to a (time,long,lat) data array\n", "duration = end_time - start_time\n", "duration_in_s = duration.total_seconds()\n", "nt = int(divmod(duration_in_s, 3600)[0]) # total duration in hours\n", "\n", "# data = np.zeros((nt,imax-imin+1,jmax-jmin+1))\n", "\n", "\n", "# How can we get the results back in order to easy reshape them?\n", "# -> Darren tries it out.\n", "#TODO: see how to stream to make sure it's in order (final array shape should be (time, y, x) or (time, lat, lon))\n", "print(\"starting stream\")\n", "print(source_stream)\n", "print(source_stream.next())\n", "count = 0\n", "while source_stream.hasNext() and count <= 10: \n", "    stream = source_stream.next()\n", "    print(stream)\n", "    idi = -1\n", "\n", "    # Transpose time series\n", "    for id in stream.indices[0]:\n", "#             idi += 1\n", "#             istr,jstr = id.split('_')[1].split('-')\n", "#             i = int(istr) - imin\n", "#             j = int(jstr) - jmin\n", "#             ti = 0\n", "        for t in stream.indices[2]:\n", "#                 data[ti,i,j] = stream.data[idi,0,ti]\n", "#                 ti += 1\n", "            print(stream.data)\n", "    count += 1\n", "\n", "# Cleans up any persisted files storing snapshot of data source\n", "em_source_spec.cleanUp()\n", "# Removes spec from database\n", "em_source_spec.remove()\n", "u_data = data"]}, {"cell_type": "code", "execution_count": null, "metadata": {"ExecuteTime": {"start_time": "2021-11-09T22:26:58.838Z"}}, "outputs": [], "source": ["udata = getDataSubset_latlong(\n", "    t_interval=(datetime(2021,9,2).timestamp(), datetime(2021,9,3).timestamp()),\n", "    lat_interval=(24, 25),\n", "    lon_interval=(-90, -89)   \n", ")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Do a number of comparisons (i.e. small medium large lat-lon size, interpolation or not)\n", "#iff i, j leads to efficiency improvement -> figure out how to convert lat-long to i,j?"]}], "metadata": {"has_local_update": false, "is_local": true, "is_remote": true, "kernelspec": {"display_name": "py-hycom_1_0_0", "language": "Python", "name": "py-hycom_1_0_0"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.13"}, "last_sync_time": "2021-11-13T19:06:39.051588"}, "nbformat": 4, "nbformat_minor": 4}