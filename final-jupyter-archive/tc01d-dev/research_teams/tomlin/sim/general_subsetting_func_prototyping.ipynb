{"cells": [{"cell_type": "code", "execution_count": 1, "metadata": {"ExecuteTime": {"end_time": "2021-11-21T01:46:56.220698Z", "start_time": "2021-11-21T01:46:55.507464Z"}}, "outputs": [], "source": ["from datetime import datetime, timedelta\n", "import matplotlib.pyplot as plt\n", "import netCDF4\n", "import abc\n", "import casadi as ca\n", "from datetime import datetime, timedelta\n", "import netCDF4\n", "import numpy as np\n", "import bisect\n", "import math"]}, {"cell_type": "code", "execution_count": 2, "metadata": {"ExecuteTime": {"end_time": "2021-11-21T01:46:56.225126Z", "start_time": "2021-11-21T01:46:56.222364Z"}}, "outputs": [], "source": ["# Goal: have a data_subset_function that is general across C3 and local files using some flags."]}, {"cell_type": "code", "execution_count": 3, "metadata": {"ExecuteTime": {"end_time": "2021-11-21T01:46:56.277090Z", "start_time": "2021-11-21T01:46:56.227281Z"}}, "outputs": [], "source": ["# Open Questions/Observations:\n", "# TO CHANGE in rest of the CODE\n", "# - t_grid in the dict should also be an array (for consistency reasons)\n", "\n", "# Questions for C3 Team:\n", "# - how to prevent re-loading of files that are still in temp? Can we re-use them? Would speed up a lot I think!\n", "# Because we'll subset multiple times on the same files..."]}, {"cell_type": "code", "execution_count": 4, "metadata": {"ExecuteTime": {"end_time": "2021-11-21T01:46:56.329232Z", "start_time": "2021-11-21T01:46:56.279830Z"}}, "outputs": [], "source": ["# Testing the function\n", "# Base settings\n", "lat_interval = [24, 25]\n", "lon_interval = [-90,-89]"]}, {"cell_type": "code", "execution_count": 18, "metadata": {"ExecuteTime": {"end_time": "2021-11-20T22:53:39.824429Z", "start_time": "2021-11-20T22:53:34.210546Z"}, "code_folding": [0]}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Subsetted data from 2021-11-11 14:00:00 UTC to 2021-11-17 00:00:00 UTC in 131 time steps\n"]}], "source": ["# Test C3 file approach\n", "# t_interval = [datetime(2021, 9, 2, 12, 0).timestamp(), datetime(2021, 9, 3, 12, 0).timestamp()]\n", "# t_interval = [datetime(2021, 9, 2, 12, 0).timestamp(), None]\n", "t_interval = [datetime(2021, 11, 11, 14, 0).timestamp(), None]\n", "# t_interval = [datetime(2021, 11, 11, 14, 0).timestamp(), datetime(2021, 11, 15, 14, 0).timestamp()]\n", "# Flags\n", "data_type = 'F' # can be 'F' or 'H'\n", "access = 'C3' # can be 'local' or 'C3'\n", "# file = None\n", "file = 'hycom-test/fmrc/GOMu0.04_901m000_FMRC_RUN_2021-11-11T12:00:00Z-2021-11-11T12:00:00Z-2021-11-17T00:00:00Z.nc/GOMu0.04_901m000_FMRC_RUN_2021-11-11T12:00:00Z-2021-11-11T12:00:00Z-2021-11-17T00:00:00Z.nc'\n", "\n", "grid_dict, u_data, v_data = get_current_data_subset(\n", "    t_interval, lat_interval, lon_interval,\n", "    data_type, access, file)"]}, {"cell_type": "code", "execution_count": null, "metadata": {"code_folding": []}, "outputs": [], "source": ["# Test local file approach\n", "t_interval = [datetime(2021, 6, 2, 12, 0).timestamp(), None]\n", "t_interval = [datetime(2021, 6, 2, 12, 0).timestamp(), datetime(2021, 6, 3, 12, 0).timestamp()]\n", "# Flags\n", "data_type = 'H' # can be 'F' or 'H'\n", "access = 'local' # can be 'local' or 'C3'\n", "# file = './data/forecast_folder/GOMu0.04_901m000_FMRC_RUN_2021-06-02T12_00_00Z.nc4'\n", "file = './data/2021_06_1-05_hourly.nc4'\n", "\n", "grid_dict, u_data, v_data = get_current_data_subset(\n", "    t_interval, lat_interval, lon_interval,\n", "    data_type, access, file)"]}, {"cell_type": "code", "execution_count": 88, "metadata": {"ExecuteTime": {"end_time": "2021-11-21T02:15:22.745963Z", "start_time": "2021-11-21T02:15:22.735695Z"}, "code_folding": [1]}, "outputs": [], "source": ["# define overarching function\n", "def get_current_data_subset(t_interval, lat_interval, lon_interval,\n", "                        data_type, access,\n", "                        file = None, C3_hindcast_max_temp_in_h = 120):\n", "    \"\"\" Function to get a subset of current data either via local file or via C3 database of files.\n", "    Inputs:\n", "        t_interval              if time-varying: [t_0, t_T] in POSIX time\n", "                                where t_0 and t_T are the start and end timestamps respectively\n", "                                if t_T is None and we use a file, the full available time is returned.\n", "        lat_interval            [y_lower, y_upper] in degrees\n", "        lon_interval            [x_lower, x_upper] in degrees\n", "\n", "        data_type               string either 'F' or 'H'. Specifies if Forecast for Hindcast data is requested.\n", "        access                  string either 'local' or 'C3'. Specifies if a local file or C3 database is used.\n", "        file                    string of the path to the file (required for all local and C3 Forecasts but not H)\n", "\n", "    Outputs:\n", "        grids_dict              dict containing x_grid, y_grid, t_grid\n", "        u_data                  [T, Y, X] matrix of the ocean currents in x direction in m/s\n", "        v_data                  [T, Y, X] matrix of the ocean currents in y direction in m/s\n", "    \"\"\"\n", "    # Step 0: check if its C3 and Hindcasts, then we need extra function\n", "    if data_type == 'H' and access == 'C3':\n", "        if t_interval[1] is None:\n", "            t_interval[1] = t_interval[0] + C3_hindcast_max_temp_in_h * 3600\n", "        grids_dict, u_data, v_data = get_current_data_subset_from_c3_file(t_interval, lat_interval, lon_interval)\n", "        return grids_dict, u_data, v_data\n", "\n", "    # Step 1: open the file\n", "    # Check if C3 or not\n", "    if access == 'C3':\n", "        f = c3.HycomUtil.nc_open(file)\n", "    elif access == 'local':\n", "        f = netCDF4.Dataset(file)\n", "\n", "    # Step 2: Extract the grids\n", "    x_grid = f.variables['lon'][:].data\n", "    y_grid = f.variables['lat'][:].data\n", "    t_grid = get_abs_time_grid_for_hycom_file(f, data_type)\n", "\n", "    # Step 3: get the subsetting indices for space and time\n", "    ygrid_inds = np.where((y_grid >= lat_interval[0]) & (y_grid <= lat_interval[1]))[0]\n", "    ygrid_inds = add_element_front_and_back_if_possible(y_grid, ygrid_inds)\n", "    xgrid_inds = np.where((x_grid >= lon_interval[0]) & (x_grid <= lon_interval[1]))[0]\n", "    xgrid_inds = add_element_front_and_back_if_possible(x_grid, xgrid_inds)\n", "    if t_interval[1] is None: # take full file time contained in the file\n", "        tgrid_inds = np.where((t_grid >= t_interval[0]))[0]\n", "    else: # subset ending time\n", "        tgrid_inds = np.where((t_grid >= t_interval[0]) & (t_grid <= t_interval[1] + 3600))[0]\n", "    tgrid_inds = add_element_front_and_back_if_possible(t_grid, tgrid_inds)\n", "\n", "    # Step 3.1: create grid and use that as sanity check if any relevant data is contained in the file\n", "    try:\n", "        grids_dict = {'x_grid': x_grid[xgrid_inds], 'y_grid': y_grid[ygrid_inds],\n", "                      't_grid': t_grid[tgrid_inds]}\n", "    except:\n", "         raise ValueError(\"None of the requested data contained in file. Check File.\")\n", "\n", "    # Step 3.2: Advanced sanity check if only partial area is contained in file\n", "    grids_interval_sanity_check(grids_dict, lat_interval, lon_interval, t_interval)\n", "\n", "    # Step 4: extract data\n", "    # Note: HYCOM is [tdim, zdim, ydim, xdim]\n", "    if len(f.variables['water_u'].shape) == 4:  # if there is a depth dimension in the dataset\n", "        u_data = f.variables['water_u'][tgrid_inds, 0, ygrid_inds, xgrid_inds]\n", "        v_data = f.variables['water_v'][tgrid_inds, 0, ygrid_inds, xgrid_inds]\n", "    else:\n", "        raise ValueError(\"Current data in nc file does not have 4 dimensions. Check file.\")\n", "\n", "    print(\"Subsetted data from {start} to {end} in {n_steps} time steps\".format(\n", "        start=datetime.utcfromtimestamp(grids_dict['t_grid'][0]).strftime('%Y-%m-%d %H:%M:%S UTC'),\n", "        end=datetime.utcfromtimestamp(grids_dict['t_grid'][-1]).strftime('%Y-%m-%d %H:%M:%S UTC'),\n", "        n_steps=len(grids_dict['t_grid'])))\n", "\n", "    # TODO: we replace the masked array with fill value 0 because otherwise interpolation doesn't work.\n", "    # Though that means we cannot anymore detect if we're on land or not (need a way to do that/detect stranding)\n", "    return grids_dict, u_data.filled(fill_value=0.), v_data.filled(fill_value=0.)"]}, {"cell_type": "code", "execution_count": 39, "metadata": {"ExecuteTime": {"end_time": "2021-11-21T01:58:24.534981Z", "start_time": "2021-11-21T01:58:24.527559Z"}, "code_folding": [0, 18, 28]}, "outputs": [], "source": ["def get_abs_time_grid_for_hycom_file(f, data_type):\n", "    \"\"\"Helper function to extract the t_grid in POSIX time from a HYCOM File f.\"\"\"\n", "    # Get the t_grid. note that this is in hours from HYCOM data!\n", "    t_grid = f.variables['time'][:]\n", "    # Get the time_origin of the file (Note: this is very tailered for the HYCOM Data)\n", "    if data_type == 'H':\n", "        time_origin = datetime.strptime(f.variables['time'].__dict__['time_origin'] + ' +0000',\n", "                                            '%Y-%m-%d %H:%M:%S %z')\n", "    else:\n", "        time_origin = datetime.strptime(f.variables['time'].__dict__['units'] + ' +0000',\n", "                                                     'hours since %Y-%m-%d %H:%M:%S.000 UTC %z')\n", "\n", "    # for time indexing transform to POSIX time\n", "    abs_t_grid = [(time_origin + timedelta(hours=X)).timestamp() for X in t_grid.data]\n", "    return np.array(abs_t_grid)\n", "\n", "import warnings\n", "   \n", "def grids_interval_sanity_check(grids_dict, lat_interval, lon_interval, t_interval):\n", "    \"\"\"Advanced Check for warning of partially being out of bound in space or time.\"\"\"\n", "    if grids_dict['y_grid'][0] > lat_interval[0] or grids_dict['y_grid'][-1] < lat_interval[1]:\n", "        warnings.warn(\"Part of the lat requested area is outside of file.\", RuntimeWarning)\n", "    if grids_dict['x_grid'][0] > lon_interval[0] or grids_dict['x_grid'][-1] < lon_interval[1]:\n", "        warnings.warn(\"Part of the lon requested area is outside of file.\", RuntimeWarning)\n", "    if t_interval[1] is not None:\n", "        if grids_dict['t_grid'][0] > t_interval[0] or grids_dict['t_grid'][-1] < t_interval[1]:\n", "            warnings.warn(\"Part of the requested time is outside of file.\", RuntimeWarning)\n", "            \n", "def add_element_front_and_back_if_possible(grid, grid_inds):\n", "    \"\"\"Helper function to add the elements front and back of the indicies if possible.\"\"\"\n", "    # insert in the front if possible\n", "    grid_inds = np.insert(grid_inds, 0, max(0, grid_inds[0]-1), axis=0)\n", "    # insert in the end if possible\n", "    grid_inds = np.insert(grid_inds, len(grid_inds), min(len(grid), grid_inds[-1]+1), axis=0)\n", "    return grid_inds"]}, {"cell_type": "code", "execution_count": 7, "metadata": {"ExecuteTime": {"end_time": "2021-11-21T01:46:56.577670Z", "start_time": "2021-11-21T01:46:56.500234Z"}, "code_folding": [0]}, "outputs": [], "source": ["# Functions for using the Data from the C3 Cloud DB\n", "\n", "# C3 file based data-access function\n", "def get_current_data_subset_from_c3_file(\n", "        t_interval,  # temp_res_in_h,   ----> separate function\n", "        lat_interval,  # lat_res_in_deg,\n", "        lon_interval,  # lon_res_in_deg,\n", "        # depth_interval_to_avg_over\n", "):\n", "    \"\"\" Function to get a subset of current data via the C3 data integration.\n", "\n", "    Inputs:\n", "        t_interval              if time-varying: [t_0, t_T] in POSIX time\n", "                                where t_0 and t_T are the start and end timestamps respectively\n", "                                if fixed_time:   [fixed_timestamp] in POSIX\n", "        temp_res_in_h           which temporal resolution the time-axis should have\n", "                                e.g. if temp_res_in_h = 1, t_grid = [t_0, t_0 + 3600s, ... t_T]\n", "                                if temp_res_in_h = 5,      t_grid = [t_0, t_0 + 5*3600s, ... t_T]\n", "                                if temp_res_in_h = 0.5,      t_grid = [t_0, t_0 + 1800s, ... t_T]\n", "                                => so either averaging or interpolation needs to be done in the backend\n", "        lat_interval            [y_lower, y_upper] in degrees\n", "        lat_res_in_deg          which spatial resolution in y direction in degrees\n", "                                e.g. if lat_res_in_deg = 1, y_grid = [y_lower, y_lower + 1, ... y_upper]\n", "                                 => so either averaging or interpolation needs to be done in the backend\n", "        lon_interval            [x_lower, x_upper] in degrees\n", "        lon_res_in_deg          which spatial resolution in x direction in degrees\n", "                                e.g. if lon_res_in_deg = 1, x_grid = [x_lower, x_lower + 1, ... x_upper]\n", "                                 => so either averaging or interpolation needs to be done in the backend\n", "        depth_interval_to_avg_over\n", "                                Interval to average over the current dimension in meters\n", "                                e.g. [0, 10] then the currents are averaged over the depth 0-10m.\n", "\n", "    Outputs:\n", "        grids_dict              dict containing x_grid, y_grid, t_grid\n", "        u_data                  [T, Y, X] matrix of the ocean currents in x direction in m/s\n", "        v_data                  [T, Y, X] matrix of the ocean currents in y direction in m/s\n", "    \"\"\"\n", "\n", "    # Step 1: get required file references and data from C3 file DB\n", "    # Step 1.1: Getting time and formatting for the db query\n", "    start = datetime.utcfromtimestamp(t_interval[0])\n", "    end = datetime.utcfromtimestamp(t_interval[1])\n", "\n", "    # Step 1.2: Getting correct range of nc files from database\n", "    filter_string = 'start>=' + '\"' + start.strftime(\"%Y-%m-%d\") + '\"' + \\\n", "                    ' && end<=' + '\"' + end.strftime(\"%Y-%m-%d\") + \"T23:00:00.000\" + '\"' \\\n", "                                                                                     ' && status==' + '\"' + 'downloaded' + '\"'\n", "    objs_list = c3.HindcastFile.fetch({'filter': filter_string, \"order\": \"start\"}).objs\n", "\n", "    # some basic sanity checks\n", "    if objs_list is None:\n", "        raise ValueError(\"No files in the database for the selected t_interval\")\n", "    if len(objs_list) != (end - start).days + 1:\n", "        raise ValueError(\"DB Query didn't return the expected number of files (one per day), check DB and code.\")\n", "\n", "    # Step 1.3: extract url and start list from the query results\n", "    urls_list = [obj.file.url for obj in objs_list]\n", "    start_list = [obj.start for obj in objs_list]\n", "\n", "    # Step 2: Prepare the stacking loop by getting the x, y grids and subsetting indices in x, y\n", "    # Note: these stay constant across files in this case where all files have same lat-lon range\n", "\n", "    # Step 2.1: open the file and get the x and y grid\n", "    f = c3.HycomUtil.nc_open(urls_list[0])\n", "    xgrid = f.variables['lon'][:].data\n", "    ygrid = f.variables['lat'][:].data\n", "\n", "    # Step 2.2: get the respective indices of the lat, lon subset from the file grids\n", "    ygrid_inds = np.where((ygrid >= lat_interval[0]) & (ygrid <= lat_interval[1]))[0]\n", "    xgrid_inds = np.where((xgrid >= lon_interval[0]) & (xgrid <= lon_interval[1]))[0]\n", "\n", "    # Step 2.3 initialze t_grid stacking variable\n", "    full_t_grid = []\n", "\n", "    # Step 3: iterate over all files in order and stack the current data and absolute t_grids\n", "    for idx in range(len(start_list)):\n", "        # Step 3.0: load the current data file\n", "        f = c3.HycomUtil.nc_open(urls_list[idx])\n", "        # set the default start and end time\n", "        start_hr, end_hr = 0, 24\n", "\n", "        # Step 3.1: do the time-subsetting\n", "        # Case 1: file is first -- get data from the file from the hour before or at t_0\n", "        if idx == 0:\n", "            start_hr = math.floor((t_interval[0] - start_list[idx].timestamp()) / 3600)\n", "        # Case 2: file is last -- get data from file until or after the hour t_T\n", "        if idx == len(start_list) - 1:\n", "            end_hr = math.ceil((t_interval[1] - start_list[idx].timestamp()) / 3600) + 1\n", "\n", "        # Step 3.2: extract data from the file\n", "        u_data = f.variables['water_u'][start_hr:end_hr, 0, ygrid_inds, xgrid_inds]\n", "        v_data = f.variables['water_v'][start_hr:end_hr, 0, ygrid_inds, xgrid_inds]\n", "\n", "        # Step 3.3: stack the sub-setted abs_t_grid and current data\n", "        full_t_grid = full_t_grid + [start_list[idx].timestamp() + i * 3600 for i in range(start_hr, end_hr)]\n", "\n", "        if idx == 0:\n", "            full_u_data = u_data\n", "            full_v_data = v_data\n", "        else:\n", "            full_u_data = np.concatenate((full_u_data, u_data), axis=0)\n", "            full_v_data = np.concatenate((full_v_data, v_data), axis=0)\n", "\n", "    # Step 4: create dict to output\n", "    grids_dict = {'x_grid': xgrid[xgrid_inds], 'y_grid': ygrid[ygrid_inds], 't_grid': full_t_grid}\n", "\n", "    # Step 5: # log what data has been subsetted\n", "    print(\"Subsetted data from {start} to {end} in {n_steps} time steps of {time:.2f} hour(s) resolution\".format(\n", "        start=datetime.utcfromtimestamp(grids_dict['t_grid'][0]).strftime('%Y-%m-%d %H:%M:%S UTC'),\n", "        end=datetime.utcfromtimestamp(grids_dict['t_grid'][-1]).strftime('%Y-%m-%d %H:%M:%S UTC'),\n", "        n_steps=len(grids_dict['t_grid']), time=(grids_dict['t_grid'][1] - grids_dict['t_grid'][0]) / 3600.))\n", "\n", "    # Step 6: return the grids_dict and the stacked data\n", "    # TODO: currently, we just do fill_value =0 but then we can't detect if we're on land.\n", "    # We need a way to do that in the simulator, doing it via the currents could be one way.\n", "    return grids_dict, full_u_data.filled(fill_value=0.), full_v_data.filled(fill_value=0.)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}], "metadata": {"has_local_update": true, "is_local": true, "is_remote": true, "kernelspec": {"display_name": "py-ocean_sim_cpu_test", "language": "Python", "name": "py-ocean_sim_cpu_test"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.7"}, "last_sync_time": "2021-11-21T01:50:42.913960"}, "nbformat": 4, "nbformat_minor": 4}