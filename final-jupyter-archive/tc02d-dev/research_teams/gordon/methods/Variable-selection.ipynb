{"cells": [{"cell_type": "markdown", "id": "757f29ef", "metadata": {}, "source": ["# Variable selection\n", "\n", "How do we decide which inputs are most important for a GP? We're fetching the kernel parameters from the fitted GP and taking the inputs associated with the smallest length scale parameters. (We will go on to use different length scale parameter vectors as representatives of each GP fit for each GeoSurfaceTimePoint and then cluster these points in time and space based on which inputs are most important.)"]}, {"cell_type": "code", "execution_count": null, "id": "8b436597", "metadata": {"code_folding": []}, "outputs": [], "source": ["def ard(fitted_gpr,\n", "        parameter_names):\n", "    \"\"\"\n", "    For automatic relevance determination. Obtain the fitted length scale parameters for the fitted_gpr object.\n", "\n", "    Parameters\n", "\n", "    fitted_gpr : Scikit-learn GaussianProcessRegressor\n", "        a fitted GP\n", "    inputs : list\n", "        parameters considered from the dataset for fitting the GP\n", "\n", "    Value\n", "\n", "    numpy array\n", "        list of parameters with length scales, ordered by length scale\n", "    \"\"\"\n", "\n", "    # To record the inputs' predictive relevances R_j\n", "    dtype = [('input', 'U35'), ('length_scale', float)]\n", "    length_scales_and_names = []\n", "\n", "    # Obtain the length scales from the 'fitted_gpr' parameter GP\n", "    variable_length_scales = kernel_GP_pipe(fitted_gpr)['k2__length_scale']\n", "\n", "    # To produce a dictionary of parameters and their length scales\n", "    variable_names = np.array(parameter_names)\n", "\n", "    # We tabulate the variables and their length scales...\n", "    for var in range(len(variable_names)):\n", "        length_scales_and_names.append((variable_names[var], variable_length_scales[var]))\n", "\n", "    # And then order them by length scale\n", "    scored_inputs = np.array(length_scales_and_names, dtype=dtype)\n", "    return(np.sort(scored_inputs, order='input'))\n", "\n", "\n", "def cv(df,\n", "       inputs,\n", "       output,\n", "       folds=10,\n", "       nu=0.5,\n", "       mean_zero=False):\n", "    \"\"\"\n", "    Estimate the cross-validation error of a model\n", "\n", "    Parameters\n", "\n", "    df : Pandas DataFrame\n", "        full data set\n", "    folds : integer\n", "        number of folds for cross-validation\n", "    inputs : list\n", "        parameters considered from the dataset for fitting the GP\n", "    output : str\n", "        output of interest\n", "    nu : numeric\n", "        shape parameter for Matern kernel, ideally an integer multiple of 0.5\n", "    mean_zero : logical\n", "        if False, fit a mean field using linear regression, center the training response, and add back the mean after\n", "        predicting\n", "\n", "    Value\n", "\n", "    list\n", "        The list of validation error on each of the k=1,2,...,<folds> folds.\n", "    \"\"\"\n", "    import random\n", "\n", "    # To record the test error on each fold...\n", "    cv_error = []\n", "\n", "    # Assign folds to the samples\n", "    df[\"fold\"] = [x % folds for x in random.sample(range(df.shape[0]), df.shape[0])]\n", "\n", "    # Set aside data\n", "    X = np.array(df[inputs])\n", "    y = np.array(df[output])\n", "\n", "    for fold in range(folds):\n", "\n", "        # Train / test split\n", "        X_train = np.array(df[(df.fold != fold)][inputs])\n", "        y_train = np.array(df[(df.fold != fold)][output])\n", "        X_test = np.array(df[(df.fold == fold)][inputs])\n", "        y_test = np.array(df[(df.fold == fold)][output])\n", "        \n", "        # Fit GP\n", "        my_model = train_GP_pipe(X_train, y_train)\n", "\n", "        # Obtain predictions\n", "        y_predictions = np.array(my_model.process(c3.Dataset.fromPython(X_test)).m_data)\n", "\n", "        # Compute and record error\n", "        cv_error.append(np.mean((y_predictions - y_test) ** 2))\n", "\n", "    return(cv_error)"]}, {"cell_type": "markdown", "id": "f80af9db", "metadata": {}, "source": ["# Diagnostics"]}, {"cell_type": "code", "execution_count": null, "id": "d8cc3cf8", "metadata": {}, "outputs": [], "source": ["def select_vars(df,\n", "                ard_results,\n", "                output,\n", "                max_num_vars=10,\n", "                folds=10,\n", "                nu=0.5,\n", "                mean_zero=False):\n", "    \"\"\"\n", "    This is currently a diagnostic tool. We ask how the cross validation error changes as a function of the number of\n", "    inputs we use to fit a GP. We won't be using this method on every GP we fit, though. We will first cluster the\n", "    GeoSurfaceTimePoints by some appropriate method, and then we will select variables within each cluster.\n", "    \"\"\"\n", "\n", "    import numpy as np\n", "\n", "    ordered_inputs = ard_results[\"input\"][0:max_num_vars]\n", "    var_counter = list(range(1, len(ordered_inputs) + 1))\n", "    cv_means = []\n", "    cv_stds = []\n", "    \n", "    for k in var_counter:\n", "\n", "        cv_results_k = cv(df=df,\n", "                          inputs=ordered_inputs[0:k],\n", "                          output=output,\n", "                          folds=folds,\n", "                          nu=nu,\n", "                          mean_zero=mean_zero)\n", "        cv_means.append(np.mean(cv_results_k))\n", "        cv_stds.append(np.std(cv_results_k))\n", "    \n", "    return(pd.DataFrame({\n", "        'num_vars' : var_counter,\n", "        'next_var' : ordered_inputs,\n", "        'mean' : cv_means,\n", "        'std' : cv_stds\n", "    }))\n", "\n", "\n", "def plot_cv_curve(selection_results):\n", "    \"\"\"\n", "    This function just produces a plot of the results of the above diagnostic function.\n", "    \"\"\"\n", "    \n", "    import matplotlib.pyplot as plt\n", "    \n", "    plt.plot(selection_results['num_vars'], selection_results['mean'])\n", "    plt.fill_between(\n", "        selection_results['num_vars'].ravel(),\n", "        selection_results['mean'] - 1.96 * selection_results['std'],\n", "        selection_results['mean'] + 1.96 * selection_results['std'],\n", "        alpha = 0.5\n", "    )\n", "    \n", "    _ = plt.title(\"CV error as a function of $k$ the number of top inputs\")\n", "    plt.show()"]}], "metadata": {"has_local_update": false, "is_local": true, "is_remote": true, "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.8.10"}, "last_sync_time": "2022-06-17T02:06:32.296716"}, "nbformat": 4, "nbformat_minor": 5}