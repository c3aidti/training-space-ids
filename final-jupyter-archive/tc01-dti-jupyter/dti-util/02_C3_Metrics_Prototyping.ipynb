{"cells": [{"cell_type": "markdown", "metadata": {"heading_collapsed": true}, "source": ["# This notebook runs on a Python3 kernel\n", "No kernel changes required!"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# Metrics on the C3 AI Suite"]}, {"cell_type": "markdown", "metadata": {}, "source": ["**Note** The cells below contain generic working code. You can edit the existing code or add additional cells as you'd like."]}, {"cell_type": "markdown", "metadata": {}, "source": ["Import the necessary packages"]}, {"cell_type": "code", "execution_count": 1, "metadata": {"ExecuteTime": {"end_time": "2021-09-22T00:26:21.435278Z", "start_time": "2021-09-22T00:26:20.417580Z"}}, "outputs": [], "source": ["import matplotlib\n", "%matplotlib inline\n", "from datetime import datetime\n", "import pandas as pd\n", "pd.options.display.max_colwidth = 1000\n", "import numpy as np\n", "import matplotlib.pyplot as plt\n", "plt.rcParams['figure.figsize'] = (10,6)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Helper Functions for Plotting Metric Results\n", "#### Come back to this at the end of Section 3"]}, {"cell_type": "code", "execution_count": null, "metadata": {"ExecuteTime": {"end_time": "2021-06-08T01:49:14.933185Z", "start_time": "2021-06-08T01:49:14.927954Z"}, "code_folding": []}, "outputs": [], "source": ["'''\n", "FUTURE CHALLENGE - Skip for now\n", "Implement helper function that takes an EvalMetricsSpec\n", "and returns an appropriately formatted dataframe\n", "(See demo video for example)\n", "'''\n", "\n", "def spec_to_emr_to_df():\n", "    #TODO \n", "    return df"]}, {"cell_type": "code", "execution_count": null, "metadata": {"ExecuteTime": {"end_time": "2021-06-08T01:49:15.146690Z", "start_time": "2021-06-08T01:49:15.141796Z"}, "code_folding": []}, "outputs": [], "source": ["'''\n", "FUTURE CHALLENGE - Skip for now\n", "Implement helper function that takes in a dataframe, ids and expressions\n", "and plots them using the plotting tool of your choice.\n", "(See demo video for example using matplotlib)\n", "'''\n", "def plot_metrics(df, ids, expressions):\n", "    #TODO\n", "    return\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### 1. Evaluating Metrics already provisioned on the server"]}, {"cell_type": "markdown", "metadata": {}, "source": ["The following block of code allows you to list all the Metrics available on a specified type"]}, {"cell_type": "code", "execution_count": null, "metadata": {"ExecuteTime": {"end_time": "2021-06-11T18:32:19.565006Z", "start_time": "2021-06-11T18:32:19.288906Z"}, "scrolled": true}, "outputs": [], "source": ["metrics = pd.DataFrame(c3.MyType.listMetrics().toJson())\n", "metrics"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### REMINDER:  `evalMetrics` or `evalMetricsWithMetadata`\n", "\n", "* `evalMetrics`: to evaluate metrics already defined (i.e. provisioned) in C3 AI Suite environment\n", "* `evalMetricsWithMetadata`: to evaluate metrics defined on the fly or already in C3 AI Suite. If you do this, you will need to pass in a second argument to this function that will be a list of the metrics that do not yet exist in a C3 Database."]}, {"cell_type": "markdown", "metadata": {}, "source": ["Create EvalMetricsSpec:"]}, {"cell_type": "code", "execution_count": null, "metadata": {"ExecuteTime": {"end_time": "2021-06-04T20:40:18.429281Z", "start_time": "2021-06-04T20:40:18.425083Z"}}, "outputs": [], "source": ["my_spec = c3.EvalMetricsSpec(\n", "            ids = [\"id1\", \"id2\"],\n", "            expressions = [\"MyExpression\"],\n", "            start = \"2016-01-01\",\n", "            end = \"2020-01-01\",\n", "            interval = \"DAY\" \n", "        )"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Retrieve EvalMetricsResult:"]}, {"cell_type": "code", "execution_count": null, "metadata": {"ExecuteTime": {"end_time": "2021-06-04T20:40:22.066307Z", "start_time": "2021-06-04T20:40:19.235618Z"}}, "outputs": [], "source": ["evalMetricsResult = c3.MyType.evalMetrics(spec=my_spec)\n", "evalMetricsResult"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Convert to pandas dataframe:"]}, {"cell_type": "code", "execution_count": null, "metadata": {"ExecuteTime": {"end_time": "2021-06-04T20:40:22.089291Z", "start_time": "2021-06-04T20:40:22.067656Z"}}, "outputs": [], "source": ["df = c3.EvalMetricsResult.toPandas(evalMetricsResult)\n", "df"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Add source and timestamp column to dataframe:"]}, {"cell_type": "code", "execution_count": null, "metadata": {"ExecuteTime": {"end_time": "2021-06-04T20:40:37.343599Z", "start_time": "2021-06-04T20:40:37.324135Z"}}, "outputs": [], "source": ["df['source'] = df.index.str.split('_').str[0]\n", "df['timestamp'] = pd.to_datetime(df.index.str.split('_').str[1],format=\"%Y-%m-%dT%H:%M:%S.%f\")\n", "df"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Plot metric:"]}, {"cell_type": "code", "execution_count": null, "metadata": {"ExecuteTime": {"end_time": "2021-06-04T20:40:22.534514Z", "start_time": "2021-06-04T20:40:22.113708Z"}}, "outputs": [], "source": ["df[df['source']=='id1'].plot(x='timestamp',y='MyExpression')\n", "df[df['source']=='id2'].plot(x='timestamp',y='MyExpression')"]}, {"cell_type": "markdown", "metadata": {"heading_collapsed": true}, "source": ["### 2. Prototyping and Evaluating Simple Metrics"]}, {"cell_type": "markdown", "metadata": {"hidden": true}, "source": ["Define Simple Metric that you want to prototype:"]}, {"cell_type": "code", "execution_count": null, "metadata": {"ExecuteTime": {"end_time": "2021-06-04T20:41:20.212730Z", "start_time": "2021-06-04T20:41:20.170597Z"}, "code_folding": [], "hidden": true}, "outputs": [], "source": ["my_metric = c3.SimpleMetric(id = \"MyMetric_MyType\",\n", "                            name = \"MyMetric\",\n", "                            description = \"MyDescription\",\n", "                            srcType = \"MyType\",\n", "                            path = \"MyPath\",\n", "                            expression = \"MyExpression\"\n", "                           )\n", "            \n", "my_metric.toJson()"]}, {"cell_type": "markdown", "metadata": {"hidden": true}, "source": ["Create EvalMetricsSpec:"]}, {"cell_type": "code", "execution_count": null, "metadata": {"ExecuteTime": {"end_time": "2021-06-04T20:41:20.369600Z", "start_time": "2021-06-04T20:41:20.366630Z"}, "hidden": true}, "outputs": [], "source": ["my_spec = c3.EvalMetricsSpec(\n", "            ids = [\"id1\", \"id2\"],\n", "            expressions = [\"MyExpression\"],\n", "            start = \"2016-01-01\",\n", "            end = \"2020-01-01\",\n", "            interval = \"DAY\" \n", "        )"]}, {"cell_type": "markdown", "metadata": {"hidden": true}, "source": ["Get EvalMetricsResult:\n", "\n", "**Note**: We use evalMetricsWithMetadata while prototyping metrics"]}, {"cell_type": "code", "execution_count": null, "metadata": {"ExecuteTime": {"end_time": "2021-06-04T20:41:23.825467Z", "start_time": "2021-06-04T20:41:20.992727Z"}, "hidden": true}, "outputs": [], "source": ["evalMetricsResult = c3.MyType.evalMetricsWithMetadata(spec=my_spec,\n", "                                                      overrideMetrics=[my_metric])\n", "evalMetricsResult"]}, {"cell_type": "markdown", "metadata": {"hidden": true}, "source": ["Convert to pandas dataframe:"]}, {"cell_type": "code", "execution_count": null, "metadata": {"ExecuteTime": {"end_time": "2021-06-04T20:41:26.308584Z", "start_time": "2021-06-04T20:41:26.294927Z"}, "hidden": true}, "outputs": [], "source": ["# convert EvalMetricsResult to Pandas DataFrame\n", "df = c3.EvalMetricsResult.toPandas(result=evalMetricsResult)\n", "df"]}, {"cell_type": "markdown", "metadata": {"hidden": true}, "source": ["Add source and timestamp column to dataframe:"]}, {"cell_type": "code", "execution_count": null, "metadata": {"ExecuteTime": {"end_time": "2021-06-04T20:41:28.636283Z", "start_time": "2021-06-04T20:41:28.616042Z"}, "hidden": true}, "outputs": [], "source": ["#Post process dataframe to add 'source' and 'timestamp' column\n", "df['source'] = df.index.str.split('_').str[0]\n", "df['timestamp'] = pd.to_datetime(df.index.str.split('_').str[1],format=\"%Y-%m-%dT%H:%M:%S.%f\")\n", "df"]}, {"cell_type": "markdown", "metadata": {"hidden": true}, "source": ["Plot metric:"]}, {"cell_type": "code", "execution_count": null, "metadata": {"ExecuteTime": {"end_time": "2021-06-04T20:41:29.172258Z", "start_time": "2021-06-04T20:41:28.821985Z"}, "hidden": true}, "outputs": [], "source": ["df[df['source']=='id1'].plot(x='timestamp',y='MyExpression')\n", "df[df['source']=='id2'].plot(x='timestamp',y='MyExpression')"]}, {"cell_type": "code", "execution_count": null, "metadata": {"ExecuteTime": {"end_time": "2021-06-11T21:52:55.254307Z", "start_time": "2021-06-11T21:52:55.208979Z"}, "hidden": true}, "outputs": [], "source": ["# # You have 2 options to get your metric into a file -- comment in and use whichever one you prefer!\n", "\n", "# # will print out the metric code directly, copy and paste in VS Code\n", "# my_metric.toJson() \n", "\n", "\n", "# # will write the metric to a json file named myMetric.json\n", "# import json\n", "# with open('myMetric.json', 'w') as f:\n", "#   json.dump(my_metric.toJson(), f, ensure_ascii=False)"]}, {"cell_type": "markdown", "metadata": {"heading_collapsed": true}, "source": ["### 3. Prototyping and Evaluating Simple `TSDecl` Metrics"]}, {"cell_type": "code", "execution_count": null, "metadata": {"ExecuteTime": {"end_time": "2021-06-02T15:05:25.853138Z", "start_time": "2021-06-02T15:05:25.787531Z"}, "hidden": true}, "outputs": [], "source": ["help(c3.TSDecl)"]}, {"cell_type": "markdown", "metadata": {"hidden": true}, "source": ["Define TSDecl Metric:"]}, {"cell_type": "code", "execution_count": null, "metadata": {"ExecuteTime": {"end_time": "2021-06-04T20:42:12.547121Z", "start_time": "2021-06-04T20:42:12.524602Z"}, "hidden": true}, "outputs": [], "source": ["myTsDeclMetric = c3.SimpleMetric(id = \"MyMetric_MyType\",\n", "                                 name = \"MyMetric\",\n", "                                 srcType = \"MyType\",\n", "                                 description=\"MyDescription\",\n", "                                 path=\"MyPath\",\n", "                                 tsDecl = c3.TSDecl(data = \"MyData\",\n", "                                                   value = \"MyValue\",\n", "                                                   treatment = \"MyTreatment\",\n", "                                                   start = \"MyStart\"))\n", "\n", "myTsDeclMetric.toJson()"]}, {"cell_type": "markdown", "metadata": {"hidden": true}, "source": ["Create EvalMetricsSpec:"]}, {"cell_type": "code", "execution_count": null, "metadata": {"ExecuteTime": {"end_time": "2021-06-04T20:42:12.726669Z", "start_time": "2021-06-04T20:42:12.723747Z"}, "hidden": true}, "outputs": [], "source": ["my_tsdecl_spec = c3.EvalMetricsSpec(ids = [\"id1\",\"id2\",\"id3\"],\n", "                                    expressions = [\"MyExpression\"],\n", "                                    start = \"2016-01-01\",\n", "                                    end = \"2020-01-01\",\n", "                                    interval = \"DAY\")"]}, {"cell_type": "markdown", "metadata": {"hidden": true}, "source": ["Use helper function to create appropriately formatted dataframe:"]}, {"cell_type": "code", "execution_count": null, "metadata": {"ExecuteTime": {"end_time": "2021-06-04T20:42:13.631235Z", "start_time": "2021-06-04T20:42:13.534351Z"}, "code_folding": [], "hidden": true}, "outputs": [], "source": ["# TODO - \n", "# You have to implement this method in the code-block shown\n", "# on top of this notebook\n", "df = spec_to_emr_to_df()\n", "df"]}, {"cell_type": "markdown", "metadata": {"hidden": true}, "source": ["Using the plotting helper function, generate plots for different ids for the Metric you prototyped above."]}, {"cell_type": "code", "execution_count": null, "metadata": {"ExecuteTime": {"end_time": "2021-06-04T20:42:57.567151Z", "start_time": "2021-06-04T20:42:57.357077Z"}, "hidden": true}, "outputs": [], "source": ["# TODO - \n", "# You have to implement this method in the code-block shown\n", "# on top of this notebook\n", "plot_metrics(df, [\"id1\", \"id2\", \"id3\"], [\"MyExpression\"] )"]}, {"cell_type": "markdown", "metadata": {"heading_collapsed": true}, "source": ["### 4. Prototyping and Evaluating Compound Metrics\n"]}, {"cell_type": "markdown", "metadata": {"hidden": true}, "source": ["Define Compound Metric:"]}, {"cell_type": "code", "execution_count": null, "metadata": {"ExecuteTime": {"end_time": "2021-06-08T01:49:20.062336Z", "start_time": "2021-06-08T01:49:20.058460Z"}, "hidden": true}, "outputs": [], "source": ["my_compound_metric = c3.CompoundMetric(id = \"MyCompoundMetric\",\n", "                                name = \"MyCompoundMetric\",\n", "                                description = \"MyDescription\",\n", "                                expression = \"MyExpression\")\n", "my_compound_metric.toJson()"]}, {"cell_type": "markdown", "metadata": {"hidden": true}, "source": ["Using the helper functions defined above, retrieve data for your prototyped compound metric and plot results"]}, {"cell_type": "code", "execution_count": null, "metadata": {"ExecuteTime": {"end_time": "2021-06-08T01:59:00.350600Z", "start_time": "2021-06-08T01:58:57.872081Z"}, "hidden": true}, "outputs": [], "source": ["myType = c3.MyType\n", "ids = [\"id1\", \"id2\", \"id3\"] #ids for the objects to evaluate the metric\n", "expressions = [\"MyMetric1\", \"MyMetric2\"]\n", "start = \"2016-01-01\"\n", "end = \"2019-06-01\"\n", "interval = \"MONTH\"\n", "\n", "#define EvalMetricsSpec\n", "my_spec = c3.EvalMetricsSpec(ids = ids,\n", "                             expressions = expressions,\n", "                             start = start,\n", "                             end = end,\n", "                             interval = interval)\n", "\n", "# retrieve appropriately formatted dataframe\n", "# ensure that you have defined these methods\n", "df = spec_to_emr_to_df()\n", "\n", "plot_metrics(df, ids, expressions)"]}, {"cell_type": "markdown", "metadata": {"heading_collapsed": true}, "source": ["# Make sure to SYNC your notebook to the server, then CLOSE AND HALT this notebook when you leave.\u00b6\n", "To sync: go to the File menu, Save and Checkpoint your notebook, and then select \"Upload Notebook to C3.ai\", or select the notebook in the tree view (check the box) and hit the \"Sync\" button."]}], "metadata": {"has_local_update": false, "is_local": true, "is_remote": true, "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.7.9"}, "last_sync_time": "2021-09-22T00:26:02.298890"}, "nbformat": 4, "nbformat_minor": 4}